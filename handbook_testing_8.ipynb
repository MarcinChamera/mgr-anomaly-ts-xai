{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "\n",
    "@book{leborgne2022fraud,\n",
    "\n",
    "title={Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook},\n",
    "\n",
    "author={Le Borgne, Yann-A{\\\"e}l and Siblini, Wissam and Lebichot, Bertrand and Bontempi, Gianluca},\n",
    "\n",
    "url={https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook},\n",
    "\n",
    "year={2022},\n",
    "\n",
    "publisher={Universit{\\'e} Libre de Bruxelles}\n",
    "\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covered subchapters:\n",
    "* 7.4 Sequential models and representation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run shared_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run my_shared_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 391 ms\n",
      "Wall time: 408 ms\n",
      "919767 transactions loaded, containing 8195 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT = '../fraud-detection-handbook/simulated-data-transformed/data/'\n",
    "\n",
    "BEGIN_DATE = \"2018-06-11\"\n",
    "END_DATE = \"2018-09-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
    "\n",
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the starting day for the training period, and the deltas\n",
    "start_date_training = datetime.datetime.strptime(\"2018-07-25\", \"%Y-%m-%d\")\n",
    "delta_train=7\n",
    "delta_delay=7\n",
    "delta_test=7\n",
    "\n",
    "\n",
    "delta_valid = delta_test\n",
    "\n",
    "start_date_training_with_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "\n",
    "(train_df, valid_df)=get_train_test_set(transactions_df,start_date_training_with_valid,\n",
    "                                       delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_test)\n",
    "\n",
    "# By default, scales input data\n",
    "(train_df, valid_df)=scaleData(train_df, valid_df,input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TX_AMOUNT',\n",
       " 'TX_DURING_WEEKEND',\n",
       " 'TX_DURING_NIGHT',\n",
       " 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
       " 'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW',\n",
       " 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
       " 'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW',\n",
       " 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
       " 'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW',\n",
       " 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
       " 'TERMINAL_ID_RISK_1DAY_WINDOW',\n",
       " 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
       " 'TERMINAL_ID_RISK_7DAY_WINDOW',\n",
       " 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
       " 'TERMINAL_ID_RISK_30DAY_WINDOW']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark variable\n",
    "dates = train_df['TX_DATETIME'].values\n",
    "\n",
    "# time variable for chronological order sequence building\n",
    "customer_ids = train_df['CUSTOMER_ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_sort = np.argsort(dates)\n",
    "sorted_dates = dates[indices_sort]\n",
    "sorted_ids = customer_ids[indices_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-07-11T00:00:54.000000000', '2018-07-11T00:01:59.000000000',\n",
       "       '2018-07-11T00:03:39.000000000', ...,\n",
       "       '2018-07-17T23:57:59.000000000', '2018-07-17T23:58:23.000000000',\n",
       "       '2018-07-17T23:59:52.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 579,  181, 4386, ...,  137, 1331, 1655], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_customer_ids = np.unique(sorted_ids)\n",
    "unique_customer_ids[0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example\n",
    "\n",
    "The sequence of transcation IDs for customer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1888, 10080, 12847, 15627, 18908, 22842, 37972, 42529, 44495,\n",
       "       48980, 58692, 63977], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "current_customer_id = unique_customer_ids[idx]\n",
    "customer_mask = sorted_ids == current_customer_id\n",
    "# this is the full sequence of transaction indices (after sort) for customer 0\n",
    "customer_full_seq = np.where(customer_mask)[0]\n",
    "# this is the full sequence of transaction indices (before sort) for customer 0\n",
    "customer_full_seq_original_indices = indices_sort[customer_full_seq]\n",
    "customer_full_seq_original_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   -1,    -1,    -1,    -1,  1888],\n",
       "       [   -1,    -1,    -1,  1888, 10080],\n",
       "       [   -1,    -1,  1888, 10080, 12847],\n",
       "       [   -1,  1888, 10080, 12847, 15627],\n",
       "       [ 1888, 10080, 12847, 15627, 18908],\n",
       "       [10080, 12847, 15627, 18908, 22842],\n",
       "       [12847, 15627, 18908, 22842, 37972],\n",
       "       [15627, 18908, 22842, 37972, 42529],\n",
       "       [18908, 22842, 37972, 42529, 44495],\n",
       "       [22842, 37972, 42529, 44495, 48980],\n",
       "       [37972, 42529, 44495, 48980, 58692],\n",
       "       [42529, 44495, 48980, 58692, 63977]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_all_seqs = rolling_window(customer_full_seq_original_indices,seq_len)\n",
    "customer_all_seqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6th sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10080, 12847, 15627, 18908, 22842])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_all_seqs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(train_df[input_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6965, -0.6306,  2.1808, -0.8466,  0.0336, -1.1665,  0.0176, -0.9341,\n",
       "          0.2310, -0.9810, -0.0816, -0.3445, -0.1231, -0.2491, -0.1436],\n",
       "        [ 0.0358, -0.6306, -0.4586, -0.8466,  0.4450, -1.1665,  0.1112, -0.8994,\n",
       "          0.2278,  0.0028, -0.0816,  0.6425, -0.1231, -0.0082, -0.1436],\n",
       "        [ 1.1437, -0.6306, -0.4586, -0.3003,  0.7595, -1.0352,  0.2462, -0.8994,\n",
       "          0.2458,  1.9702, -0.0816,  1.3005, -0.1231,  1.7989, -0.1436],\n",
       "        [ 0.3645, -0.6306, -0.4586,  0.2461,  0.6804, -1.0352,  0.3186, -0.8647,\n",
       "          0.2514,  1.9702, -0.0816,  0.3135, -0.1231, -0.8514, -0.1436],\n",
       "        [ 0.3348, -0.6306, -0.4586, -0.3003,  0.7462, -1.1665,  0.2494, -0.8994,\n",
       "          0.2262, -0.9810, -0.0816, -2.3185, -0.1231, -1.5743, -0.1436]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixth_sequence = x_train[customer_all_seqs[5],:]\n",
    "sixth_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixth_sequence.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficient Pandas + groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TX_DATETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>579</td>\n",
       "      <td>2018-07-11 00:00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>2018-07-11 00:01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4386</td>\n",
       "      <td>2018-07-11 00:03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4599</td>\n",
       "      <td>2018-07-11 00:05:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4784</td>\n",
       "      <td>2018-07-11 00:06:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66923</th>\n",
       "      <td>1494</td>\n",
       "      <td>2018-07-17 23:55:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66924</th>\n",
       "      <td>2561</td>\n",
       "      <td>2018-07-17 23:56:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66925</th>\n",
       "      <td>137</td>\n",
       "      <td>2018-07-17 23:57:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66926</th>\n",
       "      <td>1331</td>\n",
       "      <td>2018-07-17 23:58:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66927</th>\n",
       "      <td>1655</td>\n",
       "      <td>2018-07-17 23:59:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTOMER_ID         TX_DATETIME\n",
       "0              579 2018-07-11 00:00:54\n",
       "1              181 2018-07-11 00:01:59\n",
       "2             4386 2018-07-11 00:03:39\n",
       "3             4599 2018-07-11 00:05:50\n",
       "4             4784 2018-07-11 00:06:04\n",
       "...            ...                 ...\n",
       "66923         1494 2018-07-17 23:55:41\n",
       "66924         2561 2018-07-17 23:56:05\n",
       "66925          137 2018-07-17 23:57:59\n",
       "66926         1331 2018-07-17 23:58:23\n",
       "66927         1655 2018-07-17 23:59:52\n",
       "\n",
       "[66928 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ids_dates = pd.DataFrame({'CUSTOMER_ID': customer_ids,\n",
    "        'TX_DATETIME': dates})\n",
    "df_ids_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       NaT\n",
       "1       2018-07-11 00:00:54\n",
       "2       2018-07-11 00:01:59\n",
       "3       2018-07-11 00:03:39\n",
       "4       2018-07-11 00:05:50\n",
       "                ...        \n",
       "66923   2018-07-17 23:54:45\n",
       "66924   2018-07-17 23:55:41\n",
       "66925   2018-07-17 23:56:05\n",
       "66926   2018-07-17 23:57:59\n",
       "66927   2018-07-17 23:58:23\n",
       "Name: TX_DATETIME, Length: 66928, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ids_dates[\"TX_DATETIME\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   NaT\n",
       "1       0 days 00:01:05\n",
       "2       0 days 00:01:40\n",
       "3       0 days 00:02:11\n",
       "4       0 days 00:00:14\n",
       "              ...      \n",
       "66923   0 days 00:00:56\n",
       "66924   0 days 00:00:24\n",
       "66925   0 days 00:01:54\n",
       "66926   0 days 00:00:24\n",
       "66927   0 days 00:01:29\n",
       "Name: TX_DATETIME, Length: 66928, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_ids_dates[\"TX_DATETIME\"] - df_ids_dates[\"TX_DATETIME\"].shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the transaction are chronologically ordered\n",
    "datetime_diff = (df_ids_dates[\"TX_DATETIME\"] - df_ids_dates[\"TX_DATETIME\"].shift(1)).iloc[1:].dt.total_seconds()\n",
    "assert (datetime_diff >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>tmp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>579</td>\n",
       "      <td>2018-07-11 00:00:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>2018-07-11 00:01:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4386</td>\n",
       "      <td>2018-07-11 00:03:39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4599</td>\n",
       "      <td>2018-07-11 00:05:50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4784</td>\n",
       "      <td>2018-07-11 00:06:04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUSTOMER_ID         TX_DATETIME  tmp_index\n",
       "0          579 2018-07-11 00:00:54          0\n",
       "1          181 2018-07-11 00:01:59          1\n",
       "2         4386 2018-07-11 00:03:39          2\n",
       "3         4599 2018-07-11 00:05:50          3\n",
       "4         4784 2018-07-11 00:06:04          4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ids_dates[\"tmp_index\"]  = np.arange(len(df_ids_dates))\n",
    "df_ids_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_customer_id = df_ids_dates.groupby(\"CUSTOMER_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_0</th>\n",
       "      <th>tx_1</th>\n",
       "      <th>tx_2</th>\n",
       "      <th>tx_3</th>\n",
       "      <th>tx_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tx_0  tx_1  tx_2  tx_3  tx_4\n",
       "0    -1    -1    -1    -1     0\n",
       "1    -1    -1    -1    -1     1\n",
       "2    -1    -1    -1    -1     2\n",
       "3    -1    -1    -1    -1     3\n",
       "4    -1    -1    -1    -1     4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_indices = pd.DataFrame(\n",
    "            {\n",
    "                \"tx_{}\".format(n): df_groupby_customer_id[\"tmp_index\"].shift(seq_len - n - 1)\n",
    "                for n in range(seq_len)\n",
    "            }\n",
    "        )\n",
    "\n",
    "sequence_indices = sequence_indices.fillna(-1).astype(int)\n",
    "sequence_indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_0</th>\n",
       "      <th>tx_1</th>\n",
       "      <th>tx_2</th>\n",
       "      <th>tx_3</th>\n",
       "      <th>tx_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66923</th>\n",
       "      <td>59962</td>\n",
       "      <td>65409</td>\n",
       "      <td>65951</td>\n",
       "      <td>66805</td>\n",
       "      <td>66923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66924</th>\n",
       "      <td>42669</td>\n",
       "      <td>48902</td>\n",
       "      <td>62594</td>\n",
       "      <td>64441</td>\n",
       "      <td>66924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66925</th>\n",
       "      <td>-1</td>\n",
       "      <td>18988</td>\n",
       "      <td>23403</td>\n",
       "      <td>66777</td>\n",
       "      <td>66925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66926</th>\n",
       "      <td>56083</td>\n",
       "      <td>56468</td>\n",
       "      <td>63286</td>\n",
       "      <td>63338</td>\n",
       "      <td>66926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66927</th>\n",
       "      <td>49051</td>\n",
       "      <td>52037</td>\n",
       "      <td>58500</td>\n",
       "      <td>60393</td>\n",
       "      <td>66927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tx_0   tx_1   tx_2   tx_3   tx_4\n",
       "66923  59962  65409  65951  66805  66923\n",
       "66924  42669  48902  62594  64441  66924\n",
       "66925     -1  18988  23403  66777  66925\n",
       "66926  56083  56468  63286  63338  66926\n",
       "66927  49051  52037  58500  60393  66927"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_indices.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -1    -1  1888 10080 12847]\n",
      "[   -1  1888 10080 12847 15627]\n",
      "[ 1888 10080 12847 15627 18908]\n",
      "------------------------------\n",
      "[   -1    -1  1888 10080 12847]\n",
      "[   -1  1888 10080 12847 15627]\n",
      "[ 1888 10080 12847 15627 18908]\n"
     ]
    }
   ],
   "source": [
    "print(customer_all_seqs[2])\n",
    "print(customer_all_seqs[3])\n",
    "print(customer_all_seqs[4])\n",
    "print(30*'-')\n",
    "print(sequence_indices.loc[12847].values)\n",
    "print(sequence_indices.loc[15627].values)\n",
    "print(sequence_indices.loc[18908].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "x_valid = torch.FloatTensor(valid_df[input_features].values)\n",
    "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "y_valid = torch.FloatTensor(valid_df[output_feature].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "\n",
    "\n",
    "# Generators\n",
    "\n",
    "training_set = FraudSequenceDataset(x_train, y_train,train_df['CUSTOMER_ID'].values, train_df['TX_DATETIME'].values,seq_len,padding_mode = \"zeros\")\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **train_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 15, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size, number of features, sequence length\n",
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudConvNet(\n",
       "  (padding1): ConstantPad1d(padding=(1, 0), value=0)\n",
       "  (conv1): Conv1d(15, 100, kernel_size=(2,), stride=(1,))\n",
       "  (pooling): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "training_set = FraudSequenceDataset(x_train, \n",
    "                                    y_train,train_df['CUSTOMER_ID'].values, \n",
    "                                    train_df['TX_DATETIME'].values,\n",
    "                                    seq_len,\n",
    "                                    padding_mode = \"zeros\")\n",
    "\n",
    "valid_set = FraudSequenceDataset(x_valid, \n",
    "                                 y_valid,\n",
    "                                 valid_df['CUSTOMER_ID'].values, \n",
    "                                 valid_df['TX_DATETIME'].values,\n",
    "                                 seq_len,\n",
    "                                 padding_mode = \"zeros\")\n",
    "\n",
    "training_generator,valid_generator = prepare_generators(training_set, valid_set, batch_size=64)\n",
    "cnn = FraudConvNet(x_train.shape[1], seq_len).to(DEVICE)\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da63ed541624d4781740c9ca47c3e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221227_133310-2eyrviz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/2eyrviz6\" target=\"_blank\">copper-mountain-35</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    seq_len=5,\n",
    "    hidden_size = 100,\n",
    "    conv1_num_filters = 100,\n",
    "    conv1_filter_size=2,\n",
    "    max_pooling=True,\n",
    "    optimizer='adam',\n",
    "    lr=0.0001,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=2,\n",
    "    max_epochs=100,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['cnn', 'imbalance-not-considered'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.11350999349535908\n",
      "valid loss: 0.04332761334234981\n",
      "New best score: 0.04332761334234981\n",
      "\n",
      "Epoch 1: train loss: 0.04622721335855998\n",
      "valid loss: 0.03007508676799391\n",
      "New best score: 0.03007508676799391\n",
      "\n",
      "Epoch 2: train loss: 0.03614304168083052\n",
      "valid loss: 0.026291765901387307\n",
      "New best score: 0.026291765901387307\n",
      "\n",
      "Epoch 3: train loss: 0.03290854613287784\n",
      "valid loss: 0.024909574793946874\n",
      "New best score: 0.024909574793946874\n",
      "\n",
      "Epoch 4: train loss: 0.030797378536461573\n",
      "valid loss: 0.024116291352318693\n",
      "New best score: 0.024116291352318693\n",
      "\n",
      "Epoch 5: train loss: 0.0292948524776604\n",
      "valid loss: 0.023185593134576018\n",
      "New best score: 0.023185593134576018\n",
      "\n",
      "Epoch 6: train loss: 0.027989952710820415\n",
      "valid loss: 0.02238688605819712\n",
      "New best score: 0.02238688605819712\n",
      "\n",
      "Epoch 7: train loss: 0.026988997871820134\n",
      "valid loss: 0.022145571418951362\n",
      "New best score: 0.022145571418951362\n",
      "\n",
      "Epoch 8: train loss: 0.026260754396697332\n",
      "valid loss: 0.02172331586085728\n",
      "New best score: 0.02172331586085728\n",
      "\n",
      "Epoch 9: train loss: 0.02557059156242758\n",
      "valid loss: 0.021544961050748216\n",
      "New best score: 0.021544961050748216\n",
      "\n",
      "Epoch 10: train loss: 0.02510334534806967\n",
      "valid loss: 0.02167423897145489\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 11: train loss: 0.024623324531424313\n",
      "valid loss: 0.021495898886802582\n",
      "New best score: 0.021495898886802582\n",
      "\n",
      "Epoch 12: train loss: 0.024206023574913593\n",
      "valid loss: 0.021230877464118062\n",
      "New best score: 0.021230877464118062\n",
      "\n",
      "Epoch 13: train loss: 0.023820835461837362\n",
      "valid loss: 0.021392457917729608\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 14: train loss: 0.02343073567537142\n",
      "valid loss: 0.02128997985820688\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 15: train loss: 0.02315220787436087\n",
      "valid loss: 0.021391211984083666\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = 0.0001)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "cnn,training_execution_time,train_losses,valid_losses = \\\n",
    "    training_loop_and_saving_best_wandb(cnn,\n",
    "                  training_generator,\n",
    "                  valid_generator,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  verbose=True,\n",
    "                  save_path='models/DL/cnn/cnn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "valid_predictions = get_predictions_sequential(cnn, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0     0.85              0.566     0.586               0.264"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_predictions\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\cnn)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.85</td></tr><tr><td>Average precision</td><td>0.566</td></tr><tr><td>Card Precision@100</td><td>0.264</td></tr><tr><td>F1 score</td><td>0.586</td></tr><tr><td>Prediction execution time</td><td>10.05</td></tr><tr><td>Training execution time</td><td>365.268</td></tr><tr><td>train loss</td><td>0.02315</td></tr><tr><td>val loss</td><td>0.02139</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">copper-mountain-35</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/2eyrviz6\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/2eyrviz6</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_133310-2eyrviz6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "artifact = wandb.Artifact('cnn', type='cnn', description='trained cnn with 1 conv1d layer, max pooling and 1 dense layer')\n",
    "artifact.add_dir('models/DL/cnn')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudLSTM(\n",
       "  (lstm): LSTM(15, 100, batch_first=True)\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = FraudLSTM(x_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 0.0001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34faf5d017ef4d16960b8b249a381fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666656966, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221227_134054-20ijlbh6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/20ijlbh6\" target=\"_blank\">eager-firebrand-36</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    seq_len=5,\n",
    "    hidden_size = 100,\n",
    "    hidden_size_lstm = 100,\n",
    "    num_layers_lstm = 1,\n",
    "    dropout = 0,\n",
    "    optimizer='adam',\n",
    "    lr=0.0001,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=2,\n",
    "    max_epochs=100,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['lstm', 'imbalance-not-considered'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.11769908162441112\n",
      "valid loss: 0.02722328091523727\n",
      "New best score: 0.02722328091523727\n",
      "\n",
      "Epoch 1: train loss: 0.033310829799793246\n",
      "valid loss: 0.024378997859763888\n",
      "New best score: 0.024378997859763888\n",
      "\n",
      "Epoch 2: train loss: 0.029553174446995796\n",
      "valid loss: 0.022223314901182803\n",
      "New best score: 0.022223314901182803\n",
      "\n",
      "Epoch 3: train loss: 0.026766734665177806\n",
      "valid loss: 0.021396628077411668\n",
      "New best score: 0.021396628077411668\n",
      "\n",
      "Epoch 4: train loss: 0.024907904123285533\n",
      "valid loss: 0.020335928123963416\n",
      "New best score: 0.020335928123963416\n",
      "\n",
      "Epoch 5: train loss: 0.023890609810454683\n",
      "valid loss: 0.020084351468373274\n",
      "New best score: 0.020084351468373274\n",
      "\n",
      "Epoch 6: train loss: 0.023037582767431057\n",
      "valid loss: 0.01964684613150814\n",
      "New best score: 0.01964684613150814\n",
      "\n",
      "Epoch 7: train loss: 0.02251058735496972\n",
      "valid loss: 0.01924232041127369\n",
      "New best score: 0.01924232041127369\n",
      "\n",
      "Epoch 8: train loss: 0.022025993510316807\n",
      "valid loss: 0.019455202991560182\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 9: train loss: 0.02152586069430383\n",
      "valid loss: 0.019022997332573996\n",
      "New best score: 0.019022997332573996\n",
      "\n",
      "Epoch 10: train loss: 0.021129216333934914\n",
      "valid loss: 0.018847208789961992\n",
      "New best score: 0.018847208789961992\n",
      "\n",
      "Epoch 11: train loss: 0.020773262642484237\n",
      "valid loss: 0.0187162789124283\n",
      "New best score: 0.0187162789124283\n",
      "\n",
      "Epoch 12: train loss: 0.020367970643442635\n",
      "valid loss: 0.01852704958119964\n",
      "New best score: 0.01852704958119964\n",
      "\n",
      "Epoch 13: train loss: 0.020234847828290867\n",
      "valid loss: 0.018341565601492065\n",
      "New best score: 0.018341565601492065\n",
      "\n",
      "Epoch 14: train loss: 0.019831051578490157\n",
      "valid loss: 0.018326476021145618\n",
      "New best score: 0.018326476021145618\n",
      "\n",
      "Epoch 15: train loss: 0.019583915378635724\n",
      "valid loss: 0.018123666015186453\n",
      "New best score: 0.018123666015186453\n",
      "\n",
      "Epoch 16: train loss: 0.019418955460924436\n",
      "valid loss: 0.018398193594404175\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 17: train loss: 0.01906471965806897\n",
      "valid loss: 0.01822412699331209\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 18: train loss: 0.018903557895017204\n",
      "valid loss: 0.017920236876412535\n",
      "New best score: 0.017920236876412535\n",
      "\n",
      "Epoch 19: train loss: 0.018808694832480155\n",
      "valid loss: 0.017809387852432704\n",
      "New best score: 0.017809387852432704\n",
      "\n",
      "Epoch 20: train loss: 0.018559294416607905\n",
      "valid loss: 0.018060480803124036\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 21: train loss: 0.01839504770551279\n",
      "valid loss: 0.018428605187256804\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 22: train loss: 0.018255437255737302\n",
      "valid loss: 0.017883307163099774\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "lstm,training_execution_time,train_losses,valid_losses = \\\n",
    "    training_loop_and_saving_best_wandb(lstm,\n",
    "                  training_generator,\n",
    "                  valid_generator,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  verbose=True,\n",
    "                  save_path='models/DL/lstm/lstm_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "valid_predictions = get_predictions_sequential(lstm, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.858              0.662     0.697               0.277"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_predictions\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\lstm)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▆▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.858</td></tr><tr><td>Average precision</td><td>0.662</td></tr><tr><td>Card Precision@100</td><td>0.277</td></tr><tr><td>F1 score</td><td>0.697</td></tr><tr><td>Prediction execution time</td><td>9.212</td></tr><tr><td>Training execution time</td><td>566.41576</td></tr><tr><td>train loss</td><td>0.01826</td></tr><tr><td>val loss</td><td>0.01788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-firebrand-36</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/20ijlbh6\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/20ijlbh6</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_134054-20ijlbh6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "artifact = wandb.Artifact('lstm', type='lstm', description='trained LSTM with 1 lstm layer and 1 hidden dense layer')\n",
    "artifact.add_dir('models/DL/lstm')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence of all hidden states, and the last hidden and cell states - on previous LSTM\n",
    "out_seq, (last_hidden,last_cell) = lstm.lstm(x_batch.transpose(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 100])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 100])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hidden states of the whole batch\n",
    "test_hidden_states_seq = out_seq\n",
    "\n",
    "test_context_projector = torch.nn.Linear(x_batch.shape[1], out_seq.shape[2]).to(DEVICE)\n",
    "# the context vector of the whole batch\n",
    "test_context_vector = test_context_projector(x_batch[:,:,-1:].transpose(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "test_attention = Attention(100).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 100])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_state, attn = test_attention(test_context_vector,test_hidden_states_seq)\n",
    "output_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5409, 0.4099, 0.0408, 0.0066, 0.0017], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if the last hidden state is used as a context vector instead\n",
    "output, attn = test_attention(test_hidden_states_seq[:,4:,:],test_hidden_states_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4132e-07, 5.8130e-06, 3.3866e-04, 1.5329e-02, 9.8433e-01],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudLSTMWithAttention(\n",
       "  (lstm): LSTM(15, 100, batch_first=True)\n",
       "  (ff): Linear(in_features=15, out_features=100, bias=True)\n",
       "  (attention): Attention(\n",
       "    (linear_out): Linear(in_features=200, out_features=100, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "lstm_attn = FraudLSTMWithAttention(x_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(lstm_attn.parameters(), lr = 0.00008)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "training_generator,valid_generator = prepare_generators(training_set,valid_set,batch_size=64)\n",
    "lstm_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d53361fb6b44049f8b56c9f5f736ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221227_135322-3a26in9x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/3a26in9x\" target=\"_blank\">lyric-firefly-37</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    seq_len=5,\n",
    "    hidden_size = 100,\n",
    "    hidden_size_lstm = 100,\n",
    "    num_layers_lstm = 1,\n",
    "    dropout = 0,\n",
    "    attention_out_dim=100,\n",
    "    optimizer='adam',\n",
    "    lr=0.00008,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=2,\n",
    "    max_epochs=100,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['lstm', 'imbalance-not-considered', 'attention'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.10345629619253732\n",
      "valid loss: 0.0217021710073952\n",
      "New best score: 0.0217021710073952\n",
      "\n",
      "Epoch 1: train loss: 0.026198114701422078\n",
      "valid loss: 0.020528786274212632\n",
      "New best score: 0.020528786274212632\n",
      "\n",
      "Epoch 2: train loss: 0.02440665406609011\n",
      "valid loss: 0.019647970981641463\n",
      "New best score: 0.019647970981641463\n",
      "\n",
      "Epoch 3: train loss: 0.023379573382812963\n",
      "valid loss: 0.019510614707088862\n",
      "New best score: 0.019510614707088862\n",
      "\n",
      "Epoch 4: train loss: 0.022794361631710964\n",
      "valid loss: 0.019047817616097508\n",
      "New best score: 0.019047817616097508\n",
      "\n",
      "Epoch 5: train loss: 0.022292002547958805\n",
      "valid loss: 0.018893860004043278\n",
      "New best score: 0.018893860004043278\n",
      "\n",
      "Epoch 6: train loss: 0.021784094891717468\n",
      "valid loss: 0.01878023694073425\n",
      "New best score: 0.01878023694073425\n",
      "\n",
      "Epoch 7: train loss: 0.02147723132669641\n",
      "valid loss: 0.01882252073325115\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 8: train loss: 0.02097141956182617\n",
      "valid loss: 0.018680794560604938\n",
      "New best score: 0.018680794560604938\n",
      "\n",
      "Epoch 9: train loss: 0.020616913763347684\n",
      "valid loss: 0.018731316284128958\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 10: train loss: 0.020165410831242972\n",
      "valid loss: 0.01848030736417983\n",
      "New best score: 0.01848030736417983\n",
      "\n",
      "Epoch 11: train loss: 0.019802826342091007\n",
      "valid loss: 0.01889964193481026\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 12: train loss: 0.019516432447600256\n",
      "valid loss: 0.01844384471778987\n",
      "New best score: 0.01844384471778987\n",
      "\n",
      "Epoch 13: train loss: 0.018990966299304784\n",
      "valid loss: 0.017862880188854707\n",
      "New best score: 0.017862880188854707\n",
      "\n",
      "Epoch 14: train loss: 0.018721194445286\n",
      "valid loss: 0.018141412304057816\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 15: train loss: 0.018500105304915963\n",
      "valid loss: 0.018349668251533734\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 16: train loss: 0.01812279939214765\n",
      "valid loss: 0.017992340957445646\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "lstm_attn,training_execution_time,train_losses,valid_losses = \\\n",
    "    training_loop_and_saving_best_wandb(lstm_attn,\n",
    "                  training_generator,\n",
    "                  valid_generator,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  verbose=True,\n",
    "                  save_path='models/DL/lstm_attention/lstm_attention_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "valid_predictions = get_predictions_sequential(lstm_attn, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.859              0.648     0.685               0.273"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_predictions\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\lstm_attention)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▆▄▄▃▃▃▃▂▃▂▃▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.859</td></tr><tr><td>Average precision</td><td>0.648</td></tr><tr><td>Card Precision@100</td><td>0.273</td></tr><tr><td>F1 score</td><td>0.685</td></tr><tr><td>Prediction execution time</td><td>10.368</td></tr><tr><td>Training execution time</td><td>442.53794</td></tr><tr><td>train loss</td><td>0.01812</td></tr><tr><td>val loss</td><td>0.01799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lyric-firefly-37</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/3a26in9x\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/3a26in9x</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_135322-3a26in9x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "artifact = wandb.Artifact('lstm_attention', type='lstm', description='trained LSTM with 1 lstm layer and 1 hidden dense layer')\n",
    "artifact.add_dir('models/DL/lstm_attention')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN hypertuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudConvNetWithDropout(\n",
       "  (padding1): ConstantPad1d(padding=(1, 0), value=0)\n",
       "  (conv1): Conv1d(15, 100, kernel_size=(2,), stride=(1,))\n",
       "  (padding2): ConstantPad1d(padding=(1, 0), value=0)\n",
       "  (conv2): Conv1d(100, 100, kernel_size=(2,), stride=(1,))\n",
       "  (pooling): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=100, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "training_generator,valid_generator = prepare_generators(training_set, valid_set, batch_size=64)\n",
    "cnn = FraudConvNetWithDropout(x_train.shape[1], hidden_size=500, conv2_params=(100,2), p=0.2).to(DEVICE)\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2630bd20de4812bc9a523cdc10c2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666656966, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221227_142514-35an9489</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/35an9489\" target=\"_blank\">clear-pond-38</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    seq_len=5,\n",
    "    hidden_size = 500,\n",
    "    conv1_num_filters = 100,\n",
    "    conv1_filter_size=2,\n",
    "    conv2_num_filters = 100,\n",
    "    conv2_filter_size=2,\n",
    "    max_pooling=True,\n",
    "    optimizer='adam',\n",
    "    lr=0.001,\n",
    "    dropout=0.2,\n",
    "    early_stopping=False,\n",
    "    max_epochs=10,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['cnn', 'imbalance-not-considered', 'hypertuned'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.039928647961138514\n",
      "valid loss: 0.022087659611674585\n",
      "\n",
      "Epoch 1: train loss: 0.02892241059583999\n",
      "valid loss: 0.023961937860356736\n",
      "\n",
      "Epoch 2: train loss: 0.02733318814218719\n",
      "valid loss: 0.02203040748263348\n",
      "\n",
      "Epoch 3: train loss: 0.026041931413592866\n",
      "valid loss: 0.021224333546022614\n",
      "\n",
      "Epoch 4: train loss: 0.025165783186411095\n",
      "valid loss: 0.021952382443075787\n",
      "\n",
      "Epoch 5: train loss: 0.024826697816024534\n",
      "valid loss: 0.02247233640051401\n",
      "\n",
      "Epoch 6: train loss: 0.02387879006511195\n",
      "valid loss: 0.021559467048847366\n",
      "\n",
      "Epoch 7: train loss: 0.023080084664518073\n",
      "valid loss: 0.02227427572682449\n",
      "\n",
      "Epoch 8: train loss: 0.022720476658469473\n",
      "valid loss: 0.02111525116933642\n",
      "\n",
      "Epoch 9: train loss: 0.021741562783240652\n",
      "valid loss: 0.0225722527006753\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "cnn,training_execution_time,train_losses,valid_losses = \\\n",
    "    training_loop_and_saving_best_wandb(cnn,\n",
    "                  training_generator,\n",
    "                  valid_generator,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  max_epochs=10,\n",
    "                  apply_early_stopping=False,\n",
    "                  verbose=True,\n",
    "                  save_path='models/DL/cnn_hypertuned/cnn_hypertuned_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "valid_predictions = get_predictions_sequential(cnn, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.861               0.58       0.6               0.261"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_predictions\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\cnn_hypertuned)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▄▃▃▂▂▂▂▁▁</td></tr><tr><td>val loss</td><td>▃█▃▁▃▄▂▄▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.861</td></tr><tr><td>Average precision</td><td>0.58</td></tr><tr><td>Card Precision@100</td><td>0.261</td></tr><tr><td>F1 score</td><td>0.6</td></tr><tr><td>Prediction execution time</td><td>9.184</td></tr><tr><td>Training execution time</td><td>245.792</td></tr><tr><td>train loss</td><td>0.02174</td></tr><tr><td>val loss</td><td>0.02257</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">clear-pond-38</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/35an9489\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/35an9489</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_142514-35an9489\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "artifact = wandb.Artifact('cnn_hypertuned', type='cnn', description='hypertuned CNN with 2 conv layers, max pooling and dropout')\n",
    "artifact.add_dir('models/DL/cnn_hypertuned')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM hypertuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudLSTM(\n",
       "  (lstm): LSTM(15, 100, batch_first=True, dropout=0.2)\n",
       "  (fc1): Linear(in_features=100, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "training_generator,valid_generator = prepare_generators(training_set, valid_set, batch_size=128)\n",
    "lstm = FraudLSTM(x_train.shape[1], hidden_size=500, dropout_lstm=0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25855b4d4394863a2637f2d9275f715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221227_145328-3ec2th9e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/3ec2th9e\" target=\"_blank\">pleasant-gorge-40</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    seq_len=5,\n",
    "    hidden_size = 500,\n",
    "    hidden_size_lstm = 100,\n",
    "    num_layers_lstm = 1,\n",
    "    dropout = 0.2,\n",
    "    optimizer='adam',\n",
    "    lr=0.001,\n",
    "    early_stopping=False,\n",
    "    early_stopping_patience=2,\n",
    "    max_epochs=5,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['lstm', 'imbalance-not-considered', 'hypertuned'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.04487916065404907\n",
      "valid loss: 0.021035679431497954\n",
      "\n",
      "Epoch 1: train loss: 0.023487651652975245\n",
      "valid loss: 0.020190327492843517\n",
      "\n",
      "Epoch 2: train loss: 0.022156137640295944\n",
      "valid loss: 0.01939645365051372\n",
      "\n",
      "Epoch 3: train loss: 0.020882145353649916\n",
      "valid loss: 0.01768297026839766\n",
      "\n",
      "Epoch 4: train loss: 0.02023269282264393\n",
      "valid loss: 0.017787850829193118\n"
     ]
    }
   ],
   "source": [
    "lstm,training_execution_time,train_losses,valid_losses = \\\n",
    "    training_loop_and_saving_best_wandb(lstm,\n",
    "                  training_generator,\n",
    "                  valid_generator,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  max_epochs=5,\n",
    "                  apply_early_stopping=False,\n",
    "                  verbose=True,\n",
    "                  save_path='models/DL/lstm_hypertuned/lstm_hypertuned_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "valid_predictions = get_predictions_sequential(lstm, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0     0.86              0.663      0.69                0.28"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_predictions\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\lstm_hypertuned)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▂▂▁▁</td></tr><tr><td>val loss</td><td>█▆▅▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.86</td></tr><tr><td>Average precision</td><td>0.663</td></tr><tr><td>Card Precision@100</td><td>0.28</td></tr><tr><td>F1 score</td><td>0.69</td></tr><tr><td>Prediction execution time</td><td>9.193</td></tr><tr><td>Training execution time</td><td>107.70441</td></tr><tr><td>train loss</td><td>0.02023</td></tr><tr><td>val loss</td><td>0.01779</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pleasant-gorge-40</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/3ec2th9e\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/3ec2th9e</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_145328-3ec2th9e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "artifact = wandb.Artifact('lstm_hypertuned', type='lstm', description='hypertuned LSTM with a dropout')\n",
    "artifact.add_dir('models/DL/lstm_hypertuned')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM with Attention hypertuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudLSTMWithAttention(\n",
       "  (lstm): LSTM(15, 100, batch_first=True, dropout=0.2)\n",
       "  (ff): Linear(in_features=15, out_features=100, bias=True)\n",
       "  (attention): Attention(\n",
       "    (linear_out): Linear(in_features=200, out_features=100, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=100, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "lstm_attn = FraudLSTMWithAttention(x_train.shape[1], hidden_size = 500, dropout_lstm=0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(lstm_attn.parameters(), lr = 0.0001)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "training_generator,valid_generator = prepare_generators(training_set,valid_set,batch_size=128)\n",
    "lstm_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchamera\u001b[0m (\u001b[33mmgr-anomaly-tsxai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480fa4a90100453ca987d569f8b49fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221227_152053-809zrmos</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/809zrmos\" target=\"_blank\">mild-armadillo-42</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    seq_len=5,\n",
    "    hidden_size = 500,\n",
    "    hidden_size_lstm = 100,\n",
    "    num_layers_lstm = 1,\n",
    "    dropout = 0.2,\n",
    "    attention_out_dim=100,\n",
    "    optimizer='adam',\n",
    "    lr=0.0001,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=2,\n",
    "    max_epochs=10,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['lstm', 'imbalance-not-considered', 'attention', 'hypertuned'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.10548595289822604\n",
      "valid loss: 0.021504723847697298\n",
      "\n",
      "Epoch 1: train loss: 0.02578488107811638\n",
      "valid loss: 0.020385841143065374\n",
      "\n",
      "Epoch 2: train loss: 0.024271011042691783\n",
      "valid loss: 0.020096459284660664\n",
      "\n",
      "Epoch 3: train loss: 0.02343763606369061\n",
      "valid loss: 0.019549743625677015\n",
      "\n",
      "Epoch 4: train loss: 0.0227407039727225\n",
      "valid loss: 0.019702040369461767\n",
      "\n",
      "Epoch 5: train loss: 0.022185817820529308\n",
      "valid loss: 0.01921654843870656\n",
      "\n",
      "Epoch 6: train loss: 0.02175957207607166\n",
      "valid loss: 0.019327489653343993\n",
      "\n",
      "Epoch 7: train loss: 0.021197493755246155\n",
      "valid loss: 0.019075061447763872\n",
      "\n",
      "Epoch 8: train loss: 0.020854293203371333\n",
      "valid loss: 0.018955326651824908\n",
      "\n",
      "Epoch 9: train loss: 0.02040450737979014\n",
      "valid loss: 0.018721931482315487\n"
     ]
    }
   ],
   "source": [
    "lstm_attn,training_execution_time,train_losses,valid_losses = \\\n",
    "    training_loop_and_saving_best_wandb(lstm_attn,\n",
    "                  training_generator,\n",
    "                  valid_generator,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  verbose=True,\n",
    "                  max_epochs=10,\n",
    "                  apply_early_stopping=False,\n",
    "                  save_path='models/DL/lstm_attention_hypertuned/lstm_attention_hypertuned_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "valid_predictions = get_predictions_sequential(lstm_attn, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.859               0.64     0.688               0.277"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_predictions\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\lstm_attention_hypertuned)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▅▄▃▃▂▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.859</td></tr><tr><td>Average precision</td><td>0.64</td></tr><tr><td>Card Precision@100</td><td>0.277</td></tr><tr><td>F1 score</td><td>0.688</td></tr><tr><td>Prediction execution time</td><td>9.26</td></tr><tr><td>Training execution time</td><td>224.35897</td></tr><tr><td>train loss</td><td>0.0204</td></tr><tr><td>val loss</td><td>0.01872</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mild-armadillo-42</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/809zrmos\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/809zrmos</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_152053-809zrmos\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "artifact = wandb.Artifact('lstm_attention_hypertuned', type='lstm', description='hypertuned LSTM')\n",
    "artifact.add_dir('models/DL/lstm_attention_hypertuned')\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a11e3a7eb51e2483c16a5d7cdfda12389edc17230fd81a6fc823433cff3faa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
