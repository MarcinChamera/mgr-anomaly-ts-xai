{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "\n",
    "@book{leborgne2022fraud,\n",
    "\n",
    "title={Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook},\n",
    "\n",
    "author={Le Borgne, Yann-A{\\\"e}l and Siblini, Wissam and Lebichot, Bertrand and Bontempi, Gianluca},\n",
    "\n",
    "url={https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook},\n",
    "\n",
    "year={2022},\n",
    "\n",
    "publisher={Universit{\\'e} Libre de Bruxelles}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sklearn\n",
    "import xgboost\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different models on a baseline feature transformation and a simple train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 63257  100 63257    0     0   165k      0 --:--:-- --:--:-- --:--:--  165k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py\n",
    "%run shared_functions.py\n",
    "# missing:\n",
    "# .to('cuda')/.to('cpu') to be added in FraudDataset class in return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 88 ms\n",
      "201295 transactions loaded, containing 1792 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "# 1. create 'fraud-detection-handbook' folder one folder above\n",
    "# 2. cd to the folder\n",
    "# 3. git clone https://github.com/Fraud-Detection-Handbook/simulated-data-transformed\n",
    "DIR_INPUT = '../fraud-detection-handbook/simulated-data-transformed/data/'\n",
    "\n",
    "BEGIN_DATE = \"2018-07-25\"\n",
    "END_DATE = \"2018-08-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201295 entries, 0 to 201294\n",
      "Data columns (total 23 columns):\n",
      " #   Column                               Non-Null Count   Dtype         \n",
      "---  ------                               --------------   -----         \n",
      " 0   TRANSACTION_ID                       201295 non-null  int64         \n",
      " 1   TX_DATETIME                          201295 non-null  datetime64[ns]\n",
      " 2   CUSTOMER_ID                          201295 non-null  int64         \n",
      " 3   TERMINAL_ID                          201295 non-null  int64         \n",
      " 4   TX_AMOUNT                            201295 non-null  float64       \n",
      " 5   TX_TIME_SECONDS                      201295 non-null  int64         \n",
      " 6   TX_TIME_DAYS                         201295 non-null  int64         \n",
      " 7   TX_FRAUD                             201295 non-null  int64         \n",
      " 8   TX_FRAUD_SCENARIO                    201295 non-null  int64         \n",
      " 9   TX_DURING_WEEKEND                    201295 non-null  int64         \n",
      " 10  TX_DURING_NIGHT                      201295 non-null  int64         \n",
      " 11  CUSTOMER_ID_NB_TX_1DAY_WINDOW        201295 non-null  float64       \n",
      " 12  CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW   201295 non-null  float64       \n",
      " 13  CUSTOMER_ID_NB_TX_7DAY_WINDOW        201295 non-null  float64       \n",
      " 14  CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW   201295 non-null  float64       \n",
      " 15  CUSTOMER_ID_NB_TX_30DAY_WINDOW       201295 non-null  float64       \n",
      " 16  CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW  201295 non-null  float64       \n",
      " 17  TERMINAL_ID_NB_TX_1DAY_WINDOW        201295 non-null  float64       \n",
      " 18  TERMINAL_ID_RISK_1DAY_WINDOW         201295 non-null  float64       \n",
      " 19  TERMINAL_ID_NB_TX_7DAY_WINDOW        201295 non-null  float64       \n",
      " 20  TERMINAL_ID_RISK_7DAY_WINDOW         201295 non-null  float64       \n",
      " 21  TERMINAL_ID_NB_TX_30DAY_WINDOW       201295 non-null  float64       \n",
      " 22  TERMINAL_ID_RISK_30DAY_WINDOW        201295 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), int64(9)\n",
      "memory usage: 35.3 MB\n"
     ]
    }
   ],
   "source": [
    "transactions_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns 0-8 : simulator data\n",
    "\n",
    "columns 9+ : baseline feature transformation\n",
    "\n",
    "(11-16 \"keep track of the average spending amount and number of transcations for each customer and for three window sizes\", for example CUSTOMER_ID_NB_TX_7DAY_WINDOW - \"number of transcations by the customer in the last 7 days\")\n",
    "\n",
    "(17-22 \"characterize the 'risk' associated with the terminal. The risk will be defined as the average number of frauds that were observed on the terminal for three window sizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_training = datetime.datetime.strptime(BEGIN_DATE, \"%Y-%m-%d\")\n",
    "delta_train = delta_delay = delta_test = 7\n",
    "\n",
    "end_date_training = start_date_training+datetime.timedelta(days=delta_train-1)\n",
    "\n",
    "start_date_test = start_date_training+datetime.timedelta(days=delta_train+delta_delay)\n",
    "end_date_test = start_date_training+datetime.timedelta(days=delta_train+delta_delay+delta_test-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df, test_df) = get_train_test_set(transactions_df,start_date_training,\n",
    "                                       delta_train=7,delta_delay=7,delta_test=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=[\n",
    "       'TX_AMOUNT',\n",
    "       'TX_DURING_WEEKEND',\n",
    "       'TX_DURING_NIGHT',\n",
    "       'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sklearn.tree.DecisionTreeClassifier(max_depth = 2, random_state=0)\n",
    "\n",
    "model_and_predictions_dictionary = fit_model_and_get_predictions(classifier, train_df, test_df, \n",
    "                                                                 input_features, output_feature,\n",
    "                                                                 scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': DecisionTreeClassifier(max_depth=2, random_state=0),\n",
       " 'predictions_test': array([0.00353643, 0.00353643, 0.00353643, ..., 0.00353643, 0.00353643,\n",
       "        0.00353643]),\n",
       " 'predictions_train': array([0.00353643, 0.00353643, 0.00353643, ..., 0.00353643, 0.00353643,\n",
       "        0.00353643]),\n",
       " 'training_execution_time': 0.09800076484680176,\n",
       " 'prediction_execution_time': 0.01399993896484375}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_and_predictions_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  Card Precision@100\n",
       "0    0.763              0.496               0.241"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df=test_df\n",
    "predictions_df['predictions']=model_and_predictions_dictionary['predictions_test']\n",
    "    \n",
    "performance_assessment(predictions_df, top_k_list=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier, open('models/baseline/dt_maxdepth2_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_dictionary={'Logistic regression':sklearn.linear_model.LogisticRegression(random_state=0), \n",
    "                        'Decision tree with depth of two':sklearn.tree.DecisionTreeClassifier(max_depth=2,random_state=0), \n",
    "                        'Decision tree - unlimited depth':sklearn.tree.DecisionTreeClassifier(random_state=0), \n",
    "                        'Random forest':sklearn.ensemble.RandomForestClassifier(random_state=0,n_jobs=-1),\n",
    "                        'XGBoost':xgboost.XGBClassifier(random_state=0,n_jobs=-1),\n",
    "                       }\n",
    "\n",
    "fitted_models_and_predictions_dictionary={}\n",
    "\n",
    "for classifier_name in classifiers_dictionary:\n",
    "    \n",
    "    model_and_predictions = fit_model_and_get_predictions(classifiers_dictionary[classifier_name], train_df, test_df, \n",
    "                                                                                  input_features=input_features,\n",
    "                                                                                output_feature=output_feature)\n",
    "    fitted_models_and_predictions_dictionary[classifier_name]=model_and_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree with depth of two</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree - unlimited depth</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 AUC ROC  Average precision  \\\n",
       "Logistic regression                0.871              0.606   \n",
       "Decision tree with depth of two    0.763              0.496   \n",
       "Decision tree - unlimited depth    0.788              0.309   \n",
       "Random forest                      0.867              0.658   \n",
       "XGBoost                            0.862              0.639   \n",
       "\n",
       "                                 Card Precision@100  \n",
       "Logistic regression                           0.291  \n",
       "Decision tree with depth of two               0.241  \n",
       "Decision tree - unlimited depth               0.243  \n",
       "Random forest                                 0.287  \n",
       "XGBoost                                       0.273  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary, test_df, \n",
    "                                                        type_set='test', \n",
    "                                                        top_k_list=[100])\n",
    "df_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training execution time</th>\n",
       "      <th>Prediction execution time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.106002</td>\n",
       "      <td>0.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree with depth of two</th>\n",
       "      <td>0.097003</td>\n",
       "      <td>0.010998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree - unlimited depth</th>\n",
       "      <td>0.964999</td>\n",
       "      <td>0.013999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>1.685004</td>\n",
       "      <td>0.090001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>2.293000</td>\n",
       "      <td>0.033001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Training execution time  \\\n",
       "Logistic regression                             0.106002   \n",
       "Decision tree with depth of two                 0.097003   \n",
       "Decision tree - unlimited depth                 0.964999   \n",
       "Random forest                                   1.685004   \n",
       "XGBoost                                         2.293000   \n",
       "\n",
       "                                 Prediction execution time  \n",
       "Logistic regression                               0.009998  \n",
       "Decision tree with depth of two                   0.010998  \n",
       "Decision tree - unlimited depth                   0.013999  \n",
       "Random forest                                     0.090001  \n",
       "XGBoost                                           0.033001  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_execution_times=execution_times_model_collection(fitted_models_and_predictions_dictionary)\n",
    "df_execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifiers_dictionary['Logistic regression'], open('models/baseline/lr_model.sav', 'wb'))\n",
    "pickle.dump(classifiers_dictionary['Decision tree - unlimited depth'], open('models/baseline/dt_maxdepth_unlim_model.sav', 'wb'))\n",
    "pickle.dump(classifiers_dictionary['Random forest'], open('models/baseline/rf_model.sav', 'wb'))\n",
    "pickle.dump(classifiers_dictionary['XGBoost'], open('models/baseline/xgb_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "x_test = torch.FloatTensor(test_df[input_features].values)\n",
    "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "y_test = torch.FloatTensor(test_df[output_feature].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        if self.y is not None:\n",
    "            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)\n",
    "        else:\n",
    "            return self.x[index].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "test_loader_params = {'batch_size': 64,\n",
    "          'num_workers': 0}\n",
    "\n",
    "training_set = FraudDataset(x_train, y_train)\n",
    "\n",
    "testing_set = FraudDataset(x_test, y_test)\n",
    "\n",
    "\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **train_loader_params)\n",
    "testing_generator = torch.utils.data.DataLoader(testing_set, **test_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFraudMLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleFraudMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(relu)\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFraudMLP(len(input_features), 1000).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFraudMLP(\n",
       "  (fc1): Linear(in_features=15, out_features=1000, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.03482447893932093\n",
      "test loss: 0.02212812714421821\n",
      "\n",
      "Epoch 1: train loss: 0.026304942334636153\n",
      "test loss: 0.020956096490620177\n",
      "\n",
      "Epoch 2: train loss: 0.02477469021703899\n",
      "test loss: 0.020735017180904893\n",
      "\n",
      "Epoch 3: train loss: 0.024022467529443717\n",
      "test loss: 0.021015695675631982\n",
      "\n",
      "Epoch 4: train loss: 0.023468064743609875\n",
      "test loss: 0.020646726651373806\n",
      "\n",
      "Epoch 5: train loss: 0.023047099678824123\n",
      "test loss: 0.019709601263545297\n",
      "\n",
      "Epoch 6: train loss: 0.022711212656856803\n",
      "test loss: 0.01983951722781872\n",
      "\n",
      "Epoch 7: train loss: 0.022619226127091996\n",
      "test loss: 0.019601698620699787\n",
      "\n",
      "Epoch 8: train loss: 0.02191990295894263\n",
      "test loss: 0.020056967769849648\n",
      "\n",
      "Epoch 9: train loss: 0.021763283022316962\n",
      "test loss: 0.01953357877695379\n",
      "\n",
      "Epoch 10: train loss: 0.021666503598763796\n",
      "test loss: 0.02038441432545904\n",
      "\n",
      "Epoch 11: train loss: 0.021089430717878988\n",
      "test loss: 0.020437601461248015\n",
      "\n",
      "Epoch 12: train loss: 0.020934559022927998\n",
      "test loss: 0.019799922216856395\n",
      "\n",
      "Epoch 13: train loss: 0.020954489445209248\n",
      "test loss: 0.019475833875250835\n",
      "\n",
      "Epoch 14: train loss: 0.020536611315889106\n",
      "test loss: 0.02022764288693049\n",
      "\n",
      "Epoch 15: train loss: 0.02056483875784658\n",
      "test loss: 0.020707417206386868\n",
      "\n",
      "Epoch 16: train loss: 0.020515442318987494\n",
      "test loss: 0.0194570370436095\n",
      "\n",
      "Epoch 17: train loss: 0.020440912170364006\n",
      "test loss: 0.020088763099417303\n",
      "\n",
      "Epoch 18: train loss: 0.019911137190412598\n",
      "test loss: 0.02025029844236146\n",
      "\n",
      "Epoch 19: train loss: 0.020020016404816952\n",
      "test loss: 0.020314449870204462\n",
      "\n",
      "Epoch 20: train loss: 0.019695228962941038\n",
      "test loss: 0.019234791765951487\n",
      "\n",
      "Epoch 21: train loss: 0.01985108181453185\n",
      "test loss: 0.019125235138556067\n",
      "\n",
      "Epoch 22: train loss: 0.019675522321701354\n",
      "test loss: 0.019474333973599416\n",
      "\n",
      "Epoch 23: train loss: 0.01947619728192414\n",
      "test loss: 0.01915151258300822\n",
      "\n",
      "Epoch 24: train loss: 0.019450293530330776\n",
      "test loss: 0.02018576894598501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changed from 150 for faster results\n",
    "n_epochs = 25\n",
    "model.train()\n",
    "\n",
    "start_time=time.time()\n",
    "epochs_train_losses = []\n",
    "epochs_test_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss=[]\n",
    "    for x_batch, y_batch in training_generator:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    epochs_train_losses.append(np.mean(train_loss))\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n",
    "    \n",
    "    val_loss = evaluate_model(model,testing_generator,criterion)    \n",
    "    epochs_test_losses.append(val_loss)\n",
    "    print('test loss: {}'.format(val_loss))   \n",
    "    print(\"\")\n",
    "    \n",
    "training_execution_time=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341.3051838874817"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model(x_test.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  Card Precision@100\n",
       "0    0.872              0.624                0.28"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df=test_df\n",
    "predictions_df['predictions']=predictions_test.detach().cpu().numpy()\n",
    "    \n",
    "performance_assessment(predictions_df, top_k_list=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/baseline/simple_mlp_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  Card Precision@100\n",
       "0    0.872              0.624                0.28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if saved parameters above can be used to restore\n",
    "# the model and run inference\n",
    "\n",
    "model = SimpleFraudMLP(len(input_features), 1000).to(DEVICE)\n",
    "model.load_state_dict(torch.load('models/baseline/simple_mlp_model.pt'))\n",
    "model.eval()\n",
    "predictions_test = model(x_test.to(DEVICE))\n",
    "predictions_df=test_df\n",
    "predictions_df['predictions']=predictions_test.detach().cpu().numpy()\n",
    "    \n",
    "performance_assessment(predictions_df, top_k_list=[100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a11e3a7eb51e2483c16a5d7cdfda12389edc17230fd81a6fc823433cff3faa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
