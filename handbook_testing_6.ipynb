{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "\n",
    "@book{leborgne2022fraud,\n",
    "\n",
    "title={Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook},\n",
    "\n",
    "author={Le Borgne, Yann-A{\\\"e}l and Siblini, Wissam and Lebichot, Bertrand and Bontempi, Gianluca},\n",
    "\n",
    "url={https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook},\n",
    "\n",
    "year={2022},\n",
    "\n",
    "publisher={Universit{\\'e} Libre de Bruxelles}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covered subchapters:\n",
    "* 7.2.3+ Feed-forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 63257  100 63257    0     0   194k      0 --:--:-- --:--:-- --:--:--  194k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py\n",
    "%run shared_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 406 ms\n",
      "Wall time: 412 ms\n",
      "919767 transactions loaded, containing 8195 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT = '../fraud-detection-handbook/simulated-data-transformed/data/'\n",
    "\n",
    "BEGIN_DATE = \"2018-06-11\"\n",
    "END_DATE = \"2018-09-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
    "\n",
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_training = datetime.datetime.strptime(\"2018-07-25\", \"%Y-%m-%d\")\n",
    "delta_train=7\n",
    "delta_delay=7\n",
    "delta_test=7\n",
    "delta_valid = delta_test\n",
    "\n",
    "start_date_training_with_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "\n",
    "(train_df, valid_df)=get_train_test_set(transactions_df,start_date_training_with_valid,\n",
    "                                       delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_test)\n",
    "\n",
    "(train_df, valid_df)=scaleData(train_df, valid_df, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFraudMLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleFraudMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(relu)\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFraudMLP(len(input_features), 1000).to(DEVICE)\n",
    "\n",
    "x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "x_valid = torch.FloatTensor(valid_df[input_features].values)\n",
    "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "y_valid = torch.FloatTensor(valid_df[output_feature].values)\n",
    "\n",
    "training_set = FraudDataset(x_train, y_train)\n",
    "valid_set = FraudDataset(x_valid, y_valid)\n",
    "\n",
    "training_generator,valid_generator = prepare_generators(training_set,valid_set,batch_size=64)\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_and_saving_best(model,training_generator,valid_generator,optimizer,criterion,max_epochs=100,apply_early_stopping=True,patience=2,verbose=False, save_path='models/DL/not_named_pytorch_model.pt'):\n",
    "    model.train()\n",
    "\n",
    "    if apply_early_stopping:\n",
    "        early_stopping = EarlyStopping(verbose=verbose,patience=patience)\n",
    "    \n",
    "    all_train_losses = []\n",
    "    all_valid_losses = []\n",
    "    \n",
    "    start_time=time.time()\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_loss=[]\n",
    "        for x_batch, y_batch in training_generator:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        all_train_losses.append(np.mean(train_loss))\n",
    "        if verbose:\n",
    "            print('')\n",
    "            print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n",
    "        valid_loss = evaluate_model(model,valid_generator,criterion)\n",
    "        all_valid_losses.append(valid_loss)\n",
    "        if verbose:\n",
    "            print('valid loss: {}'.format(valid_loss))\n",
    "        if apply_early_stopping:\n",
    "            if not early_stopping.continue_training(valid_loss):\n",
    "                if verbose:\n",
    "                    print(\"Early stopping\")\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                break\n",
    "        \n",
    "    training_execution_time=time.time()-start_time\n",
    "    return model,training_execution_time,all_train_losses,all_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.03167143154241159\n",
      "valid loss: 0.02539406170091424\n",
      "New best score: 0.02539406170091424\n",
      "\n",
      "Epoch 1: train loss: 0.03158345085926653\n",
      "valid loss: 0.02534434596163124\n",
      "New best score: 0.02534434596163124\n",
      "\n",
      "Epoch 2: train loss: 0.0314941303123387\n",
      "valid loss: 0.025289974362675934\n",
      "New best score: 0.025289974362675934\n",
      "\n",
      "Epoch 3: train loss: 0.03141030433799637\n",
      "valid loss: 0.02523016636921449\n",
      "New best score: 0.02523016636921449\n",
      "\n",
      "Epoch 4: train loss: 0.03132711604850128\n",
      "valid loss: 0.025154840411323178\n",
      "New best score: 0.025154840411323178\n",
      "\n",
      "Epoch 5: train loss: 0.031242985558833206\n",
      "valid loss: 0.0251122789434539\n",
      "New best score: 0.0251122789434539\n",
      "\n",
      "Epoch 6: train loss: 0.0311668875572017\n",
      "valid loss: 0.02504833714293489\n",
      "New best score: 0.02504833714293489\n",
      "\n",
      "Epoch 7: train loss: 0.031102575351712052\n",
      "valid loss: 0.025012948760976556\n",
      "New best score: 0.025012948760976556\n",
      "\n",
      "Epoch 8: train loss: 0.03101668998765551\n",
      "valid loss: 0.024945566618224717\n",
      "New best score: 0.024945566618224717\n",
      "\n",
      "Epoch 9: train loss: 0.030935536134706714\n",
      "valid loss: 0.02486830353177066\n",
      "New best score: 0.02486830353177066\n",
      "\n",
      "Epoch 10: train loss: 0.030869756633839632\n",
      "valid loss: 0.024842386444155228\n",
      "New best score: 0.024842386444155228\n",
      "\n",
      "Epoch 11: train loss: 0.030798979663605272\n",
      "valid loss: 0.024799344643105656\n",
      "New best score: 0.024799344643105656\n",
      "\n",
      "Epoch 12: train loss: 0.030761785829710432\n",
      "valid loss: 0.02473017731706912\n",
      "New best score: 0.02473017731706912\n",
      "\n",
      "Epoch 13: train loss: 0.03066339739308965\n",
      "valid loss: 0.024669950008086982\n",
      "New best score: 0.024669950008086982\n",
      "\n",
      "Epoch 14: train loss: 0.03059856145153887\n",
      "valid loss: 0.02461986621597507\n",
      "New best score: 0.02461986621597507\n",
      "\n",
      "Epoch 15: train loss: 0.030542353509140002\n",
      "valid loss: 0.024596520550956166\n",
      "New best score: 0.024596520550956166\n",
      "\n",
      "Epoch 16: train loss: 0.030472400189550098\n",
      "valid loss: 0.02456686056468412\n",
      "New best score: 0.02456686056468412\n",
      "\n",
      "Epoch 17: train loss: 0.030411804969917564\n",
      "valid loss: 0.024519681507121017\n",
      "New best score: 0.024519681507121017\n",
      "\n",
      "Epoch 18: train loss: 0.03037606472043538\n",
      "valid loss: 0.024456234670198355\n",
      "New best score: 0.024456234670198355\n",
      "\n",
      "Epoch 19: train loss: 0.030299635837522352\n",
      "valid loss: 0.02440864806562214\n",
      "New best score: 0.02440864806562214\n",
      "\n",
      "Epoch 20: train loss: 0.030236033466332957\n",
      "valid loss: 0.02439994787023774\n",
      "New best score: 0.02439994787023774\n",
      "\n",
      "Epoch 21: train loss: 0.030181658931920593\n",
      "valid loss: 0.024352010870047035\n",
      "New best score: 0.024352010870047035\n",
      "\n",
      "Epoch 22: train loss: 0.030168261502764363\n",
      "valid loss: 0.024328854329670305\n",
      "New best score: 0.024328854329670305\n",
      "\n",
      "Epoch 23: train loss: 0.03011291100840346\n",
      "valid loss: 0.02428148527619495\n",
      "New best score: 0.02428148527619495\n",
      "\n",
      "Epoch 24: train loss: 0.030052352985803457\n",
      "valid loss: 0.024236220402561657\n",
      "New best score: 0.024236220402561657\n",
      "\n",
      "Epoch 25: train loss: 0.02998516734321753\n",
      "valid loss: 0.024215700686527567\n",
      "New best score: 0.024215700686527567\n",
      "\n",
      "Epoch 26: train loss: 0.029912703895823848\n",
      "valid loss: 0.02414388364140209\n",
      "New best score: 0.02414388364140209\n",
      "\n",
      "Epoch 27: train loss: 0.02988470398556498\n",
      "valid loss: 0.024137496704978695\n",
      "New best score: 0.024137496704978695\n",
      "\n",
      "Epoch 28: train loss: 0.029819676307088785\n",
      "valid loss: 0.024102034130708768\n",
      "New best score: 0.024102034130708768\n",
      "\n",
      "Epoch 29: train loss: 0.029769625576848723\n",
      "valid loss: 0.02405533076625297\n",
      "New best score: 0.02405533076625297\n",
      "\n",
      "Epoch 30: train loss: 0.029721745201493354\n",
      "valid loss: 0.02403302631580113\n",
      "New best score: 0.02403302631580113\n",
      "\n",
      "Epoch 31: train loss: 0.02967153643177783\n",
      "valid loss: 0.024025175653275898\n",
      "New best score: 0.024025175653275898\n",
      "\n",
      "Epoch 32: train loss: 0.029633735924474824\n",
      "valid loss: 0.023965430407036768\n",
      "New best score: 0.023965430407036768\n",
      "\n",
      "Epoch 33: train loss: 0.029588717171062234\n",
      "valid loss: 0.023949314896882477\n",
      "New best score: 0.023949314896882477\n",
      "\n",
      "Epoch 34: train loss: 0.029542125610146765\n",
      "valid loss: 0.023909093325835514\n",
      "New best score: 0.023909093325835514\n",
      "\n",
      "Epoch 35: train loss: 0.029501049370455057\n",
      "valid loss: 0.023905988739131658\n",
      "New best score: 0.023905988739131658\n",
      "\n",
      "Epoch 36: train loss: 0.02945884425873311\n",
      "valid loss: 0.023861832721820457\n",
      "New best score: 0.023861832721820457\n",
      "\n",
      "Epoch 37: train loss: 0.029414863796658943\n",
      "valid loss: 0.023818488323379083\n",
      "New best score: 0.023818488323379083\n",
      "\n",
      "Epoch 38: train loss: 0.029374543450778105\n",
      "valid loss: 0.023780227604429008\n",
      "New best score: 0.023780227604429008\n",
      "\n",
      "Epoch 39: train loss: 0.02933483578293205\n",
      "valid loss: 0.023748193443574702\n",
      "New best score: 0.023748193443574702\n",
      "\n",
      "Epoch 40: train loss: 0.029293839177107848\n",
      "valid loss: 0.023715335633758394\n",
      "New best score: 0.023715335633758394\n",
      "\n",
      "Epoch 41: train loss: 0.029258059192382967\n",
      "valid loss: 0.023718903849379774\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 42: train loss: 0.029218293337131822\n",
      "valid loss: 0.023681124059554658\n",
      "New best score: 0.023681124059554658\n",
      "\n",
      "Epoch 43: train loss: 0.02918982229873994\n",
      "valid loss: 0.02364345467725738\n",
      "New best score: 0.02364345467725738\n",
      "\n",
      "Epoch 44: train loss: 0.029165174826769513\n",
      "valid loss: 0.02364742641891938\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 45: train loss: 0.029106542110366545\n",
      "valid loss: 0.023608967447602523\n",
      "New best score: 0.023608967447602523\n",
      "\n",
      "Epoch 46: train loss: 0.029071472307184557\n",
      "valid loss: 0.02360124152352209\n",
      "New best score: 0.02360124152352209\n",
      "\n",
      "Epoch 47: train loss: 0.029035248355156463\n",
      "valid loss: 0.02355295754129403\n",
      "New best score: 0.02355295754129403\n",
      "\n",
      "Epoch 48: train loss: 0.029001016833108937\n",
      "valid loss: 0.023553082766011358\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 49: train loss: 0.02896797061246957\n",
      "valid loss: 0.023513859287260578\n",
      "New best score: 0.023513859287260578\n",
      "\n",
      "Epoch 50: train loss: 0.02895623958161204\n",
      "valid loss: 0.02348664064352182\n",
      "New best score: 0.02348664064352182\n",
      "\n",
      "Epoch 51: train loss: 0.0288992508645766\n",
      "valid loss: 0.023475807019168397\n",
      "New best score: 0.023475807019168397\n",
      "\n",
      "Epoch 52: train loss: 0.028873228444406197\n",
      "valid loss: 0.023443618160290797\n",
      "New best score: 0.023443618160290797\n",
      "\n",
      "Epoch 53: train loss: 0.02887112015202093\n",
      "valid loss: 0.023420069138697586\n",
      "New best score: 0.023420069138697586\n",
      "\n",
      "Epoch 54: train loss: 0.02880601862594165\n",
      "valid loss: 0.023399207773592955\n",
      "New best score: 0.023399207773592955\n",
      "\n",
      "Epoch 55: train loss: 0.028793322054195585\n",
      "valid loss: 0.02339309156475375\n",
      "New best score: 0.02339309156475375\n",
      "\n",
      "Epoch 56: train loss: 0.028741981826827686\n",
      "valid loss: 0.023359239664274813\n",
      "New best score: 0.023359239664274813\n",
      "\n",
      "Epoch 57: train loss: 0.028728439228432913\n",
      "valid loss: 0.023343848063778438\n",
      "New best score: 0.023343848063778438\n",
      "\n",
      "Epoch 58: train loss: 0.02868409038732366\n",
      "valid loss: 0.023318228217686622\n",
      "New best score: 0.023318228217686622\n",
      "\n",
      "Epoch 59: train loss: 0.028655358017680464\n",
      "valid loss: 0.023306635679941765\n",
      "New best score: 0.023306635679941765\n",
      "\n",
      "Epoch 60: train loss: 0.02862467778353359\n",
      "valid loss: 0.02330522142538974\n",
      "New best score: 0.02330522142538974\n",
      "\n",
      "Epoch 61: train loss: 0.028630344951516427\n",
      "valid loss: 0.023291782512904598\n",
      "New best score: 0.023291782512904598\n",
      "\n",
      "Epoch 62: train loss: 0.02856836446234155\n",
      "valid loss: 0.023252962093769772\n",
      "New best score: 0.023252962093769772\n",
      "\n",
      "Epoch 63: train loss: 0.028541093485841232\n",
      "valid loss: 0.02322913285706172\n",
      "New best score: 0.02322913285706172\n",
      "\n",
      "Epoch 64: train loss: 0.028521498169502453\n",
      "valid loss: 0.023211285171399268\n",
      "New best score: 0.023211285171399268\n",
      "\n",
      "Epoch 65: train loss: 0.028486403527787137\n",
      "valid loss: 0.02320374442478184\n",
      "New best score: 0.02320374442478184\n",
      "\n",
      "Epoch 66: train loss: 0.028459269995934705\n",
      "valid loss: 0.023199663112764477\n",
      "New best score: 0.023199663112764477\n",
      "\n",
      "Epoch 67: train loss: 0.028427286926535872\n",
      "valid loss: 0.023202997506876055\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 68: train loss: 0.028408466838968003\n",
      "valid loss: 0.02316219987006746\n",
      "New best score: 0.02316219987006746\n",
      "\n",
      "Epoch 69: train loss: 0.02838202102651132\n",
      "valid loss: 0.02314014100632503\n",
      "New best score: 0.02314014100632503\n",
      "\n",
      "Epoch 70: train loss: 0.028355720034269814\n",
      "valid loss: 0.023105279220105277\n",
      "New best score: 0.023105279220105277\n",
      "\n",
      "Epoch 71: train loss: 0.028331568065752946\n",
      "valid loss: 0.023107386906911196\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 72: train loss: 0.028307057643775786\n",
      "valid loss: 0.02308002892281107\n",
      "New best score: 0.02308002892281107\n",
      "\n",
      "Epoch 73: train loss: 0.02828293847054578\n",
      "valid loss: 0.023063061832160246\n",
      "New best score: 0.023063061832160246\n",
      "\n",
      "Epoch 74: train loss: 0.028301995548100905\n",
      "valid loss: 0.023034631859388997\n",
      "New best score: 0.023034631859388997\n",
      "\n",
      "Epoch 75: train loss: 0.02823611647384793\n",
      "valid loss: 0.023033946983343184\n",
      "New best score: 0.023033946983343184\n",
      "\n",
      "Epoch 76: train loss: 0.02820960248497281\n",
      "valid loss: 0.023015690823670863\n",
      "New best score: 0.023015690823670863\n",
      "\n",
      "Epoch 77: train loss: 0.02822820735177342\n",
      "valid loss: 0.022995779384690964\n",
      "New best score: 0.022995779384690964\n",
      "\n",
      "Epoch 78: train loss: 0.028164569039634976\n",
      "valid loss: 0.022988982460222365\n",
      "New best score: 0.022988982460222365\n",
      "\n",
      "Epoch 79: train loss: 0.028143445321004375\n",
      "valid loss: 0.022980906680999884\n",
      "New best score: 0.022980906680999884\n",
      "\n",
      "Epoch 80: train loss: 0.028120740669615653\n",
      "valid loss: 0.022963124144150585\n",
      "New best score: 0.022963124144150585\n",
      "\n",
      "Epoch 81: train loss: 0.028097005928937796\n",
      "valid loss: 0.02295886581443006\n",
      "New best score: 0.02295886581443006\n",
      "\n",
      "Epoch 82: train loss: 0.028107523660613563\n",
      "valid loss: 0.022933925350344248\n",
      "New best score: 0.022933925350344248\n",
      "\n",
      "Epoch 83: train loss: 0.02805330855041799\n",
      "valid loss: 0.022941174199346635\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 84: train loss: 0.028033730023260983\n",
      "valid loss: 0.02290862282824606\n",
      "New best score: 0.02290862282824606\n",
      "\n",
      "Epoch 85: train loss: 0.028010252398397793\n",
      "valid loss: 0.02287995394426169\n",
      "New best score: 0.02287995394426169\n",
      "\n",
      "Epoch 86: train loss: 0.02799089005360305\n",
      "valid loss: 0.022878368884895018\n",
      "New best score: 0.022878368884895018\n",
      "\n",
      "Epoch 87: train loss: 0.027968363768739863\n",
      "valid loss: 0.02288403296894063\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 88: train loss: 0.027957315701612025\n",
      "valid loss: 0.022872019283056176\n",
      "New best score: 0.022872019283056176\n",
      "\n",
      "Epoch 89: train loss: 0.02793066676690049\n",
      "valid loss: 0.022846142066734246\n",
      "New best score: 0.022846142066734246\n",
      "\n",
      "Epoch 90: train loss: 0.02790666954172508\n",
      "valid loss: 0.022842820064811024\n",
      "New best score: 0.022842820064811024\n",
      "\n",
      "Epoch 91: train loss: 0.02788997377468412\n",
      "valid loss: 0.022816205226505796\n",
      "New best score: 0.022816205226505796\n",
      "\n",
      "Epoch 92: train loss: 0.027874513992453866\n",
      "valid loss: 0.022798322844497166\n",
      "New best score: 0.022798322844497166\n",
      "\n",
      "Epoch 93: train loss: 0.027850455066712704\n",
      "valid loss: 0.022788648236583654\n",
      "New best score: 0.022788648236583654\n",
      "\n",
      "Epoch 94: train loss: 0.027838252301160497\n",
      "valid loss: 0.022783115102599064\n",
      "New best score: 0.022783115102599064\n",
      "\n",
      "Epoch 95: train loss: 0.0278105862967556\n",
      "valid loss: 0.02277629012827217\n",
      "New best score: 0.02277629012827217\n",
      "\n",
      "Epoch 96: train loss: 0.02779150930995453\n",
      "valid loss: 0.022770014945977454\n",
      "New best score: 0.022770014945977454\n",
      "\n",
      "Epoch 97: train loss: 0.02777388142412938\n",
      "valid loss: 0.02276040838619114\n",
      "New best score: 0.02276040838619114\n",
      "\n",
      "Epoch 98: train loss: 0.0277607109765816\n",
      "valid loss: 0.022739400572901785\n",
      "New best score: 0.022739400572901785\n",
      "\n",
      "Epoch 99: train loss: 0.027769561272459976\n",
      "valid loss: 0.022731825593818245\n",
      "New best score: 0.022731825593818245\n",
      "\n",
      "Epoch 100: train loss: 0.027746890490139207\n",
      "valid loss: 0.022696702092214197\n",
      "New best score: 0.022696702092214197\n",
      "\n",
      "Epoch 101: train loss: 0.02770425281135711\n",
      "valid loss: 0.022696333665838415\n",
      "New best score: 0.022696333665838415\n",
      "\n",
      "Epoch 102: train loss: 0.027682979831366975\n",
      "valid loss: 0.022688032137586283\n",
      "New best score: 0.022688032137586283\n",
      "\n",
      "Epoch 103: train loss: 0.027663122309660306\n",
      "valid loss: 0.022676721936895874\n",
      "New best score: 0.022676721936895874\n",
      "\n",
      "Epoch 104: train loss: 0.027673497172802628\n",
      "valid loss: 0.02266534680571875\n",
      "New best score: 0.02266534680571875\n",
      "\n",
      "Epoch 105: train loss: 0.027660985439650742\n",
      "valid loss: 0.022641105037386137\n",
      "New best score: 0.022641105037386137\n",
      "\n",
      "Epoch 106: train loss: 0.027610826868088436\n",
      "valid loss: 0.02264156349848121\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 107: train loss: 0.027594398654619833\n",
      "valid loss: 0.022624642144165975\n",
      "New best score: 0.022624642144165975\n",
      "\n",
      "Epoch 108: train loss: 0.02757786421072322\n",
      "valid loss: 0.02261701847625072\n",
      "New best score: 0.02261701847625072\n",
      "\n",
      "Epoch 109: train loss: 0.02756013684856205\n",
      "valid loss: 0.02261151064523175\n",
      "New best score: 0.02261151064523175\n",
      "\n",
      "Epoch 110: train loss: 0.02754466035016002\n",
      "valid loss: 0.022605131348198065\n",
      "New best score: 0.022605131348198065\n",
      "\n",
      "Epoch 111: train loss: 0.027528121782311846\n",
      "valid loss: 0.02258966121837863\n",
      "New best score: 0.02258966121837863\n",
      "\n",
      "Epoch 112: train loss: 0.027506847167387605\n",
      "valid loss: 0.022550407636025158\n",
      "New best score: 0.022550407636025158\n",
      "\n",
      "Epoch 113: train loss: 0.027495013380531813\n",
      "valid loss: 0.022548701407011252\n",
      "New best score: 0.022548701407011252\n",
      "\n",
      "Epoch 114: train loss: 0.02747589406440743\n",
      "valid loss: 0.022566092456818197\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 115: train loss: 0.027462322199022678\n",
      "valid loss: 0.02254677699965328\n",
      "New best score: 0.02254677699965328\n",
      "\n",
      "Epoch 116: train loss: 0.02744506716943679\n",
      "valid loss: 0.022532410069516368\n",
      "New best score: 0.022532410069516368\n",
      "\n",
      "Epoch 117: train loss: 0.02742722122079691\n",
      "valid loss: 0.022526203170724093\n",
      "New best score: 0.022526203170724093\n",
      "\n",
      "Epoch 118: train loss: 0.027442557816251215\n",
      "valid loss: 0.022502985794117542\n",
      "New best score: 0.022502985794117542\n",
      "\n",
      "Epoch 119: train loss: 0.027397962735812704\n",
      "valid loss: 0.022481014866310635\n",
      "New best score: 0.022481014866310635\n",
      "\n",
      "Epoch 120: train loss: 0.02738268362437455\n",
      "valid loss: 0.022484444089926007\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 121: train loss: 0.027365705848895867\n",
      "valid loss: 0.022470580480860473\n",
      "New best score: 0.022470580480860473\n",
      "\n",
      "Epoch 122: train loss: 0.027353840515268592\n",
      "valid loss: 0.022460598856862125\n",
      "New best score: 0.022460598856862125\n",
      "\n",
      "Epoch 123: train loss: 0.027366163806293524\n",
      "valid loss: 0.022452736111571555\n",
      "New best score: 0.022452736111571555\n",
      "\n",
      "Epoch 124: train loss: 0.02732089553188611\n",
      "valid loss: 0.022452373575174905\n",
      "New best score: 0.022452373575174905\n",
      "\n",
      "Epoch 125: train loss: 0.02730698916721861\n",
      "valid loss: 0.022429476570734967\n",
      "New best score: 0.022429476570734967\n",
      "\n",
      "Epoch 126: train loss: 0.027318789055846972\n",
      "valid loss: 0.022408401953117524\n",
      "New best score: 0.022408401953117524\n",
      "\n",
      "Epoch 127: train loss: 0.02727516283535792\n",
      "valid loss: 0.022420316582667778\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 128: train loss: 0.027261605347154116\n",
      "valid loss: 0.022404949119965968\n",
      "New best score: 0.022404949119965968\n",
      "\n",
      "Epoch 129: train loss: 0.027246109120027798\n",
      "valid loss: 0.02239830241350284\n",
      "New best score: 0.02239830241350284\n",
      "\n",
      "Epoch 130: train loss: 0.027231873082750286\n",
      "valid loss: 0.022394876161213616\n",
      "New best score: 0.022394876161213616\n",
      "\n",
      "Epoch 131: train loss: 0.02721763749844635\n",
      "valid loss: 0.02238623084897389\n",
      "New best score: 0.02238623084897389\n",
      "\n",
      "Epoch 132: train loss: 0.027202890237862775\n",
      "valid loss: 0.022365890997283852\n",
      "New best score: 0.022365890997283852\n",
      "\n",
      "Epoch 133: train loss: 0.027187879885107024\n",
      "valid loss: 0.0223476106901475\n",
      "New best score: 0.0223476106901475\n",
      "\n",
      "Epoch 134: train loss: 0.027198267207359877\n",
      "valid loss: 0.022335007293098938\n",
      "New best score: 0.022335007293098938\n",
      "\n",
      "Epoch 135: train loss: 0.02716058228422227\n",
      "valid loss: 0.022343791933740424\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 136: train loss: 0.027145387040785948\n",
      "valid loss: 0.022330311067463433\n",
      "New best score: 0.022330311067463433\n",
      "\n",
      "Epoch 137: train loss: 0.02713221773312892\n",
      "valid loss: 0.022327315109868438\n",
      "New best score: 0.022327315109868438\n",
      "\n",
      "Epoch 138: train loss: 0.027118264714631662\n",
      "valid loss: 0.022315089470996963\n",
      "New best score: 0.022315089470996963\n",
      "\n",
      "Epoch 139: train loss: 0.027102012267152833\n",
      "valid loss: 0.02232874165813291\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 140: train loss: 0.027091853275857725\n",
      "valid loss: 0.022311339317439276\n",
      "New best score: 0.022311339317439276\n",
      "\n",
      "Epoch 141: train loss: 0.027078178445461346\n",
      "valid loss: 0.022297913746531707\n",
      "New best score: 0.022297913746531707\n",
      "\n",
      "Epoch 142: train loss: 0.02706440572758663\n",
      "valid loss: 0.022279548732553674\n",
      "New best score: 0.022279548732553674\n",
      "\n",
      "Epoch 143: train loss: 0.02704941172083309\n",
      "valid loss: 0.022268628977147525\n",
      "New best score: 0.022268628977147525\n",
      "\n",
      "Epoch 144: train loss: 0.027035253572528808\n",
      "valid loss: 0.022272882370858407\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 145: train loss: 0.027018840889264803\n",
      "valid loss: 0.022283012217134645\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 146: train loss: 0.027048328090067346\n",
      "valid loss: 0.02225388330152981\n",
      "New best score: 0.02225388330152981\n",
      "\n",
      "Epoch 147: train loss: 0.02699671753964442\n",
      "valid loss: 0.022252848937527322\n",
      "New best score: 0.022252848937527322\n",
      "\n",
      "Epoch 148: train loss: 0.027014442260535593\n",
      "valid loss: 0.022261941028107468\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 149: train loss: 0.026971548677281427\n",
      "valid loss: 0.02224179826666667\n",
      "New best score: 0.02224179826666667\n",
      "\n",
      "Epoch 150: train loss: 0.02698101422813566\n",
      "valid loss: 0.02221913063832523\n",
      "New best score: 0.02221913063832523\n",
      "\n",
      "Epoch 151: train loss: 0.026944022642156503\n",
      "valid loss: 0.0222283787091512\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 152: train loss: 0.02693226879411849\n",
      "valid loss: 0.022196607274904114\n",
      "New best score: 0.022196607274904114\n",
      "\n",
      "Epoch 153: train loss: 0.026919060635351957\n",
      "valid loss: 0.022177264756456913\n",
      "New best score: 0.022177264756456913\n",
      "\n",
      "Epoch 154: train loss: 0.02690653067084838\n",
      "valid loss: 0.022172344156892086\n",
      "New best score: 0.022172344156892086\n",
      "\n",
      "Epoch 155: train loss: 0.026894323637550538\n",
      "valid loss: 0.02216818330114799\n",
      "New best score: 0.02216818330114799\n",
      "\n",
      "Epoch 156: train loss: 0.026875920213107196\n",
      "valid loss: 0.022198024142630234\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 157: train loss: 0.02686300247896064\n",
      "valid loss: 0.022140801648604252\n",
      "New best score: 0.022140801648604252\n",
      "\n",
      "Epoch 158: train loss: 0.026878775853127684\n",
      "valid loss: 0.022138196099651317\n",
      "New best score: 0.022138196099651317\n",
      "\n",
      "Epoch 159: train loss: 0.026844324193045454\n",
      "valid loss: 0.022142655272138576\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 160: train loss: 0.02682839084374781\n",
      "valid loss: 0.022162197181278116\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 161: train loss: 0.026821632019910127\n",
      "valid loss: 0.022135663304803637\n",
      "New best score: 0.022135663304803637\n",
      "\n",
      "Epoch 162: train loss: 0.026806018502009858\n",
      "valid loss: 0.022134163149230467\n",
      "New best score: 0.022134163149230467\n",
      "\n",
      "Epoch 163: train loss: 0.026794641589644376\n",
      "valid loss: 0.022134003302723658\n",
      "New best score: 0.022134003302723658\n",
      "\n",
      "Epoch 164: train loss: 0.026789386342920676\n",
      "valid loss: 0.02211386844760082\n",
      "New best score: 0.02211386844760082\n",
      "\n",
      "Epoch 165: train loss: 0.02677250487429854\n",
      "valid loss: 0.02210026236436752\n",
      "New best score: 0.02210026236436752\n",
      "\n",
      "Epoch 166: train loss: 0.026782621035884788\n",
      "valid loss: 0.022101374592026442\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 167: train loss: 0.026809486851450518\n",
      "valid loss: 0.022089391399576976\n",
      "New best score: 0.022089391399576976\n",
      "\n",
      "Epoch 168: train loss: 0.02673474576766736\n",
      "valid loss: 0.022077306410771047\n",
      "New best score: 0.022077306410771047\n",
      "\n",
      "Epoch 169: train loss: 0.02672372996027138\n",
      "valid loss: 0.022061748387892554\n",
      "New best score: 0.022061748387892554\n",
      "\n",
      "Epoch 170: train loss: 0.026710008503646583\n",
      "valid loss: 0.022041827330335242\n",
      "New best score: 0.022041827330335242\n",
      "\n",
      "Epoch 171: train loss: 0.026701671393440384\n",
      "valid loss: 0.022063401873768027\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 172: train loss: 0.026687572045335423\n",
      "valid loss: 0.022062777425544185\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 173: train loss: 0.026675762322617348\n",
      "valid loss: 0.022065531079214617\n",
      "3  iterations since best score.\n",
      "Early stopping on epoch  173\n"
     ]
    }
   ],
   "source": [
    "model,training_execution_time,train_losses,valid_losses = training_loop_and_saving_best(model,training_generator,valid_generator,optimizer,criterion,\n",
    "                                                            max_epochs=500,verbose=True, save_path='models/DL/simple_mlp_model_earlystop2.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.04549537295561077\n",
      "valid loss: 0.022971050099271244\n",
      "New best score: 0.022971050099271244\n",
      "\n",
      "Epoch 1: train loss: 0.02667415100212136\n",
      "valid loss: 0.020753496100545908\n",
      "New best score: 0.020753496100545908\n",
      "\n",
      "Epoch 2: train loss: 0.024774995586170634\n",
      "valid loss: 0.022122189733886816\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 3: train loss: 0.02355040387579028\n",
      "valid loss: 0.02112830007306295\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 4: train loss: 0.022702795966108993\n",
      "valid loss: 0.019787302717714075\n",
      "New best score: 0.019787302717714075\n",
      "\n",
      "Epoch 5: train loss: 0.022256823705244868\n",
      "valid loss: 0.019103717567689228\n",
      "New best score: 0.019103717567689228\n",
      "\n",
      "Epoch 6: train loss: 0.02177833071148582\n",
      "valid loss: 0.019241891345365452\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 7: train loss: 0.021255694936077693\n",
      "valid loss: 0.01938037621811582\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 8: train loss: 0.020836039317191274\n",
      "valid loss: 0.018438583379356912\n",
      "New best score: 0.018438583379356912\n",
      "\n",
      "Epoch 9: train loss: 0.020573974778897077\n",
      "valid loss: 0.01818423560945205\n",
      "New best score: 0.01818423560945205\n",
      "\n",
      "Epoch 10: train loss: 0.020246188380790207\n",
      "valid loss: 0.018366772427014965\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 11: train loss: 0.02004075480851409\n",
      "valid loss: 0.018197192785157083\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 12: train loss: 0.019745771986513398\n",
      "valid loss: 0.017979401976628423\n",
      "New best score: 0.017979401976628423\n",
      "\n",
      "Epoch 13: train loss: 0.019671222302207036\n",
      "valid loss: 0.019537477959914368\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 14: train loss: 0.019153262812748414\n",
      "valid loss: 0.01860247150971936\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 15: train loss: 0.019063464651818265\n",
      "valid loss: 0.017768161506404784\n",
      "New best score: 0.017768161506404784\n",
      "\n",
      "Epoch 16: train loss: 0.01879843701693064\n",
      "valid loss: 0.019586353749800167\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 17: train loss: 0.018611342217693064\n",
      "valid loss: 0.017331625993841943\n",
      "New best score: 0.017331625993841943\n",
      "\n",
      "Epoch 18: train loss: 0.018442325376042738\n",
      "valid loss: 0.01865265529922113\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 19: train loss: 0.018113323202424363\n",
      "valid loss: 0.01778764151389166\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 20: train loss: 0.01792847909966847\n",
      "valid loss: 0.018735417481728123\n",
      "3  iterations since best score.\n",
      "Early stopping on epoch  20\n"
     ]
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "model = SimpleFraudMLP(len(input_features), 1000).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "model,training_execution_time,train_losses_adam,valid_losses_adam = training_loop_and_saving_best(model,training_generator,valid_generator,optimizer,criterion,verbose=True,\n",
    "                                                                        save_path='models/DL/simple_mlp_model_adam.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "model = SimpleFraudMLPWithDropout(len(input_features), 1000,0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "model,training_execution_time,train_losses_dropout,valid_losses_dropout = training_loop_and_saving_best(model,training_generator,valid_generator,optimizer,criterion,verbose=False,\n",
    "                                                                                                        save_path='models/DL/simple_mlp_model_dropout.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TX_AMOUNT',\n",
       " 'TX_DURING_WEEKEND',\n",
       " 'TX_DURING_NIGHT',\n",
       " 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
       " 'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW',\n",
       " 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
       " 'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW',\n",
       " 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
       " 'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW',\n",
       " 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
       " 'TERMINAL_ID_RISK_1DAY_WINDOW',\n",
       " 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
       " 'TERMINAL_ID_RISK_7DAY_WINDOW',\n",
       " 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
       " 'TERMINAL_ID_RISK_30DAY_WINDOW']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekday(tx_datetime):\n",
    "    \n",
    "    # Transform date into weekday (0 is Monday, 6 is Sunday)\n",
    "    weekday = tx_datetime.weekday()\n",
    "    \n",
    "    return int(weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TX_WEEKDAY'] = train_df.TX_DATETIME.apply(weekday)\n",
    "valid_df['TX_WEEKDAY'] = valid_df.TX_DATETIME.apply(weekday)\n",
    "input_categorical_features = ['TX_WEEKDAY','TERMINAL_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudMLPWithEmbedding(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, categorical_inputs_modalities,numerical_inputs_size,embedding_sizes, hidden_size,p):\n",
    "            super(FraudMLPWithEmbedding, self).__init__()\n",
    "            self.categorical_inputs_modalities = categorical_inputs_modalities\n",
    "            self.numerical_inputs_size = numerical_inputs_size\n",
    "            self.embedding_sizes = embedding_sizes\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.p = p\n",
    "            \n",
    "            assert len(categorical_inputs_modalities)==len(embedding_sizes), 'categorical_inputs_modalities and embedding_sizes must have the same length'\n",
    "            \n",
    "            #embedding layers\n",
    "            self.emb = []\n",
    "            for i in range(len(categorical_inputs_modalities)):\n",
    "                self.emb.append(torch.nn.Embedding(int(categorical_inputs_modalities[i]), int(embedding_sizes[i])).to(DEVICE))\n",
    "                \n",
    "            \n",
    "            #contenated inputs to hidden\n",
    "            self.fc1 = torch.nn.Linear(self.numerical_inputs_size+int(np.sum(embedding_sizes)), self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            #hidden to output\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            \n",
    "            self.dropout = torch.nn.Dropout(self.p)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            #we assume that x start with numerical features then categorical features\n",
    "            inputs = [x[:,:self.numerical_inputs_size]]\n",
    "            for i in range(len(self.categorical_inputs_modalities)):\n",
    "                inputs.append(self.emb[i](x[:,self.numerical_inputs_size+i].to(torch.int64)))\n",
    "            \n",
    "            x = torch.cat(inputs,axis=1)\n",
    "            \n",
    "            \n",
    "            hidden = self.fc1(x)\n",
    "            hidden = self.relu(hidden)\n",
    "            \n",
    "            hidden = self.dropout(hidden)\n",
    "            \n",
    "            output = self.fc2(hidden)\n",
    "            output = self.sigmoid(output)\n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_generators_with_categorical_features(train_df,valid_df,input_categorical_features,batch_size=64):\n",
    "    x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "    x_valid = torch.FloatTensor(valid_df[input_features].values)\n",
    "    y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "    y_valid = torch.FloatTensor(valid_df[output_feature].values)\n",
    "    \n",
    "    #categorical variables : encoding valid according to train\n",
    "    encoder = sklearn.preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "    x_train_cat = encoder.fit_transform(train_df[input_categorical_features].values) + 1\n",
    "    categorical_inputs_modalities = np.max(x_train_cat,axis=0)+1\n",
    "    \n",
    "    x_train_cat = torch.IntTensor(x_train_cat)\n",
    "    x_valid_cat = torch.IntTensor(encoder.transform(valid_df[input_categorical_features].values) + 1)\n",
    "    \n",
    "    x_train = torch.cat([x_train,x_train_cat],axis=1)\n",
    "    x_valid = torch.cat([x_valid,x_valid_cat],axis=1)\n",
    "    \n",
    "    train_loader_params = {'batch_size': batch_size,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 0}\n",
    "    valid_loader_params = {'batch_size': batch_size,\n",
    "              'num_workers': 0}\n",
    "    \n",
    "    training_set = FraudDataset(x_train, y_train)\n",
    "    valid_set = FraudDataset(x_valid, y_valid)\n",
    "    \n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **train_loader_params)\n",
    "    valid_generator = torch.utils.data.DataLoader(valid_set, **valid_loader_params)\n",
    "    \n",
    "    return training_generator,valid_generator, categorical_inputs_modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "training_generator,valid_generator,categorical_inputs_modalities = prepare_generators_with_categorical_features(train_df,valid_df,input_categorical_features,batch_size=64)\n",
    "\n",
    "embedding_sizes = [10]*len(categorical_inputs_modalities)\n",
    "\n",
    "model = FraudMLPWithEmbedding(categorical_inputs_modalities,len(input_features),embedding_sizes, 1000,0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "model,training_execution_time,train_losses_embedding,valid_losses_embedding = training_loop_and_saving_best(model,training_generator,valid_generator,optimizer,criterion,verbose=False,\n",
    "                                                                                            save_path='models/DL/simple_mlp_model_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prequential grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudMLP(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, hidden_size=100,num_layers=1,p=0, input_size=len(input_features)):\n",
    "            super(FraudMLP, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.p = p\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            \n",
    "            self.fc_hidden=[]\n",
    "            for _ in range(num_layers-1):\n",
    "                self.fc_hidden.append(torch.nn.Linear(self.hidden_size, self.hidden_size))\n",
    "                self.fc_hidden.append(torch.nn.ReLU())\n",
    "                \n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 2)\n",
    "            self.softmax = torch.nn.Softmax()\n",
    "            \n",
    "            self.dropout = torch.nn.Dropout(self.p)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            hidden = self.fc1(x)\n",
    "            hidden = self.relu(hidden)             \n",
    "            hidden = self.dropout(hidden)\n",
    "            \n",
    "            for layer in self.fc_hidden:\n",
    "                hidden=layer(hidden)\n",
    "                hidden = self.dropout(hidden)\n",
    "            \n",
    "            output = self.fc2(hidden)\n",
    "            output = self.softmax(output)\n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDatasetForPipe(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        'Initialization'\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = None\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y.values)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        if self.y is not None:\n",
    "            # DON'T ADD .to(DEVICE) BELOW!!!\n",
    "            # it will slow down training process more than 10 times\n",
    "            # return self.x[index].to(DEVICE), self.y[index].to(DEVICE)\n",
    "            return self.x[index], self.y[index]\n",
    "        else:\n",
    "            return self.x[index], -1       \n",
    "            # return self.x[index].to(DEVICE), -1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.FraudMLP'>,\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    FraudMLP,\n",
    "    max_epochs=2,\n",
    "    lr=0.001,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    batch_size=64,\n",
    "    dataset=FraudDatasetForPipe,\n",
    "    iterator_train__shuffle=True,\n",
    "    # device=DEVICE\n",
    ")\n",
    "net.set_params(train_split=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns that are needed as argument to custom scoring function\n",
    "# to reduce serialization time of transaction dataset\n",
    "transactions_df_scorer=transactions_df[['CUSTOMER_ID', 'TX_FRAUD','TX_TIME_DAYS']]\n",
    "\n",
    "card_precision_top_100 = sklearn.metrics.make_scorer(card_precision_top_k_custom, \n",
    "                                                     needs_proba=True, \n",
    "                                                     top_k=100, \n",
    "                                                     transactions_df=transactions_df_scorer)\n",
    "\n",
    "n_folds=4\n",
    "start_date_training_for_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "start_date_training_for_test = start_date_training+datetime.timedelta(days=(n_folds-1)*delta_test)\n",
    "delta_assessment = delta_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing performance before the proper hp search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Total execution time: 82.48s\n"
     ]
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "start_time=time.time()\n",
    "\n",
    "parameters = {\n",
    "    'clf__lr': [0.001 ],\n",
    "    'clf__batch_size': [64],\n",
    "    'clf__max_epochs': [10, 20],\n",
    "    'clf__module__hidden_size': [100],\n",
    "    'clf__module__num_layers': [1,2],\n",
    "    'clf__module__p': [0],\n",
    "}\n",
    "\n",
    "scoring = {'roc_auc':'roc_auc',\n",
    "           'average_precision': 'average_precision',\n",
    "           'card_precision@100': card_precision_top_100,\n",
    "           }\n",
    "\n",
    "\n",
    "performance_metrics_list_grid=['roc_auc', 'average_precision', 'card_precision@100']\n",
    "performance_metrics_list=['AUC ROC', 'Average precision', 'Card Precision@100']\n",
    "\n",
    "performances_df_validation=prequential_grid_search(\n",
    "    transactions_df, net, \n",
    "    input_features, output_feature,\n",
    "    parameters, scoring, \n",
    "    start_date_training=start_date_training_with_valid,\n",
    "    n_folds=n_folds,\n",
    "    expe_type='Validation',\n",
    "    delta_train=delta_train, \n",
    "    delta_delay=delta_delay, \n",
    "    delta_assessment=delta_valid,\n",
    "    performance_metrics_list_grid=performance_metrics_list_grid,\n",
    "    performance_metrics_list=performance_metrics_list)\n",
    "\n",
    "print(\"Validation: Total execution time: \"+str(round(time.time()-start_time,2))+\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My execution time on GPU: ~70-80s\n",
    "\n",
    "Handbook's execution time: 37.16s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'clf__lr': [0.001 , 0.0001, 0.0002],\n",
    "    'clf__batch_size': [64,128,256],\n",
    "    'clf__max_epochs': [10,20,40],\n",
    "    'clf__module__hidden_size': [500],\n",
    "    'clf__module__num_layers': [1,2],\n",
    "    'clf__module__p': [0,0.2,0.4],\n",
    "    'clf__module__input_size': [int(len(input_features))],\n",
    "}\n",
    "\n",
    "scoring = {'roc_auc':'roc_auc',\n",
    "           'average_precision': 'average_precision',\n",
    "           'card_precision@100': card_precision_top_100,\n",
    "           }\n",
    "           \n",
    "performance_metrics_list_grid=['roc_auc', 'average_precision', 'card_precision@100']\n",
    "performance_metrics_list=['AUC ROC', 'Average precision', 'Card Precision@100']\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "performances_df=model_selection_wrapper(transactions_df, net, \n",
    "                                        input_features, output_feature,\n",
    "                                        parameters, scoring, \n",
    "                                        start_date_training_for_valid,\n",
    "                                        start_date_training_for_test,\n",
    "                                        n_folds=n_folds,\n",
    "                                        delta_train=delta_train, \n",
    "                                        delta_delay=delta_delay, \n",
    "                                        delta_assessment=delta_assessment,\n",
    "                                        performance_metrics_list_grid=performance_metrics_list_grid,\n",
    "                                        performance_metrics_list=performance_metrics_list,\n",
    "                                        n_jobs=1)\n",
    "\n",
    "\n",
    "execution_time_nn = time.time()-start_time\n",
    "\n",
    "parameters_dict=dict(performances_df['Parameters'])\n",
    "performances_df['Parameters summary']=[str(parameters_dict[i]['clf__lr'])+\n",
    "                                   '/'+\n",
    "                                   str(parameters_dict[i]['clf__batch_size'])+\n",
    "                                   '/'+\n",
    "                                   str(parameters_dict[i]['clf__max_epochs'])+\n",
    "                                   '/'+\n",
    "                                   str(parameters_dict[i]['clf__module__p'])+\n",
    "                                   '/'+\n",
    "                                   str(parameters_dict[i]['clf__module__num_layers'])\n",
    "                                   for i in range(len(parameters_dict))]\n",
    "\n",
    "performances_df_nn=performances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above search in the handbook took ~120min\n",
    "\n",
    "my execution didn't finalize for over 600min...\n",
    "\n",
    "nvidia-smi shows around 20% GPU usage of kernel\n",
    "\n",
    "task manager shows ~90% of GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_df_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_performances_nn=get_summary_performances(performances_df_nn, parameter_column_name=\"Parameters summary\")\n",
    "summary_performances_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict=dict(performances_df_nn['Parameters'])\n",
    "performances_df_nn['Parameters summary']=[\n",
    "                                   str(parameters_dict[i]['clf__batch_size'])+\n",
    "                                   '/'+\n",
    "                                   str(parameters_dict[i]['clf__max_epochs'])+\n",
    "                                   '/'+\n",
    "                                   str(parameters_dict[i]['clf__module__p'])\n",
    "    \n",
    "                                   for i in range(len(parameters_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_df_nn_subset = performances_df_nn[performances_df_nn['Parameters'].apply(lambda x:x['clf__lr']== 0.001 and x['clf__module__hidden_size']==500 and x['clf__module__num_layers']==2 and x['clf__module__p']==0.2 and x['clf__max_epochs']==20).values]\n",
    "summary_performances_nn_subset=get_summary_performances(performances_df_nn_subset, parameter_column_name=\"Parameters summary\")\n",
    "indexes_summary = summary_performances_nn_subset.index.values\n",
    "indexes_summary[0] = 'Best estimated parameters'\n",
    "summary_performances_nn_subset.rename(index = dict(zip(np.arange(len(indexes_summary)),indexes_summary)))\n",
    "get_performances_plots(performances_df_nn_subset, \n",
    "                       performance_metrics_list=['AUC ROC', 'Average precision', 'Card Precision@100'], \n",
    "                       expe_type_list=['Test','Validation'], expe_type_color_list=['#008000','#FF0000'],\n",
    "                       parameter_name=\"batch size\",\n",
    "                       summary_performances=summary_performances_nn_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDatasetCUDA(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        if self.y is not None:\n",
    "            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)\n",
    "        else:\n",
    "            return self.x[index].to(DEVICE)\n",
    "\n",
    "(train_df, test_df) = get_train_test_set(transactions_df,start_date_training,\n",
    "                                       delta_train=7,delta_delay=7,delta_test=7)\n",
    "(train_df, test_df)=scaleData(train_df, test_df, input_features)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "x_test = torch.FloatTensor(test_df[input_features].values)\n",
    "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "y_test = torch.FloatTensor(test_df[output_feature].values)\n",
    "\n",
    "training_set = FraudDatasetCUDA(x_train, y_train)\n",
    "testing_set = FraudDatasetCUDA(x_test, y_test)\n",
    "\n",
    "training_generator,testing_generator = prepare_generators(training_set,testing_set,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudMLPHypertuned(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size,hidden_size=500,num_layers=2,p=0.2):\n",
    "            super(FraudMLPHypertuned, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.p = p\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            \n",
    "            self.fc_hidden=[]\n",
    "            for i in range(num_layers-1):\n",
    "                self.fc_hidden.append(torch.nn.Linear(self.hidden_size, self.hidden_size).to(DEVICE))\n",
    "                self.fc_hidden.append(torch.nn.ReLU())\n",
    "                \n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            \n",
    "            self.dropout = torch.nn.Dropout(self.p)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            hidden = self.fc1(x)\n",
    "            hidden = self.relu(hidden)             \n",
    "            hidden = self.dropout(hidden)\n",
    "            \n",
    "            for layer in self.fc_hidden:\n",
    "                hidden=layer(hidden)\n",
    "                hidden = self.dropout(hidden)\n",
    "            \n",
    "            output = self.fc2(hidden)\n",
    "            output = self.sigmoid(output)\n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.05635731458264296\n",
      "valid loss: 0.023564383531966614\n",
      "\n",
      "Epoch 1: train loss: 0.026669810487637093\n",
      "valid loss: 0.0205722178264013\n",
      "\n",
      "Epoch 2: train loss: 0.024124431836114867\n",
      "valid loss: 0.019840265057738726\n",
      "\n",
      "Epoch 3: train loss: 0.023537858952121272\n",
      "valid loss: 0.0198213920417895\n",
      "\n",
      "Epoch 4: train loss: 0.022861190018515245\n",
      "valid loss: 0.019327732899996047\n",
      "\n",
      "Epoch 5: train loss: 0.02182849854621664\n",
      "valid loss: 0.01912346193136271\n",
      "\n",
      "Epoch 6: train loss: 0.021739739785546865\n",
      "valid loss: 0.01901485049702497\n",
      "\n",
      "Epoch 7: train loss: 0.021317785480179312\n",
      "valid loss: 0.018606643888534023\n",
      "\n",
      "Epoch 8: train loss: 0.020816404895491893\n",
      "valid loss: 0.018554411129131462\n",
      "\n",
      "Epoch 9: train loss: 0.020655572756001286\n",
      "valid loss: 0.018614769987181815\n",
      "\n",
      "Epoch 10: train loss: 0.01994578763989902\n",
      "valid loss: 0.018415607302743556\n",
      "\n",
      "Epoch 11: train loss: 0.019789539822523475\n",
      "valid loss: 0.0182773393785078\n",
      "\n",
      "Epoch 12: train loss: 0.01938710204453219\n",
      "valid loss: 0.01846077228202684\n",
      "\n",
      "Epoch 13: train loss: 0.019712951800643735\n",
      "valid loss: 0.01925173801299426\n",
      "\n",
      "Epoch 14: train loss: 0.019342928833018486\n",
      "valid loss: 0.018127595365960376\n",
      "\n",
      "Epoch 15: train loss: 0.019252572017460425\n",
      "valid loss: 0.01867628175057072\n",
      "\n",
      "Epoch 16: train loss: 0.019333367864113944\n",
      "valid loss: 0.01857827896216238\n",
      "\n",
      "Epoch 17: train loss: 0.0188437244766476\n",
      "valid loss: 0.018738264102420008\n",
      "\n",
      "Epoch 18: train loss: 0.018908653544752966\n",
      "valid loss: 0.018843108424318813\n",
      "\n",
      "Epoch 19: train loss: 0.01855477335386299\n",
      "valid loss: 0.019008484649669755\n"
     ]
    }
   ],
   "source": [
    "# Best hps taken from the handbook:\n",
    "# learning_rate=0.001\n",
    "# hidden layers 2\n",
    "# hidden size 500\n",
    "# batch_size 64\n",
    "# max epochs 20\n",
    "# dropout p 0.2\n",
    "\n",
    "model = FraudMLPHypertuned(len(input_features)).to(DEVICE)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "model,training_execution_time,_,_ = training_loop(model,training_generator,testing_generator,optimizer,criterion,\n",
    "                                                            max_epochs=20,apply_early_stopping=False,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model(x_test.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  Card Precision@100\n",
       "0    0.868              0.652               0.284"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df=test_df\n",
    "predictions_df['predictions']=predictions_test.detach().cpu().numpy()\n",
    "    \n",
    "performance_assessment(predictions_df, top_k_list=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/DL/mlp_grid_search_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a11e3a7eb51e2483c16a5d7cdfda12389edc17230fd81a6fc823433cff3faa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
