{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai.all\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../shared_functions.py\n",
    "%run ../my_shared_functions.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing for first and second test (W&B testing on train test split, W&B Sweeps on train test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 516 ms\n",
      "Wall time: 492 ms\n",
      "919767 transactions loaded, containing 8195 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT = '../../fraud-detection-handbook/simulated-data-transformed/data/'\n",
    "\n",
    "BEGIN_DATE = \"2018-06-11\"\n",
    "END_DATE = \"2018-09-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
    "\n",
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN_DATE_CONFIG = \"2018-07-25\"\n",
    "start_date_training = datetime.datetime.strptime(BEGIN_DATE_CONFIG, \"%Y-%m-%d\")\n",
    "delta_train=7\n",
    "delta_delay=7\n",
    "delta_test=7\n",
    "\n",
    "\n",
    "delta_valid = delta_test\n",
    "\n",
    "start_date_training_with_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "\n",
    "(train_df, valid_df)=get_train_test_set(transactions_df,start_date_training_with_valid,\n",
    "                                       delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_test)\n",
    "\n",
    "# standardizing\n",
    "(train_df, valid_df)=scaleData(train_df, valid_df,input_features)\n",
    "\n",
    "SEQ_LEN = 5\n",
    "\n",
    "def prepare_sequenced_X_y(df, seq_len, input_features, output_feature):\n",
    "    x = torch.FloatTensor(df[input_features].values) # shape => [66928, 15] for train\n",
    "    y = torch.FloatTensor(df[output_feature].values)\n",
    "    features = torch.vstack([x, torch.zeros(x[0,:].shape)]) # shape => [66929, 15] for train\n",
    "    df_ids_dates = pd.DataFrame({'CUSTOMER_ID':df['CUSTOMER_ID'].values,\n",
    "            'TX_DATETIME':df['TX_DATETIME'].values})\n",
    "    df_ids_dates[\"tmp_index\"]  = np.arange(len(df_ids_dates))\n",
    "    df_groupby_customer_id = df_ids_dates.groupby(\"CUSTOMER_ID\")\n",
    "    sequence_indices = pd.DataFrame(\n",
    "        {\n",
    "            \"tx_{}\".format(n): df_groupby_customer_id[\"tmp_index\"].shift(SEQ_LEN - n - 1)\n",
    "            for n in range(SEQ_LEN)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    sequences_ids = sequence_indices.fillna(len(features) - 1).values.astype(int) # shape => [66928, 5] for train\n",
    "\n",
    "    x_sequenced = [features[sequences_ids[index], :].transpose(0, 1) for index in range(x.shape[0])]\n",
    "    return torch.stack(x_sequenced), y # x shape => [66928, 15, 5] for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "x_train, y_train = prepare_sequenced_X_y(train_df, SEQ_LEN, input_features, output_feature)\n",
    "x_valid, y_valid = prepare_sequenced_X_y(valid_df, SEQ_LEN, input_features, output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, splits = tsai.all.combine_split_data([x_train.numpy(), x_valid.numpy()], [y_train.numpy(), y_valid.numpy()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W&B testing on simple train test split (GRU default example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fb4a02b71c4f1e85480e6b9c004a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230113_142917-1bkvfiai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/1bkvfiai\" target=\"_blank\">lucky-puddle-47</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = SEED,\n",
    "    begin_date = BEGIN_DATE_CONFIG,\n",
    "    delta_train = delta_train,\n",
    "    delta_delay = delta_delay,\n",
    "    delta_test = delta_test,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    seq_len=SEQ_LEN,\n",
    "    hidden_size = 100,\n",
    "    n_layers = 1,\n",
    "    rnn_dropout=0,\n",
    "    bidirectional=False,\n",
    "    fc_dropout=0,\n",
    "    optimizer='adam',\n",
    "    lr=0.0001,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=5,\n",
    "    max_epochs=100,\n",
    "    scale=True,\n",
    "    criterion='bce'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['gru', 'tsai', 'imbalance-not-considered'])\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = tsai.all.TSDatasets(X, y, splits=splits, inplace=True)\n",
    "dls = tsai.all.TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=config.batch_size, num_workers=config.num_workers, drop_last=True, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (rnn): GRU(15, 100, batch_first=True)\n",
       "  (dropout): Identity()\n",
       "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru = tsai.all.GRU(dls.vars, dls.c)\n",
    "gru"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://github.com/timeseriesAI/tsai/blob/main/tutorial_nbs/12_Experiment_tracking_with_W%26B.ipynb November 2022:\n",
    "\n",
    "\"There's currently a small bug in the integration between wandb and tsai that doesn't allow to log_preds. This can be used to show predictions in W&B. We recommend setting log_preds=False.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.032060</td>\n",
       "      <td>0.027005</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.033919</td>\n",
       "      <td>0.024424</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030790</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0.022038</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.020844</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.027894</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.019861</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>0.019721</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.019602</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>0.019460</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>0.019483</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>0.019118</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019247</td>\n",
       "      <td>0.019153</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.019054</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.018024</td>\n",
       "      <td>0.018901</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.019060</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.018840</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.018678</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>0.018647</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.019772</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.018501</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.018578</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.021432</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>0.018696</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>0.018463</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.026318</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.027004871517419815.\n",
      "Better model found at epoch 1 with valid_loss value: 0.024424413219094276.\n",
      "Better model found at epoch 2 with valid_loss value: 0.023034116253256798.\n",
      "Better model found at epoch 3 with valid_loss value: 0.022038085386157036.\n",
      "Better model found at epoch 4 with valid_loss value: 0.020844215527176857.\n",
      "Better model found at epoch 5 with valid_loss value: 0.02058219164609909.\n",
      "Better model found at epoch 6 with valid_loss value: 0.02052551507949829.\n",
      "Better model found at epoch 7 with valid_loss value: 0.019861457869410515.\n",
      "Better model found at epoch 8 with valid_loss value: 0.019720803946256638.\n",
      "Better model found at epoch 10 with valid_loss value: 0.01960168220102787.\n",
      "Better model found at epoch 11 with valid_loss value: 0.019488301128149033.\n",
      "Better model found at epoch 12 with valid_loss value: 0.019459718838334084.\n",
      "Better model found at epoch 13 with valid_loss value: 0.019331851974129677.\n",
      "Better model found at epoch 15 with valid_loss value: 0.019118016585707664.\n",
      "Better model found at epoch 19 with valid_loss value: 0.01905352622270584.\n",
      "Better model found at epoch 20 with valid_loss value: 0.019027575850486755.\n",
      "Better model found at epoch 21 with valid_loss value: 0.01889653503894806.\n",
      "Better model found at epoch 23 with valid_loss value: 0.018892724066972733.\n",
      "Better model found at epoch 25 with valid_loss value: 0.01883983612060547.\n",
      "Better model found at epoch 26 with valid_loss value: 0.018692048266530037.\n",
      "Better model found at epoch 27 with valid_loss value: 0.018677828833460808.\n",
      "Better model found at epoch 28 with valid_loss value: 0.01864739879965782.\n",
      "Better model found at epoch 32 with valid_loss value: 0.018564747646450996.\n",
      "Better model found at epoch 33 with valid_loss value: 0.018501099199056625.\n",
      "Better model found at epoch 37 with valid_loss value: 0.01848011650145054.\n",
      "Better model found at epoch 38 with valid_loss value: 0.01830446347594261.\n",
      "No improvement since epoch 38: early stopping\n"
     ]
    }
   ],
   "source": [
    "criterion = tsai.all.BCEWithLogitsLossFlat()\n",
    "optimizer = tsai.all.wrap_optimizer(torch.optim.Adam, **{'lr': config.lr})\n",
    "learn = tsai.all.ts_learner(\n",
    "    dls,\n",
    "    gru,\n",
    "    loss_func=criterion,\n",
    "    opt_func=optimizer,\n",
    "    device=torch.device('cuda'),\n",
    "    lr=config.lr,\n",
    "    metrics=[],\n",
    "    model_dir='GRU',\n",
    "    cbs=[\n",
    "        WandbCallback(\n",
    "            log='all',\n",
    "            log_model=True,\n",
    "            seed=config.seed),\n",
    "        EarlyStoppingCallback(\n",
    "            patience=config.early_stopping_patience\n",
    "        ),\n",
    "        SaveModelCallback(\n",
    "            fname='gru'\n",
    "        )])\n",
    "\n",
    "start_time=time.time()\n",
    "learn.fit(config.max_epochs)\n",
    "training_execution_time=time.time()-start_time\n",
    "\n",
    "# learn.fit_one_cycle(config.max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.772              0.467     0.664               0.223"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dl = learn.dls.valid\n",
    "start_time=time.time()\n",
    "valid_probas, valid_targets, valid_preds = learn.get_preds(dl=valid_dl, with_decoded=True)\n",
    "prediction_execution_time=time.time()-start_time\n",
    "predictions_df = valid_df\n",
    "predictions_df['predictions'] = valid_preds\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fedfda1d1f54e0fba8eb6038f40c5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.137 MB of 0.137 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>▄▁▁▇▂▆▁▁██▁▃▇▂▁▁▁▂▁▁▁▁▂▁▁▁▇▁▁█▁▂▁▆▁▄▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▅▅▅▄▂▃▄▃▄▃▃▃▃▂▄▂▂▄▃▂▁▃▂▂▂▃▄▂▂▁▂▂▃▂▂▃▃</td></tr><tr><td>train_samples_per_sec</td><td>▆▄▄▅█▄▇▅▃▆▁▄▄▄▆▆▇▄▆▇▁▄▅▅▄▆▆▆▄▁▁▅▄▅▅▅▄▄▅▂</td></tr><tr><td>valid_loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.772</td></tr><tr><td>Average precision</td><td>0.467</td></tr><tr><td>Card Precision@100</td><td>0.223</td></tr><tr><td>F1 score</td><td>0.664</td></tr><tr><td>Prediction execution time</td><td>2.5131</td></tr><tr><td>Training execution time</td><td>434.79316</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>44</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.0001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.00247</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.01493</td></tr><tr><td>train_samples_per_sec</td><td>9448.7259</td></tr><tr><td>valid_loss</td><td>0.01847</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lucky-puddle-47</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/1bkvfiai\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/1bkvfiai</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230113_142917-1bkvfiai\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time})\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W&B Sweeps on simple train test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=9zrmUIlScdY\n",
    "\n",
    "https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9dcp5xcj\n",
      "Sweep URL: https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "                'method': 'random', \n",
    "                'metric': {\n",
    "                    'goal': 'minimize',\n",
    "                    'name': 'val_loss'\n",
    "                    },\n",
    "                'parameters': {\n",
    "                    'batch_size': {\n",
    "                        # integers between 32 and 256 with equally evenly-distributed logarithms\n",
    "                        # 'distribution': 'q_log_uniform',\n",
    "                        # 'max': math.log(256),\n",
    "                        # 'min': math.log(32),\n",
    "                        # 'q': 1\n",
    "                        'values' : [64, 128]\n",
    "                    },\n",
    "                    'max_epochs': {\n",
    "                        'value': 100\n",
    "                        },\n",
    "                    'num_workers': {\n",
    "                        'value' : 0\n",
    "                    },\n",
    "                    'lr': {\n",
    "                        # flat distribution between 0 and 0.1\n",
    "                        # 'distribution': 'uniform',\n",
    "                        # 'max': 0.1,\n",
    "                        # 'min': 0},\n",
    "                        'values' : [0.0001, 0.001]\n",
    "                    },\n",
    "                    'seed': {\n",
    "                        'value' : 42\n",
    "                    },\n",
    "                    'early_stopping_patience': {\n",
    "                        'value' : 5\n",
    "                    },\n",
    "                }\n",
    " }\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"mgr-anomaly-tsxai-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = tsai.all.TSDatasets(X, y, splits=splits, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['gru', 'tsai', 'imbalance-not-considered', 'sweeps']):\n",
    "        config = wandb.config\n",
    "        dls = tsai.all.TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=config.batch_size, num_workers=config.num_workers, drop_last=True, device=DEVICE)\n",
    "        gru = tsai.all.GRU(dls.vars, dls.c)\n",
    "        criterion = tsai.all.BCEWithLogitsLossFlat()\n",
    "        optimizer = tsai.all.wrap_optimizer(torch.optim.Adam, **{'lr': config.lr})\n",
    "        learn = tsai.all.ts_learner(\n",
    "            dls,\n",
    "            gru,\n",
    "            loss_func=criterion,\n",
    "            opt_func=optimizer,\n",
    "            device=torch.device('cuda'),\n",
    "            lr=config.lr,\n",
    "            metrics=[],\n",
    "            model_dir='GRU',\n",
    "            cbs=[\n",
    "                WandbCallback(\n",
    "                    log='all',\n",
    "                    log_model=True,\n",
    "                    seed=config.seed),\n",
    "                EarlyStoppingCallback(\n",
    "                    patience=config.early_stopping_patience\n",
    "                ),\n",
    "                SaveModelCallback(\n",
    "                    fname='gru'\n",
    "                )])\n",
    "\n",
    "        start_time=time.time()\n",
    "        learn.fit(config.max_epochs)\n",
    "        training_execution_time=time.time()-start_time\n",
    "\n",
    "        valid_dl = learn.dls.valid\n",
    "        start_time=time.time()\n",
    "        valid_probas, valid_targets, valid_preds = learn.get_preds(dl=valid_dl, with_decoded=True)\n",
    "        prediction_execution_time=time.time()-start_time\n",
    "        predictions_df = valid_df\n",
    "        predictions_df['predictions'] = valid_preds\n",
    "        performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "\n",
    "        wandb.log({'Training execution time': training_execution_time})\n",
    "        wandb.log({'Prediction execution time': prediction_execution_time})\n",
    "        wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "        wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "        wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "        wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z6z2p0yh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae147452c21249aa807923a4bc4a2dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230113_160254-z6z2p0yh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/z6z2p0yh\" target=\"_blank\">devoted-sweep-1</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.036574</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.024536</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.031362</td>\n",
       "      <td>0.023153</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.021114</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023016</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.020059</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020230</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024948</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.020676</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.025491</td>\n",
       "      <td>0.019861</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018090</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.023620</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.025299</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.022672</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.019902</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.020205</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.022438</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.019025</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.027187876403331757.\n",
      "Better model found at epoch 1 with valid_loss value: 0.024536387994885445.\n",
      "Better model found at epoch 2 with valid_loss value: 0.02315320260822773.\n",
      "Better model found at epoch 3 with valid_loss value: 0.022057687863707542.\n",
      "Better model found at epoch 4 with valid_loss value: 0.02111424319446087.\n",
      "Better model found at epoch 5 with valid_loss value: 0.020511161535978317.\n",
      "Better model found at epoch 6 with valid_loss value: 0.02005911059677601.\n",
      "Better model found at epoch 7 with valid_loss value: 0.019855299964547157.\n",
      "Better model found at epoch 8 with valid_loss value: 0.019809087738394737.\n",
      "Better model found at epoch 9 with valid_loss value: 0.019736459478735924.\n",
      "Better model found at epoch 10 with valid_loss value: 0.01956108771264553.\n",
      "Better model found at epoch 11 with valid_loss value: 0.01945381984114647.\n",
      "Better model found at epoch 14 with valid_loss value: 0.019298575818538666.\n",
      "Better model found at epoch 15 with valid_loss value: 0.019278602674603462.\n",
      "Better model found at epoch 18 with valid_loss value: 0.01921015791594982.\n",
      "Better model found at epoch 22 with valid_loss value: 0.019052298739552498.\n",
      "Better model found at epoch 23 with valid_loss value: 0.01903619058430195.\n",
      "Better model found at epoch 24 with valid_loss value: 0.018851742148399353.\n",
      "No improvement since epoch 24: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>█▂▁▆▂▁▁▁▁▁▁▁▆▁▁▁▂▁▁▂▅▁▁█▁▃▁▇▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▆▅▅▆▆▄▇▆▃█▂▅▁▇▅▂▆▄▅█▆▇▅█▅▅▅▆▆▃▇▅▂▇▆▇▅▂▆▇</td></tr><tr><td>valid_loss</td><td>█▆▅▄▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.763</td></tr><tr><td>Average precision</td><td>0.456</td></tr><tr><td>Card Precision@100</td><td>0.216</td></tr><tr><td>F1 score</td><td>0.653</td></tr><tr><td>Prediction execution time</td><td>3.131</td></tr><tr><td>Training execution time</td><td>360.5425</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.0001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.02466</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.0219</td></tr><tr><td>train_samples_per_sec</td><td>11723.97369</td></tr><tr><td>valid_loss</td><td>0.01903</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-sweep-1</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/z6z2p0yh\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/z6z2p0yh</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230113_160254-z6z2p0yh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tzxd1z7z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cef17f0af44c1190c5e2a05805c180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230113_160931-tzxd1z7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/tzxd1z7z\" target=\"_blank\">blooming-sweep-2</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.030149</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>0.024972</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030139</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026690</td>\n",
       "      <td>0.021704</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024154</td>\n",
       "      <td>0.020844</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>0.020532</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.026218</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023913</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.019898</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.025774</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.021633</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020120</td>\n",
       "      <td>0.019262</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.019614</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.023789</td>\n",
       "      <td>0.019193</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.020889</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>0.019150</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.018956</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>0.019415</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.018984</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.019441</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.030148880556225777.\n",
      "Better model found at epoch 1 with valid_loss value: 0.026557469740509987.\n",
      "Better model found at epoch 2 with valid_loss value: 0.024971673265099525.\n",
      "Better model found at epoch 3 with valid_loss value: 0.023768514394760132.\n",
      "Better model found at epoch 4 with valid_loss value: 0.02311629056930542.\n",
      "Better model found at epoch 5 with valid_loss value: 0.022162241861224174.\n",
      "Better model found at epoch 6 with valid_loss value: 0.021703684702515602.\n",
      "Better model found at epoch 7 with valid_loss value: 0.021231260150671005.\n",
      "Better model found at epoch 8 with valid_loss value: 0.020844390615820885.\n",
      "Better model found at epoch 9 with valid_loss value: 0.020807495340704918.\n",
      "Better model found at epoch 10 with valid_loss value: 0.02053229883313179.\n",
      "Better model found at epoch 11 with valid_loss value: 0.02014555037021637.\n",
      "Better model found at epoch 12 with valid_loss value: 0.02000058814883232.\n",
      "Better model found at epoch 13 with valid_loss value: 0.019635438919067383.\n",
      "Better model found at epoch 16 with valid_loss value: 0.019500067457556725.\n",
      "Better model found at epoch 17 with valid_loss value: 0.019452733919024467.\n",
      "Better model found at epoch 19 with valid_loss value: 0.019418291747570038.\n",
      "Better model found at epoch 20 with valid_loss value: 0.019262278452515602.\n",
      "Better model found at epoch 23 with valid_loss value: 0.019192656502127647.\n",
      "Better model found at epoch 24 with valid_loss value: 0.019147733226418495.\n",
      "Better model found at epoch 27 with valid_loss value: 0.019042622298002243.\n",
      "Better model found at epoch 29 with valid_loss value: 0.01895609125494957.\n",
      "No improvement since epoch 29: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>▆▃▂▅▅▂▁▂▃▁▆▄▅▂▂▃▅▅█▄▁▆▄▁▁▁▄▁▁▁▁▁▁▂▁▁▂▁▁▂</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▅▆▅▅▆▄▃▅████▄▅▆▆▆▆▅▄▃▅▆▅▄▅▄▄▁▅▂▅▆▅▆▆▅▄▅▅</td></tr><tr><td>valid_loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.763</td></tr><tr><td>Average precision</td><td>0.458</td></tr><tr><td>Card Precision@100</td><td>0.214</td></tr><tr><td>F1 score</td><td>0.654</td></tr><tr><td>Prediction execution time</td><td>1.549</td></tr><tr><td>Training execution time</td><td>210.50055</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.0001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.06368</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.01975</td></tr><tr><td>train_samples_per_sec</td><td>9151.87828</td></tr><tr><td>valid_loss</td><td>0.01898</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">blooming-sweep-2</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/tzxd1z7z\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/tzxd1z7z</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230113_160931-tzxd1z7z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1gu6905i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aded05f20beb40adb60a0c2969c214db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230113_161325-1gu6905i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/1gu6905i\" target=\"_blank\">celestial-sweep-3</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043276</td>\n",
       "      <td>0.030557</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.034154</td>\n",
       "      <td>0.026603</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026559</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031069</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029932</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.026251</td>\n",
       "      <td>0.019758</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.023201</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.025209</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.022030</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>0.019252</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>0.019083</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.020401</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.023539</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.021271</td>\n",
       "      <td>0.019217</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.018905</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.019033</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.019275</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.018808</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.020583</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.020114</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.021273</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.020259</td>\n",
       "      <td>0.018567</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.024188</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.018432</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.017020</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.017430</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.018305</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.018335</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.018569</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.018381</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.018374</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.0305565744638443.\n",
      "Better model found at epoch 1 with valid_loss value: 0.02660321816802025.\n",
      "Better model found at epoch 2 with valid_loss value: 0.024889223277568817.\n",
      "Better model found at epoch 3 with valid_loss value: 0.02363283559679985.\n",
      "Better model found at epoch 4 with valid_loss value: 0.02293364889919758.\n",
      "Better model found at epoch 5 with valid_loss value: 0.022098835557699203.\n",
      "Better model found at epoch 6 with valid_loss value: 0.021722489967942238.\n",
      "Better model found at epoch 7 with valid_loss value: 0.02088347263634205.\n",
      "Better model found at epoch 8 with valid_loss value: 0.020695803686976433.\n",
      "Better model found at epoch 9 with valid_loss value: 0.02034473605453968.\n",
      "Better model found at epoch 10 with valid_loss value: 0.01999599114060402.\n",
      "Better model found at epoch 12 with valid_loss value: 0.01994204893708229.\n",
      "Better model found at epoch 13 with valid_loss value: 0.019758254289627075.\n",
      "Better model found at epoch 14 with valid_loss value: 0.01959223486483097.\n",
      "Better model found at epoch 16 with valid_loss value: 0.019536543637514114.\n",
      "Better model found at epoch 17 with valid_loss value: 0.01944028213620186.\n",
      "Better model found at epoch 19 with valid_loss value: 0.01940048672258854.\n",
      "Better model found at epoch 20 with valid_loss value: 0.019255319610238075.\n",
      "Better model found at epoch 21 with valid_loss value: 0.019251899793744087.\n",
      "Better model found at epoch 23 with valid_loss value: 0.019158994778990746.\n",
      "Better model found at epoch 25 with valid_loss value: 0.019077708944678307.\n",
      "Better model found at epoch 28 with valid_loss value: 0.019064126536250114.\n",
      "Better model found at epoch 30 with valid_loss value: 0.01904750056564808.\n",
      "Better model found at epoch 32 with valid_loss value: 0.01886720396578312.\n",
      "Better model found at epoch 34 with valid_loss value: 0.01879960484802723.\n",
      "Better model found at epoch 38 with valid_loss value: 0.018660983070731163.\n",
      "Better model found at epoch 43 with valid_loss value: 0.01864847168326378.\n",
      "Better model found at epoch 46 with valid_loss value: 0.018571853637695312.\n",
      "Better model found at epoch 48 with valid_loss value: 0.018567420542240143.\n",
      "Better model found at epoch 49 with valid_loss value: 0.018561681732535362.\n",
      "Better model found at epoch 50 with valid_loss value: 0.01849435642361641.\n",
      "Better model found at epoch 51 with valid_loss value: 0.018466385081410408.\n",
      "Better model found at epoch 53 with valid_loss value: 0.018432067707180977.\n",
      "Better model found at epoch 58 with valid_loss value: 0.01831434667110443.\n",
      "Better model found at epoch 61 with valid_loss value: 0.018305061385035515.\n",
      "No improvement since epoch 61: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>▄▃▁▁▅▄▁▁▁▁▁▂▂▄█▁▃▁▁▇▁▁▅▁▁▄▂▁▂▄▁▃▁▁▁▁▅▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▅▅▅▃▃▄▄▃▃▃▃▃▃▃▂▂▃▃▃▃▃▃▃▃▂▃▄▂▃▂▃▂▂▃▃▃▁▂</td></tr><tr><td>train_samples_per_sec</td><td>▄▇▅▂▄█▅▅▄▂▅▅▂▆▄▄▄▆▄▇▅▄▆▄▃▅▁▅▂▆▇▆▆▁▆▆▅▄▅▅</td></tr><tr><td>valid_loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.776</td></tr><tr><td>Average precision</td><td>0.47</td></tr><tr><td>Card Precision@100</td><td>0.227</td></tr><tr><td>F1 score</td><td>0.669</td></tr><tr><td>Prediction execution time</td><td>1.487</td></tr><tr><td>Training execution time</td><td>406.50827</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>67</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.0001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.08326</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.02036</td></tr><tr><td>train_samples_per_sec</td><td>20288.79837</td></tr><tr><td>valid_loss</td><td>0.01837</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">celestial-sweep-3</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/1gu6905i\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/1gu6905i</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230113_161325-1gu6905i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m94gaic9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c730fd9336a943d9bb36a42283ff8ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230113_162033-m94gaic9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/m94gaic9\" target=\"_blank\">drawn-sweep-4</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/9dcp5xcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021559</td>\n",
       "      <td>0.019595</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023151</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017503</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.017958</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.019217</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.017982</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>0.018164</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.01991594396531582.\n",
      "Better model found at epoch 1 with valid_loss value: 0.019595175981521606.\n",
      "Better model found at epoch 2 with valid_loss value: 0.019043751060962677.\n",
      "Better model found at epoch 4 with valid_loss value: 0.018818840384483337.\n",
      "Better model found at epoch 7 with valid_loss value: 0.017897048965096474.\n",
      "No improvement since epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>█▂▁▁▁▄▁▁▂▁▂▁▁▇▁▅▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▃▂▃▂▃▂▂▂▂▂▃▂▂▂▂▁▂▃▂▁▂▁▂▂▂▁▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▁▃▄▄▅▁▄▇▄▅▄▄▂▃▃▃▅▅▅▅▂▅▄▄▁▅▃▄▄█▅▅▅▅▄▁▅▅▅▂</td></tr><tr><td>valid_loss</td><td>▇▆▄▄▄█▄▁▁▅▁▂▂</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.784</td></tr><tr><td>Average precision</td><td>0.492</td></tr><tr><td>Card Precision@100</td><td>0.237</td></tr><tr><td>F1 score</td><td>0.685</td></tr><tr><td>Prediction execution time</td><td>2.87</td></tr><tr><td>Training execution time</td><td>154.51186</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.04421</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.01435</td></tr><tr><td>train_samples_per_sec</td><td>11295.64588</td></tr><tr><td>valid_loss</td><td>0.01816</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">drawn-sweep-4</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/m94gaic9\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/m94gaic9</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230113_162033-m94gaic9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W&B Sweeps on prequential validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweeps on TSAI train test split\n",
    "#\n",
    "# load transcations df\n",
    "# get train test set\n",
    "# scale data\n",
    "# prepare x_train, y_train, x_val, y_val\n",
    "# combine split data (tsai)\n",
    "# define sweep config\n",
    "# initialize a hp sweep (wand.sweep())\n",
    "# create TSDatasets (tsai)\n",
    "# create train(config) function:\n",
    "#   wandb.init()\n",
    "#   create data loaders\n",
    "#   create model instance\n",
    "#   train model\n",
    "#   calculate performance\n",
    "# run sweeps (wandb.agent())\n",
    "\n",
    "\n",
    "# Grid hp search on PyTorch prequential split\n",
    "#\n",
    "# load transactions df\n",
    "# run prequential_grid_search(\n",
    "#   transactions_df,\n",
    "#   neural net instance,\n",
    "#   hyperparameters dict,\n",
    "#   start_date_training_with_valid - fixed datetime value,\n",
    "#   n_folds,\n",
    "#   delta_train, delta_delay, delta_valid,\n",
    "#   list of performance metrics\n",
    "# )\n",
    "#\n",
    "# inside prequential_grid_search:\n",
    "#   pipeline creation: scaler + neural net\n",
    "#   prequentialSplit function -> returns prequential split indices\n",
    "#       for each fold (for loop): get train test set based on start date training, delta train, delta delay and delta test\n",
    "#       return list of indices for each fold\n",
    "#   grid search: create instance, get X and Y from transcations_df, run grid search\n",
    "#   calculate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 516 ms\n",
      "Wall time: 506 ms\n",
      "919767 transactions loaded, containing 8195 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT = '../../fraud-detection-handbook/simulated-data-transformed/data/'\n",
    "\n",
    "BEGIN_DATE = \"2018-06-11\"\n",
    "END_DATE = \"2018-09-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
    "\n",
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_training = datetime.datetime.strptime(\"2018-07-25\", \"%Y-%m-%d\")\n",
    "delta_train=7\n",
    "delta_delay=7\n",
    "delta_test=7\n",
    "delta_valid = delta_test\n",
    "\n",
    "n_folds=4\n",
    "\n",
    "start_date_training_for_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "start_date_training_for_test = start_date_training+datetime.timedelta(days=(n_folds-1)*delta_test)\n",
    "delta_assessment = delta_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "prequential_split = []\n",
    "        \n",
    "for fold in range(n_folds):\n",
    "    start_date_training_fold = start_date_training-datetime.timedelta(days=fold*delta_assessment)\n",
    "    \n",
    "    (train_df, test_df)=get_train_test_set(transactions_df,\n",
    "                                            start_date_training=start_date_training_fold,\n",
    "                                            delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_assessment)\n",
    "    \n",
    "    prequential_split.append((train_df, test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 5\n",
    "\n",
    "def prepare_sequenced_X_y(df, seq_len, input_features, output_feature):\n",
    "    x = torch.FloatTensor(df[input_features].values) # shape => [66928, 15] for train\n",
    "    y = torch.FloatTensor(df[output_feature].values)\n",
    "    features = torch.vstack([x, torch.zeros(x[0,:].shape)]) # shape => [66929, 15] for train\n",
    "    df_ids_dates = pd.DataFrame({'CUSTOMER_ID':df['CUSTOMER_ID'].values,\n",
    "            'TX_DATETIME':df['TX_DATETIME'].values})\n",
    "    df_ids_dates[\"tmp_index\"]  = np.arange(len(df_ids_dates))\n",
    "    df_groupby_customer_id = df_ids_dates.groupby(\"CUSTOMER_ID\")\n",
    "    sequence_indices = pd.DataFrame(\n",
    "        {\n",
    "            \"tx_{}\".format(n): df_groupby_customer_id[\"tmp_index\"].shift(SEQ_LEN - n - 1)\n",
    "            for n in range(SEQ_LEN)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    sequences_ids = sequence_indices.fillna(len(features) - 1).values.astype(int) # shape => [66928, 5] for train\n",
    "\n",
    "    x_sequenced = [features[sequences_ids[index], :].transpose(0, 1) for index in range(x.shape[0])]\n",
    "    return torch.stack(x_sequenced), y # x shape => [66928, 15, 5] for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "                'method': 'random', \n",
    "                'metric': {\n",
    "                    'goal': 'minimize',\n",
    "                    'name': 'val_loss'\n",
    "                    },\n",
    "                'parameters': {\n",
    "                    'batch_size': {\n",
    "                        'values' : [64, 128]\n",
    "                    },\n",
    "                    'max_epochs': {\n",
    "                        'values': [20, 40]\n",
    "                        },\n",
    "                    'num_workers': {\n",
    "                        'value' : 0\n",
    "                    },\n",
    "                    'lr': {\n",
    "                        'value' : 0.001\n",
    "                    },\n",
    "                    'seed': {\n",
    "                        'value' : SEED\n",
    "                    }\n",
    "                }\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ps17q4yt\n",
      "Sweep URL: https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/ps17q4yt\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"mgr-anomaly-tsxai-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config, tags=['gru', 'tsai', 'imbalance-not-considered', 'sweeps']):\n",
    "        config = wandb.config\n",
    "        training_execution_times = []\n",
    "        prediction_execution_times = []\n",
    "        aucs = []\n",
    "        average_precisions = []\n",
    "        f1_scores = []\n",
    "        card_precisions = []\n",
    "        for i in range(n_folds):\n",
    "            train_df = prequential_split[i][0]\n",
    "            valid_df = prequential_split[i][1]\n",
    "            (train_df, valid_df)=scaleData(train_df, valid_df,input_features)\n",
    "            x_train, y_train = prepare_sequenced_X_y(train_df, SEQ_LEN, input_features, output_feature)\n",
    "            x_valid, y_valid = prepare_sequenced_X_y(valid_df, SEQ_LEN, input_features, output_feature)\n",
    "            X, y, tsai_splits = tsai.all.combine_split_data([x_train.numpy(), x_valid.numpy()], [y_train.numpy(), y_valid.numpy()])\n",
    "            dsets = tsai.all.TSDatasets(X, y, splits=tsai_splits, inplace=True)\n",
    "            dls = tsai.all.TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=config.batch_size, num_workers=config.num_workers, drop_last=True, device=DEVICE)\n",
    "            gru = tsai.all.GRU(dls.vars, dls.c)\n",
    "            criterion = tsai.all.BCEWithLogitsLossFlat()\n",
    "            optimizer = tsai.all.wrap_optimizer(torch.optim.Adam, **{'lr': config.lr})\n",
    "            learn = tsai.all.ts_learner(\n",
    "                dls,\n",
    "                gru,\n",
    "                loss_func=criterion,\n",
    "                opt_func=optimizer,\n",
    "                device=torch.device('cuda'),\n",
    "                lr=config.lr,\n",
    "                metrics=[],\n",
    "                model_dir='GRU',\n",
    "                # no early stopping for multiple folds validation!\n",
    "                cbs=[\n",
    "                    WandbCallback(\n",
    "                        log=None,\n",
    "                        log_model=False,\n",
    "                        seed=config.seed)])\n",
    "\n",
    "            start_time=time.time()\n",
    "            learn.fit(config.max_epochs)\n",
    "            training_execution_times.append(time.time()-start_time)\n",
    "\n",
    "            valid_dl = learn.dls.valid\n",
    "            start_time=time.time()\n",
    "            valid_probas, valid_targets, valid_preds = learn.get_preds(dl=valid_dl, with_decoded=True)\n",
    "            prediction_execution_times.append(time.time()-start_time)\n",
    "            predictions_df = valid_df\n",
    "            predictions_df['predictions'] = valid_preds\n",
    "            performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "            aucs.append(performance_df.loc[0,'AUC ROC'])\n",
    "            average_precisions.append(performance_df.loc[0,'Average precision'])\n",
    "            f1_scores.append(performance_df.loc[0,'F1 score'])\n",
    "            card_precisions.append(performance_df.loc[0,'Card Precision@100'])\n",
    "\n",
    "        wandb.log({'Training execution time': np.sum(training_execution_times) / n_folds})\n",
    "        wandb.log({'Prediction execution time': np.sum(prediction_execution_times) / n_folds})\n",
    "        wandb.log({'AUC ROC': np.sum(aucs) / n_folds})\n",
    "        wandb.log({'Average precision': np.sum(average_precisions) / n_folds})\n",
    "        wandb.log({'F1 score': np.sum(f1_scores) / n_folds})\n",
    "        wandb.log({'Card Precision@100': np.sum(card_precisions) / n_folds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iosr949p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchamera\u001b[0m (\u001b[33mmgr-anomaly-tsxai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5da754abccc4349ba2f9ee434a58f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230115_181331-iosr949p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/iosr949p\" target=\"_blank\">skilled-sweep-1</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/ps17q4yt\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/ps17q4yt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.020459</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016570</td>\n",
       "      <td>0.019771</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019634</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>0.018905</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018901</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.019096</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.019343</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>0.019483</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.008731</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.026671</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.029290</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.030586</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.030756</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.033719</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.034529</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.034908</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.038902</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.022214</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025191</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.020012</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.017796</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.011040</td>\n",
       "      <td>0.020421</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.021804</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.023313</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.022870</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>0.027062</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.031114</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.033083</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.035047</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.037303</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.037876</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.036522</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.039440</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.042093</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.040310</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.039260</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.029526</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.019337</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018357</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020379</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.017992</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.013153</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.023070</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.024678</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.025706</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.026815</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.032712</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.034223</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.033781</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.035894</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.035728</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.034775</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.036227</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.014804</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022759</td>\n",
       "      <td>0.016940</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026949</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>0.016864</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015378</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.027168</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.016535</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.010611</td>\n",
       "      <td>0.017992</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.019711</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.014125</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>0.025514</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.026475</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.028829</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.033912</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.033073</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.033255</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a4fd571c104f889f2b1cd91b00e8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>▁▁▂▁▁▁▁▁▁▁▁█▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▇▂▁▅▅▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▇▅▅▅▃▂▂▁▂▁▆▅▅▅▃▂▁▁▂▁▅▄▇▅▄▃▂▂▁▁█▆▃▅▄▃▂▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▂▆▄█▄▂▅▂█▄▄▃▇█▅▅▅▃▆▆▅▄▆▅▄▅▄▂▃▂▃▆▅▁▃▂▇▃▄▆</td></tr><tr><td>valid_loss</td><td>▂▂▁▂▂▃▄▆▆▇▂▂▂▂▃▄▅▆▆█▂▁▂▂▂▃▄▅▅▆▁▁▁▁▂▂▄▄▅▆</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.77175</td></tr><tr><td>Average precision</td><td>0.44575</td></tr><tr><td>Card Precision@100</td><td>0.23275</td></tr><tr><td>F1 score</td><td>0.6515</td></tr><tr><td>Prediction execution time</td><td>2.343</td></tr><tr><td>Training execution time</td><td>393.63988</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>160</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>7e-05</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.00148</td></tr><tr><td>train_samples_per_sec</td><td>9508.81051</td></tr><tr><td>valid_loss</td><td>0.03325</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">skilled-sweep-1</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/iosr949p\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/iosr949p</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230115_181331-iosr949p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wfy1075q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f931909db3884acbb29572e8ef31d187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\tsai\\wandb\\run-20230115_184032-wfy1075q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/wfy1075q\" target=\"_blank\">vital-sweep-2</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/ps17q4yt\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/sweeps/ps17q4yt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.019221</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>0.018302</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015802</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.017788</td>\n",
       "      <td>0.018183</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>0.017984</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.017612</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.019072</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.019572</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.020088</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.019923</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.021066</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.010251</td>\n",
       "      <td>0.022145</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>0.025021</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.031188</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.031675</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.022170</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>0.019877</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.019923</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018166</td>\n",
       "      <td>0.019093</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015585</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.019056</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.019789</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010423</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.021144</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.022243</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.022648</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>0.024090</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.025688</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.026899</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.029032</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.029912</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.033506</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.033591</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.032932</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.032966</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.034094</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.036406</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.020985</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.020633</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.019330</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.018580</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.018461</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022405</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.017999</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.017965</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.018535</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.015227</td>\n",
       "      <td>0.022576</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.021550</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>0.021677</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.025966</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.025819</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.030193</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.031132</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.030648</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to prepare a DataLoader for logging prediction samples -> 'NoneType' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.020064</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.023216</td>\n",
       "      <td>0.017756</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020657</td>\n",
       "      <td>0.017390</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019137</td>\n",
       "      <td>0.015813</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.016403</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.016774</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015732</td>\n",
       "      <td>0.017041</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.013706</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.020516</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.023149</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.024356</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.026770</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.029416</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.028579</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.031004</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591b5fa803c94da097ff16b68fb1c40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.007 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.191995…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>amsgrad_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>capturable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>differentiable_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fused_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximize_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>▄▃▇▇▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▅▂▁██▁▁▇▁▅▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▆▇▇▅▅▄▃▂▂▁▆▆▆▆▄▄▃▂▁▁█▆▆▆▅▄▃▂▁▁█▇▆▅▅▃▄▂▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▄▄█▆▆▃▅▁▁▁▅▂▅▃▃▃▆▄▃▃▃▅▇▃▆▆▃▃▃▃▂▆▂▃▃▆▂▇▄▃</td></tr><tr><td>valid_loss</td><td>▂▂▂▂▂▃▃▄▆▇▃▂▂▂▃▃▅▆██▂▂▂▂▂▃▄▅▆▇▂▁▁▁▂▂▃▄▆▇</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.77175</td></tr><tr><td>Average precision</td><td>0.43575</td></tr><tr><td>Card Precision@100</td><td>0.2335</td></tr><tr><td>F1 score</td><td>0.6445</td></tr><tr><td>Prediction execution time</td><td>1.22675</td></tr><tr><td>Training execution time</td><td>204.614</td></tr><tr><td>amsgrad_0</td><td>False</td></tr><tr><td>capturable_0</td><td>False</td></tr><tr><td>differentiable_0</td><td>False</td></tr><tr><td>epoch</td><td>160</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>fused_0</td><td>False</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>maximize_0</td><td>False</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.00014</td></tr><tr><td>sqr_mom_0</td><td>0.999</td></tr><tr><td>train_loss</td><td>0.00111</td></tr><tr><td>train_samples_per_sec</td><td>27990.9904</td></tr><tr><td>valid_loss</td><td>0.031</td></tr><tr><td>wd_0</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vital-sweep-2</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/wfy1075q\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/wfy1075q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230115_184032-wfy1075q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a11e3a7eb51e2483c16a5d7cdfda12389edc17230fd81a6fc823433cff3faa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
