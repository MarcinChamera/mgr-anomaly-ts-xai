{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tsai.models.utils import count_parameters\n",
    "from prettytable import PrettyTable\n",
    "import tsai.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)\n",
    "\n",
    "input_features_length = 15\n",
    "seq_len = 5\n",
    "\n",
    "def count_model_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "%run ../shared_functions.py\n",
    "%run ../my_shared_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "| convblock1.0.weight |    6720    |\n",
      "| convblock1.1.weight |     64     |\n",
      "|  convblock1.1.bias  |     64     |\n",
      "| convblock2.0.weight |   40960    |\n",
      "| convblock2.1.weight |    128     |\n",
      "|  convblock2.1.bias  |    128     |\n",
      "| convblock3.0.weight |   24576    |\n",
      "| convblock3.1.weight |     64     |\n",
      "|  convblock3.1.bias  |     64     |\n",
      "|      fc.weight      |     64     |\n",
      "|       fc.bias       |     1      |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 72833\n"
     ]
    }
   ],
   "source": [
    "fcn_model = tsai.all.FCN(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1,\n",
    "    layers=[64, 128, 64],\n",
    "    kss=[7, 5 ,3]\n",
    "    )\n",
    "_ = count_model_parameters(fcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72833"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------+\n",
      "|             Modules             | Parameters |\n",
      "+---------------------------------+------------+\n",
      "|       model.0.norm.weight       |    128     |\n",
      "|        model.0.norm.bias        |    128     |\n",
      "|   model.0.channel_proj1.weight  |   65536    |\n",
      "|    model.0.channel_proj1.bias   |    512     |\n",
      "|   model.0.channel_proj2.weight  |   32768    |\n",
      "|    model.0.channel_proj2.bias   |    128     |\n",
      "|     model.0.sgu.norm.weight     |    256     |\n",
      "|      model.0.sgu.norm.bias      |    256     |\n",
      "| model.0.sgu.spatial_proj.weight |     25     |\n",
      "|  model.0.sgu.spatial_proj.bias  |     5      |\n",
      "|       model.1.norm.weight       |    128     |\n",
      "|        model.1.norm.bias        |    128     |\n",
      "|   model.1.channel_proj1.weight  |   65536    |\n",
      "|    model.1.channel_proj1.bias   |    512     |\n",
      "|   model.1.channel_proj2.weight  |   32768    |\n",
      "|    model.1.channel_proj2.bias   |    128     |\n",
      "|     model.1.sgu.norm.weight     |    256     |\n",
      "|      model.1.sgu.norm.bias      |    256     |\n",
      "| model.1.sgu.spatial_proj.weight |     25     |\n",
      "|  model.1.sgu.spatial_proj.bias  |     5      |\n",
      "|       model.2.norm.weight       |    128     |\n",
      "|        model.2.norm.bias        |    128     |\n",
      "|   model.2.channel_proj1.weight  |   65536    |\n",
      "|    model.2.channel_proj1.bias   |    512     |\n",
      "|   model.2.channel_proj2.weight  |   32768    |\n",
      "|    model.2.channel_proj2.bias   |    128     |\n",
      "|     model.2.sgu.norm.weight     |    256     |\n",
      "|      model.2.sgu.norm.bias      |    256     |\n",
      "| model.2.sgu.spatial_proj.weight |     25     |\n",
      "|  model.2.sgu.spatial_proj.bias  |     5      |\n",
      "|       model.3.norm.weight       |    128     |\n",
      "|        model.3.norm.bias        |    128     |\n",
      "|   model.3.channel_proj1.weight  |   65536    |\n",
      "|    model.3.channel_proj1.bias   |    512     |\n",
      "|   model.3.channel_proj2.weight  |   32768    |\n",
      "|    model.3.channel_proj2.bias   |    128     |\n",
      "|     model.3.sgu.norm.weight     |    256     |\n",
      "|      model.3.sgu.norm.bias      |    256     |\n",
      "| model.3.sgu.spatial_proj.weight |     25     |\n",
      "|  model.3.sgu.spatial_proj.bias  |     5      |\n",
      "|       model.4.norm.weight       |    128     |\n",
      "|        model.4.norm.bias        |    128     |\n",
      "|   model.4.channel_proj1.weight  |   65536    |\n",
      "|    model.4.channel_proj1.bias   |    512     |\n",
      "|   model.4.channel_proj2.weight  |   32768    |\n",
      "|    model.4.channel_proj2.bias   |    128     |\n",
      "|     model.4.sgu.norm.weight     |    256     |\n",
      "|      model.4.sgu.norm.bias      |    256     |\n",
      "| model.4.sgu.spatial_proj.weight |     25     |\n",
      "|  model.4.sgu.spatial_proj.bias  |     5      |\n",
      "|       model.5.norm.weight       |    128     |\n",
      "|        model.5.norm.bias        |    128     |\n",
      "|   model.5.channel_proj1.weight  |   65536    |\n",
      "|    model.5.channel_proj1.bias   |    512     |\n",
      "|   model.5.channel_proj2.weight  |   32768    |\n",
      "|    model.5.channel_proj2.bias   |    128     |\n",
      "|     model.5.sgu.norm.weight     |    256     |\n",
      "|      model.5.sgu.norm.bias      |    256     |\n",
      "| model.5.sgu.spatial_proj.weight |     25     |\n",
      "|  model.5.sgu.spatial_proj.bias  |     5      |\n",
      "|       model.6.norm.weight       |    128     |\n",
      "|        model.6.norm.bias        |    128     |\n",
      "|   model.6.channel_proj1.weight  |   65536    |\n",
      "|    model.6.channel_proj1.bias   |    512     |\n",
      "|   model.6.channel_proj2.weight  |   32768    |\n",
      "|    model.6.channel_proj2.bias   |    128     |\n",
      "|     model.6.sgu.norm.weight     |    256     |\n",
      "|      model.6.sgu.norm.bias      |    256     |\n",
      "| model.6.sgu.spatial_proj.weight |     25     |\n",
      "|  model.6.sgu.spatial_proj.bias  |     5      |\n",
      "|          patcher.weight         |    1920    |\n",
      "|           patcher.bias          |    128     |\n",
      "|           head.weight           |    128     |\n",
      "|            head.bias            |     1      |\n",
      "+---------------------------------+------------+\n",
      "Total Trainable Params: 700371\n"
     ]
    }
   ],
   "source": [
    "gmlp_model = tsai.all.gMLP(\n",
    "    input_features_length,\n",
    "    1,\n",
    "    seq_len,\n",
    "    patch_size=1,\n",
    "    d_model=128,\n",
    "    d_ffn=256,\n",
    "    depth=7\n",
    "    )\n",
    "_ = count_model_parameters(gmlp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "|   rnn.weight_ih_l0  |    1500    |\n",
      "|   rnn.weight_hh_l0  |   30000    |\n",
      "|    rnn.bias_ih_l0   |    300     |\n",
      "|    rnn.bias_hh_l0   |    300     |\n",
      "|   rnn.weight_ih_l1  |   30000    |\n",
      "|   rnn.weight_hh_l1  |   30000    |\n",
      "|    rnn.bias_ih_l1   |    300     |\n",
      "|    rnn.bias_hh_l1   |    300     |\n",
      "| convblock1.0.weight |    4800    |\n",
      "| convblock1.1.weight |     64     |\n",
      "|  convblock1.1.bias  |     64     |\n",
      "| convblock2.0.weight |   40960    |\n",
      "| convblock2.1.weight |    128     |\n",
      "|  convblock2.1.bias  |    128     |\n",
      "| convblock3.0.weight |   24576    |\n",
      "| convblock3.1.weight |     64     |\n",
      "|  convblock3.1.bias  |     64     |\n",
      "|      fc.weight      |    164     |\n",
      "|       fc.bias       |     1      |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 163713\n"
     ]
    }
   ],
   "source": [
    "gru_fcn_model = tsai.all.GRU_FCN(\n",
    "    c_in=input_features_length,\n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    hidden_size=100,\n",
    "    rnn_layers=2,\n",
    "    bias=True,\n",
    "    cell_dropout=0.2,\n",
    "    rnn_dropout=0.4,\n",
    "    bidirectional=False,\n",
    "    fc_dropout=0.2,\n",
    "    conv_layers=[64, 128, 64],\n",
    "    kss=[5, 5, 3],\n",
    "    se=0\n",
    "    )\n",
    "_ = count_model_parameters(gru_fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "| rnn.weight_ih_l0 |    4500    |\n",
      "| rnn.weight_hh_l0 |   30000    |\n",
      "|  rnn.bias_ih_l0  |    300     |\n",
      "|  rnn.bias_hh_l0  |    300     |\n",
      "| rnn.weight_ih_l1 |   30000    |\n",
      "| rnn.weight_hh_l1 |   30000    |\n",
      "|  rnn.bias_ih_l1  |    300     |\n",
      "|  rnn.bias_hh_l1  |    300     |\n",
      "|    fc.weight     |    100     |\n",
      "|     fc.bias      |     1      |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 95801\n"
     ]
    }
   ],
   "source": [
    "gru_model = tsai.all.GRU(\n",
    "                c_in=input_features_length,\n",
    "                c_out=1,\n",
    "                hidden_size=100,\n",
    "                n_layers=2,\n",
    "                rnn_dropout=0.2,\n",
    "                fc_dropout=0.4)\n",
    "_ = count_model_parameters(gru_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+------------+\n",
      "|                     Modules                     | Parameters |\n",
      "+-------------------------------------------------+------------+\n",
      "|   inceptionblock.inception.0.bottleneck.weight  |    960     |\n",
      "|    inceptionblock.inception.0.convs.0.weight    |   159744   |\n",
      "|    inceptionblock.inception.0.convs.1.weight    |   77824    |\n",
      "|    inceptionblock.inception.0.convs.2.weight    |   36864    |\n",
      "| inceptionblock.inception.0.maxconvpool.1.weight |    960     |\n",
      "|       inceptionblock.inception.0.bn.weight      |    256     |\n",
      "|        inceptionblock.inception.0.bn.bias       |    256     |\n",
      "|   inceptionblock.inception.1.bottleneck.weight  |   16384    |\n",
      "|    inceptionblock.inception.1.convs.0.weight    |   159744   |\n",
      "|    inceptionblock.inception.1.convs.1.weight    |   77824    |\n",
      "|    inceptionblock.inception.1.convs.2.weight    |   36864    |\n",
      "| inceptionblock.inception.1.maxconvpool.1.weight |   16384    |\n",
      "|       inceptionblock.inception.1.bn.weight      |    256     |\n",
      "|        inceptionblock.inception.1.bn.bias       |    256     |\n",
      "|   inceptionblock.inception.2.bottleneck.weight  |   16384    |\n",
      "|    inceptionblock.inception.2.convs.0.weight    |   159744   |\n",
      "|    inceptionblock.inception.2.convs.1.weight    |   77824    |\n",
      "|    inceptionblock.inception.2.convs.2.weight    |   36864    |\n",
      "| inceptionblock.inception.2.maxconvpool.1.weight |   16384    |\n",
      "|       inceptionblock.inception.2.bn.weight      |    256     |\n",
      "|        inceptionblock.inception.2.bn.bias       |    256     |\n",
      "|   inceptionblock.inception.3.bottleneck.weight  |   16384    |\n",
      "|    inceptionblock.inception.3.convs.0.weight    |   159744   |\n",
      "|    inceptionblock.inception.3.convs.1.weight    |   77824    |\n",
      "|    inceptionblock.inception.3.convs.2.weight    |   36864    |\n",
      "| inceptionblock.inception.3.maxconvpool.1.weight |   16384    |\n",
      "|       inceptionblock.inception.3.bn.weight      |    256     |\n",
      "|        inceptionblock.inception.3.bn.bias       |    256     |\n",
      "|   inceptionblock.inception.4.bottleneck.weight  |   16384    |\n",
      "|    inceptionblock.inception.4.convs.0.weight    |   159744   |\n",
      "|    inceptionblock.inception.4.convs.1.weight    |   77824    |\n",
      "|    inceptionblock.inception.4.convs.2.weight    |   36864    |\n",
      "| inceptionblock.inception.4.maxconvpool.1.weight |   16384    |\n",
      "|       inceptionblock.inception.4.bn.weight      |    256     |\n",
      "|        inceptionblock.inception.4.bn.bias       |    256     |\n",
      "|   inceptionblock.inception.5.bottleneck.weight  |   16384    |\n",
      "|    inceptionblock.inception.5.convs.0.weight    |   159744   |\n",
      "|    inceptionblock.inception.5.convs.1.weight    |   77824    |\n",
      "|    inceptionblock.inception.5.convs.2.weight    |   36864    |\n",
      "| inceptionblock.inception.5.maxconvpool.1.weight |   16384    |\n",
      "|       inceptionblock.inception.5.bn.weight      |    256     |\n",
      "|        inceptionblock.inception.5.bn.bias       |    256     |\n",
      "|        inceptionblock.shortcut.0.0.weight       |    3840    |\n",
      "|        inceptionblock.shortcut.0.1.weight       |    256     |\n",
      "|         inceptionblock.shortcut.0.1.bias        |    256     |\n",
      "|         inceptionblock.shortcut.1.weight        |    256     |\n",
      "|          inceptionblock.shortcut.1.bias         |    256     |\n",
      "|                    fc.weight                    |    256     |\n",
      "|                     fc.bias                     |     1      |\n",
      "+-------------------------------------------------+------------+\n",
      "Total Trainable Params: 1820545\n"
     ]
    }
   ],
   "source": [
    "inceptiontime_model = tsai.all.InceptionTime(\n",
    "    c_in=input_features_length,\n",
    "    c_out=1,\n",
    "    nf=64,\n",
    "    nb_filters=None)\n",
    "_ = count_model_parameters(inceptiontime_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+------------+\n",
      "|                     Modules                     | Parameters |\n",
      "+-------------------------------------------------+------------+\n",
      "|   inceptionblock.inception.0.bottleneck.weight  |    480     |\n",
      "|    inceptionblock.inception.0.convs.0.weight    |   39936    |\n",
      "|    inceptionblock.inception.0.convs.1.weight    |   19456    |\n",
      "|    inceptionblock.inception.0.convs.2.weight    |    9216    |\n",
      "| inceptionblock.inception.0.maxconvpool.1.weight |    480     |\n",
      "|       inceptionblock.inception.0.bn.weight      |    128     |\n",
      "|        inceptionblock.inception.0.bn.bias       |    128     |\n",
      "|   inceptionblock.inception.1.bottleneck.weight  |    4096    |\n",
      "|    inceptionblock.inception.1.convs.0.weight    |   39936    |\n",
      "|    inceptionblock.inception.1.convs.1.weight    |   19456    |\n",
      "|    inceptionblock.inception.1.convs.2.weight    |    9216    |\n",
      "| inceptionblock.inception.1.maxconvpool.1.weight |    4096    |\n",
      "|       inceptionblock.inception.1.bn.weight      |    128     |\n",
      "|        inceptionblock.inception.1.bn.bias       |    128     |\n",
      "|   inceptionblock.inception.2.bottleneck.weight  |    4096    |\n",
      "|    inceptionblock.inception.2.convs.0.weight    |   39936    |\n",
      "|    inceptionblock.inception.2.convs.1.weight    |   19456    |\n",
      "|    inceptionblock.inception.2.convs.2.weight    |    9216    |\n",
      "| inceptionblock.inception.2.maxconvpool.1.weight |    4096    |\n",
      "|       inceptionblock.inception.2.bn.weight      |    128     |\n",
      "|        inceptionblock.inception.2.bn.bias       |    128     |\n",
      "|   inceptionblock.inception.3.bottleneck.weight  |    4096    |\n",
      "|    inceptionblock.inception.3.convs.0.weight    |   39936    |\n",
      "|    inceptionblock.inception.3.convs.1.weight    |   19456    |\n",
      "|    inceptionblock.inception.3.convs.2.weight    |    9216    |\n",
      "| inceptionblock.inception.3.maxconvpool.1.weight |    4096    |\n",
      "|       inceptionblock.inception.3.bn.weight      |    128     |\n",
      "|        inceptionblock.inception.3.bn.bias       |    128     |\n",
      "|   inceptionblock.inception.4.bottleneck.weight  |    4096    |\n",
      "|    inceptionblock.inception.4.convs.0.weight    |   39936    |\n",
      "|    inceptionblock.inception.4.convs.1.weight    |   19456    |\n",
      "|    inceptionblock.inception.4.convs.2.weight    |    9216    |\n",
      "| inceptionblock.inception.4.maxconvpool.1.weight |    4096    |\n",
      "|       inceptionblock.inception.4.bn.weight      |    128     |\n",
      "|        inceptionblock.inception.4.bn.bias       |    128     |\n",
      "|   inceptionblock.inception.5.bottleneck.weight  |    4096    |\n",
      "|    inceptionblock.inception.5.convs.0.weight    |   39936    |\n",
      "|    inceptionblock.inception.5.convs.1.weight    |   19456    |\n",
      "|    inceptionblock.inception.5.convs.2.weight    |    9216    |\n",
      "| inceptionblock.inception.5.maxconvpool.1.weight |    4096    |\n",
      "|       inceptionblock.inception.5.bn.weight      |    128     |\n",
      "|        inceptionblock.inception.5.bn.bias       |    128     |\n",
      "|        inceptionblock.shortcut.0.0.weight       |    1920    |\n",
      "|        inceptionblock.shortcut.0.1.weight       |    128     |\n",
      "|         inceptionblock.shortcut.0.1.bias        |    128     |\n",
      "|         inceptionblock.shortcut.1.weight        |    128     |\n",
      "|          inceptionblock.shortcut.1.bias         |    128     |\n",
      "|                    fc.weight                    |    128     |\n",
      "|                     fc.bias                     |     1      |\n",
      "+-------------------------------------------------+------------+\n",
      "Total Trainable Params: 457665\n"
     ]
    }
   ],
   "source": [
    "# number of parameters for default HP\n",
    "inceptiontime_model = tsai.all.InceptionTime(\n",
    "    c_in=input_features_length,\n",
    "    c_out=1)\n",
    "_ = count_model_parameters(inceptiontime_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "|   rnn.weight_ih_l0  |    2000    |\n",
      "|   rnn.weight_hh_l0  |   40000    |\n",
      "|    rnn.bias_ih_l0   |    400     |\n",
      "|    rnn.bias_hh_l0   |    400     |\n",
      "|   rnn.weight_ih_l1  |   40000    |\n",
      "|   rnn.weight_hh_l1  |   40000    |\n",
      "|    rnn.bias_ih_l1   |    400     |\n",
      "|    rnn.bias_hh_l1   |    400     |\n",
      "| convblock1.0.weight |    4800    |\n",
      "| convblock1.1.weight |     64     |\n",
      "|  convblock1.1.bias  |     64     |\n",
      "| convblock2.0.weight |   40960    |\n",
      "| convblock2.1.weight |    128     |\n",
      "|  convblock2.1.bias  |    128     |\n",
      "| convblock3.0.weight |   24576    |\n",
      "| convblock3.1.weight |     64     |\n",
      "|  convblock3.1.bias  |     64     |\n",
      "|      fc.weight      |    164     |\n",
      "|       fc.bias       |     1      |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 194613\n"
     ]
    }
   ],
   "source": [
    "lstm_fcn_model = tsai.all.LSTM_FCN(\n",
    "                c_in=input_features_length, \n",
    "                c_out=1,\n",
    "                seq_len=seq_len,\n",
    "                hidden_size=100,\n",
    "                rnn_layers=2,\n",
    "                bias=True,\n",
    "                cell_dropout=0.2,\n",
    "                rnn_dropout=0,\n",
    "                bidirectional=False,\n",
    "                fc_dropout=0.2,\n",
    "                conv_layers=[64, 128, 64],\n",
    "                kss=[5, 5, 3],\n",
    "                se=0\n",
    "                )\n",
    "_ = count_model_parameters(lstm_fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "| rnn.weight_ih_l0 |    6000    |\n",
      "| rnn.weight_hh_l0 |   40000    |\n",
      "|  rnn.bias_ih_l0  |    400     |\n",
      "|  rnn.bias_hh_l0  |    400     |\n",
      "| rnn.weight_ih_l1 |   40000    |\n",
      "| rnn.weight_hh_l1 |   40000    |\n",
      "|  rnn.bias_ih_l1  |    400     |\n",
      "|  rnn.bias_hh_l1  |    400     |\n",
      "|    fc.weight     |    100     |\n",
      "|     fc.bias      |     1      |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 127701\n"
     ]
    }
   ],
   "source": [
    "lstm_model = tsai.all.LSTM(\n",
    "                c_in=input_features_length,\n",
    "                c_out=1,\n",
    "                hidden_size=100,\n",
    "                n_layers=2,\n",
    "                rnn_dropout=0,\n",
    "                fc_dropout=0)\n",
    "_ = count_model_parameters(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLSTM-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "|   rnn.weight_ih_l0  |    2000    |\n",
      "|   rnn.weight_hh_l0  |   40000    |\n",
      "|    rnn.bias_ih_l0   |    400     |\n",
      "|    rnn.bias_hh_l0   |    400     |\n",
      "| convblock1.0.weight |    4800    |\n",
      "| convblock1.1.weight |     64     |\n",
      "|  convblock1.1.bias  |     64     |\n",
      "|   se1.fc.0.weight   |    256     |\n",
      "|   se1.fc.2.weight   |    256     |\n",
      "| convblock2.0.weight |   49152    |\n",
      "| convblock2.1.weight |    256     |\n",
      "|  convblock2.1.bias  |    256     |\n",
      "|   se2.fc.0.weight   |    4096    |\n",
      "|   se2.fc.2.weight   |    4096    |\n",
      "| convblock3.0.weight |   16384    |\n",
      "| convblock3.1.weight |     64     |\n",
      "|  convblock3.1.bias  |     64     |\n",
      "|      fc.weight      |    164     |\n",
      "|       fc.bias       |     1      |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 122773\n"
     ]
    }
   ],
   "source": [
    "mlstm_fcn_model = tsai.all.MLSTM_FCN(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    hidden_size=100,\n",
    "    rnn_layers=1,\n",
    "    bias=True,\n",
    "    cell_dropout=0.2,\n",
    "    rnn_dropout=0.4,\n",
    "    bidirectional=False,\n",
    "    fc_dropout=0.2,\n",
    "    conv_layers=[64, 256, 64],\n",
    "    kss=[5, 3, 1],\n",
    "    se=16\n",
    "    )\n",
    "_ = count_model_parameters(mlstm_fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| block1.convblock1.0.weight |    6720    |\n",
      "| block1.convblock1.1.weight |     64     |\n",
      "|  block1.convblock1.1.bias  |     64     |\n",
      "| block1.convblock2.0.weight |   20480    |\n",
      "| block1.convblock2.1.weight |     64     |\n",
      "|  block1.convblock2.1.bias  |     64     |\n",
      "| block1.convblock3.0.weight |   12288    |\n",
      "| block1.convblock3.1.weight |     64     |\n",
      "|  block1.convblock3.1.bias  |     64     |\n",
      "|  block1.shortcut.0.weight  |    960     |\n",
      "|  block1.shortcut.1.weight  |     64     |\n",
      "|   block1.shortcut.1.bias   |     64     |\n",
      "|      block2.0.weight       |   24576    |\n",
      "|      block2.1.weight       |    128     |\n",
      "|       block2.1.bias        |    128     |\n",
      "|      block3.0.weight       |   98304    |\n",
      "|      block3.1.weight       |    256     |\n",
      "|       block3.1.bias        |    256     |\n",
      "|      block3.2.weight       |     1      |\n",
      "|      block4.0.weight       |   98304    |\n",
      "|      block4.1.weight       |    128     |\n",
      "|       block4.1.bias        |    128     |\n",
      "|         lin.weight         |    128     |\n",
      "|          lin.bias          |     1      |\n",
      "+----------------------------+------------+\n",
      "Total Trainable Params: 263298\n"
     ]
    }
   ],
   "source": [
    "rescnn_model = tsai.all.ResCNN(\n",
    "                c_in=input_features_length, \n",
    "                c_out=1,\n",
    "                coord=False,\n",
    "                separable=False,\n",
    "                zero_norm=False\n",
    "            )\n",
    "_ = count_model_parameters(rescnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+------------+\n",
      "|                    Modules                     | Parameters |\n",
      "+------------------------------------------------+------------+\n",
      "|               backbone.pos_embed               |    160     |\n",
      "|               backbone.cls_token               |     32     |\n",
      "|          backbone.linear_proj.weight           |    480     |\n",
      "|           backbone.linear_proj.bias            |     32     |\n",
      "|   backbone.encoder.encoder.0.mha.W_Q.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.0.mha.W_Q.bias     |     32     |\n",
      "|   backbone.encoder.encoder.0.mha.W_K.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.0.mha.W_K.bias     |     32     |\n",
      "|   backbone.encoder.encoder.0.mha.W_V.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.0.mha.W_V.bias     |     32     |\n",
      "| backbone.encoder.encoder.0.mha.to_out.0.weight |    1024    |\n",
      "|  backbone.encoder.encoder.0.mha.to_out.0.bias  |     32     |\n",
      "|  backbone.encoder.encoder.0.attn_norm.weight   |     32     |\n",
      "|   backbone.encoder.encoder.0.attn_norm.bias    |     32     |\n",
      "|    backbone.encoder.encoder.0.pwff.0.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.0.pwff.0.bias     |     32     |\n",
      "|    backbone.encoder.encoder.0.pwff.3.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.0.pwff.3.bias     |     32     |\n",
      "|   backbone.encoder.encoder.0.ff_norm.weight    |     32     |\n",
      "|    backbone.encoder.encoder.0.ff_norm.bias     |     32     |\n",
      "|   backbone.encoder.encoder.1.mha.W_Q.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.1.mha.W_Q.bias     |     32     |\n",
      "|   backbone.encoder.encoder.1.mha.W_K.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.1.mha.W_K.bias     |     32     |\n",
      "|   backbone.encoder.encoder.1.mha.W_V.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.1.mha.W_V.bias     |     32     |\n",
      "| backbone.encoder.encoder.1.mha.to_out.0.weight |    1024    |\n",
      "|  backbone.encoder.encoder.1.mha.to_out.0.bias  |     32     |\n",
      "|  backbone.encoder.encoder.1.attn_norm.weight   |     32     |\n",
      "|   backbone.encoder.encoder.1.attn_norm.bias    |     32     |\n",
      "|    backbone.encoder.encoder.1.pwff.0.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.1.pwff.0.bias     |     32     |\n",
      "|    backbone.encoder.encoder.1.pwff.3.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.1.pwff.3.bias     |     32     |\n",
      "|   backbone.encoder.encoder.1.ff_norm.weight    |     32     |\n",
      "|    backbone.encoder.encoder.1.ff_norm.bias     |     32     |\n",
      "|   backbone.encoder.encoder.2.mha.W_Q.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.2.mha.W_Q.bias     |     32     |\n",
      "|   backbone.encoder.encoder.2.mha.W_K.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.2.mha.W_K.bias     |     32     |\n",
      "|   backbone.encoder.encoder.2.mha.W_V.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.2.mha.W_V.bias     |     32     |\n",
      "| backbone.encoder.encoder.2.mha.to_out.0.weight |    1024    |\n",
      "|  backbone.encoder.encoder.2.mha.to_out.0.bias  |     32     |\n",
      "|  backbone.encoder.encoder.2.attn_norm.weight   |     32     |\n",
      "|   backbone.encoder.encoder.2.attn_norm.bias    |     32     |\n",
      "|    backbone.encoder.encoder.2.pwff.0.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.2.pwff.0.bias     |     32     |\n",
      "|    backbone.encoder.encoder.2.pwff.3.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.2.pwff.3.bias     |     32     |\n",
      "|   backbone.encoder.encoder.2.ff_norm.weight    |     32     |\n",
      "|    backbone.encoder.encoder.2.ff_norm.bias     |     32     |\n",
      "|   backbone.encoder.encoder.3.mha.W_Q.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.3.mha.W_Q.bias     |     32     |\n",
      "|   backbone.encoder.encoder.3.mha.W_K.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.3.mha.W_K.bias     |     32     |\n",
      "|   backbone.encoder.encoder.3.mha.W_V.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.3.mha.W_V.bias     |     32     |\n",
      "| backbone.encoder.encoder.3.mha.to_out.0.weight |    1024    |\n",
      "|  backbone.encoder.encoder.3.mha.to_out.0.bias  |     32     |\n",
      "|  backbone.encoder.encoder.3.attn_norm.weight   |     32     |\n",
      "|   backbone.encoder.encoder.3.attn_norm.bias    |     32     |\n",
      "|    backbone.encoder.encoder.3.pwff.0.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.3.pwff.0.bias     |     32     |\n",
      "|    backbone.encoder.encoder.3.pwff.3.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.3.pwff.3.bias     |     32     |\n",
      "|   backbone.encoder.encoder.3.ff_norm.weight    |     32     |\n",
      "|    backbone.encoder.encoder.3.ff_norm.bias     |     32     |\n",
      "|   backbone.encoder.encoder.4.mha.W_Q.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.4.mha.W_Q.bias     |     32     |\n",
      "|   backbone.encoder.encoder.4.mha.W_K.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.4.mha.W_K.bias     |     32     |\n",
      "|   backbone.encoder.encoder.4.mha.W_V.weight    |    1024    |\n",
      "|    backbone.encoder.encoder.4.mha.W_V.bias     |     32     |\n",
      "| backbone.encoder.encoder.4.mha.to_out.0.weight |    1024    |\n",
      "|  backbone.encoder.encoder.4.mha.to_out.0.bias  |     32     |\n",
      "|  backbone.encoder.encoder.4.attn_norm.weight   |     32     |\n",
      "|   backbone.encoder.encoder.4.attn_norm.bias    |     32     |\n",
      "|    backbone.encoder.encoder.4.pwff.0.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.4.pwff.0.bias     |     32     |\n",
      "|    backbone.encoder.encoder.4.pwff.3.weight    |    1024    |\n",
      "|     backbone.encoder.encoder.4.pwff.3.bias     |     32     |\n",
      "|   backbone.encoder.encoder.4.ff_norm.weight    |     32     |\n",
      "|    backbone.encoder.encoder.4.ff_norm.bias     |     32     |\n",
      "|          backbone.encoder.norm.weight          |     32     |\n",
      "|           backbone.encoder.norm.bias           |     32     |\n",
      "|                 head.2.weight                  |     64     |\n",
      "|                  head.2.bias                   |     1      |\n",
      "+------------------------------------------------+------------+\n",
      "Total Trainable Params: 33153\n"
     ]
    }
   ],
   "source": [
    "tsit_model = tsai.all.TSiT(\n",
    "    c_in=input_features_length,\n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    d_model=32,\n",
    "    depth=5,\n",
    "    n_heads=16,\n",
    "    act='gelu',\n",
    "    lsa=False,\n",
    "    attn_dropout=0.3,\n",
    "    dropout=0,\n",
    "    drop_path_rate=0,\n",
    "    mlp_ratio=1,\n",
    "    qkv_bias=True,\n",
    "    pre_norm=True,\n",
    "    use_token=False, # use_token set to False as c_out == 1\n",
    "    use_pe=True,\n",
    "    cat_pos=None,\n",
    "    n_cat_embeds=None,\n",
    "    cat_embed_dims=None,\n",
    "    cat_padding_idxs=None,\n",
    "    token_size=None,\n",
    "    tokenizer=None,\n",
    "    feature_extractor=None,\n",
    "    flatten=False,\n",
    "    concat_pool=True,\n",
    "    fc_dropout=0.1,\n",
    "    use_bn=False,\n",
    "    bias_init=None,\n",
    "    y_range=None,\n",
    "    custom_head=None,\n",
    ")\n",
    "_ = count_model_parameters(tsit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+------------+\n",
      "|                    Modules                     | Parameters |\n",
      "+------------------------------------------------+------------+\n",
      "|               backbone.pos_embed               |    640     |\n",
      "|               backbone.cls_token               |    128     |\n",
      "|          backbone.linear_proj.weight           |    1920    |\n",
      "|           backbone.linear_proj.bias            |    128     |\n",
      "|   backbone.encoder.encoder.0.mha.W_Q.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.0.mha.W_Q.bias     |    128     |\n",
      "|   backbone.encoder.encoder.0.mha.W_K.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.0.mha.W_K.bias     |    128     |\n",
      "|   backbone.encoder.encoder.0.mha.W_V.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.0.mha.W_V.bias     |    128     |\n",
      "| backbone.encoder.encoder.0.mha.to_out.0.weight |   16384    |\n",
      "|  backbone.encoder.encoder.0.mha.to_out.0.bias  |    128     |\n",
      "|  backbone.encoder.encoder.0.attn_norm.weight   |    128     |\n",
      "|   backbone.encoder.encoder.0.attn_norm.bias    |    128     |\n",
      "|    backbone.encoder.encoder.0.pwff.0.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.0.pwff.0.bias     |    128     |\n",
      "|    backbone.encoder.encoder.0.pwff.3.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.0.pwff.3.bias     |    128     |\n",
      "|   backbone.encoder.encoder.0.ff_norm.weight    |    128     |\n",
      "|    backbone.encoder.encoder.0.ff_norm.bias     |    128     |\n",
      "|   backbone.encoder.encoder.1.mha.W_Q.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.1.mha.W_Q.bias     |    128     |\n",
      "|   backbone.encoder.encoder.1.mha.W_K.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.1.mha.W_K.bias     |    128     |\n",
      "|   backbone.encoder.encoder.1.mha.W_V.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.1.mha.W_V.bias     |    128     |\n",
      "| backbone.encoder.encoder.1.mha.to_out.0.weight |   16384    |\n",
      "|  backbone.encoder.encoder.1.mha.to_out.0.bias  |    128     |\n",
      "|  backbone.encoder.encoder.1.attn_norm.weight   |    128     |\n",
      "|   backbone.encoder.encoder.1.attn_norm.bias    |    128     |\n",
      "|    backbone.encoder.encoder.1.pwff.0.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.1.pwff.0.bias     |    128     |\n",
      "|    backbone.encoder.encoder.1.pwff.3.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.1.pwff.3.bias     |    128     |\n",
      "|   backbone.encoder.encoder.1.ff_norm.weight    |    128     |\n",
      "|    backbone.encoder.encoder.1.ff_norm.bias     |    128     |\n",
      "|   backbone.encoder.encoder.2.mha.W_Q.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.2.mha.W_Q.bias     |    128     |\n",
      "|   backbone.encoder.encoder.2.mha.W_K.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.2.mha.W_K.bias     |    128     |\n",
      "|   backbone.encoder.encoder.2.mha.W_V.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.2.mha.W_V.bias     |    128     |\n",
      "| backbone.encoder.encoder.2.mha.to_out.0.weight |   16384    |\n",
      "|  backbone.encoder.encoder.2.mha.to_out.0.bias  |    128     |\n",
      "|  backbone.encoder.encoder.2.attn_norm.weight   |    128     |\n",
      "|   backbone.encoder.encoder.2.attn_norm.bias    |    128     |\n",
      "|    backbone.encoder.encoder.2.pwff.0.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.2.pwff.0.bias     |    128     |\n",
      "|    backbone.encoder.encoder.2.pwff.3.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.2.pwff.3.bias     |    128     |\n",
      "|   backbone.encoder.encoder.2.ff_norm.weight    |    128     |\n",
      "|    backbone.encoder.encoder.2.ff_norm.bias     |    128     |\n",
      "|   backbone.encoder.encoder.3.mha.W_Q.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.3.mha.W_Q.bias     |    128     |\n",
      "|   backbone.encoder.encoder.3.mha.W_K.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.3.mha.W_K.bias     |    128     |\n",
      "|   backbone.encoder.encoder.3.mha.W_V.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.3.mha.W_V.bias     |    128     |\n",
      "| backbone.encoder.encoder.3.mha.to_out.0.weight |   16384    |\n",
      "|  backbone.encoder.encoder.3.mha.to_out.0.bias  |    128     |\n",
      "|  backbone.encoder.encoder.3.attn_norm.weight   |    128     |\n",
      "|   backbone.encoder.encoder.3.attn_norm.bias    |    128     |\n",
      "|    backbone.encoder.encoder.3.pwff.0.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.3.pwff.0.bias     |    128     |\n",
      "|    backbone.encoder.encoder.3.pwff.3.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.3.pwff.3.bias     |    128     |\n",
      "|   backbone.encoder.encoder.3.ff_norm.weight    |    128     |\n",
      "|    backbone.encoder.encoder.3.ff_norm.bias     |    128     |\n",
      "|   backbone.encoder.encoder.4.mha.W_Q.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.4.mha.W_Q.bias     |    128     |\n",
      "|   backbone.encoder.encoder.4.mha.W_K.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.4.mha.W_K.bias     |    128     |\n",
      "|   backbone.encoder.encoder.4.mha.W_V.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.4.mha.W_V.bias     |    128     |\n",
      "| backbone.encoder.encoder.4.mha.to_out.0.weight |   16384    |\n",
      "|  backbone.encoder.encoder.4.mha.to_out.0.bias  |    128     |\n",
      "|  backbone.encoder.encoder.4.attn_norm.weight   |    128     |\n",
      "|   backbone.encoder.encoder.4.attn_norm.bias    |    128     |\n",
      "|    backbone.encoder.encoder.4.pwff.0.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.4.pwff.0.bias     |    128     |\n",
      "|    backbone.encoder.encoder.4.pwff.3.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.4.pwff.3.bias     |    128     |\n",
      "|   backbone.encoder.encoder.4.ff_norm.weight    |    128     |\n",
      "|    backbone.encoder.encoder.4.ff_norm.bias     |    128     |\n",
      "|   backbone.encoder.encoder.5.mha.W_Q.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.5.mha.W_Q.bias     |    128     |\n",
      "|   backbone.encoder.encoder.5.mha.W_K.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.5.mha.W_K.bias     |    128     |\n",
      "|   backbone.encoder.encoder.5.mha.W_V.weight    |   16384    |\n",
      "|    backbone.encoder.encoder.5.mha.W_V.bias     |    128     |\n",
      "| backbone.encoder.encoder.5.mha.to_out.0.weight |   16384    |\n",
      "|  backbone.encoder.encoder.5.mha.to_out.0.bias  |    128     |\n",
      "|  backbone.encoder.encoder.5.attn_norm.weight   |    128     |\n",
      "|   backbone.encoder.encoder.5.attn_norm.bias    |    128     |\n",
      "|    backbone.encoder.encoder.5.pwff.0.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.5.pwff.0.bias     |    128     |\n",
      "|    backbone.encoder.encoder.5.pwff.3.weight    |   16384    |\n",
      "|     backbone.encoder.encoder.5.pwff.3.bias     |    128     |\n",
      "|   backbone.encoder.encoder.5.ff_norm.weight    |    128     |\n",
      "|    backbone.encoder.encoder.5.ff_norm.bias     |    128     |\n",
      "|          backbone.encoder.norm.weight          |    128     |\n",
      "|           backbone.encoder.norm.bias           |    128     |\n",
      "|                 head.2.weight                  |    256     |\n",
      "|                  head.2.bias                   |     1      |\n",
      "+------------------------------------------------+------------+\n",
      "Total Trainable Params: 600833\n"
     ]
    }
   ],
   "source": [
    "# number of parameters for default HPs\n",
    "tsit_model = tsai.all.TSiT(\n",
    "    c_in=input_features_length,\n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    d_model=128,\n",
    "    depth=6,\n",
    "    n_heads=16,\n",
    "    act='gelu',\n",
    "    lsa=False,\n",
    "    attn_dropout=0.3,\n",
    "    dropout=0,\n",
    "    drop_path_rate=0,\n",
    "    mlp_ratio=1,\n",
    "    qkv_bias=True,\n",
    "    pre_norm=True,\n",
    "    use_token=False, # use_token set to False as c_out == 1\n",
    "    use_pe=True,\n",
    "    cat_pos=None,\n",
    "    n_cat_embeds=None,\n",
    "    cat_embed_dims=None,\n",
    "    cat_padding_idxs=None,\n",
    "    token_size=None,\n",
    "    tokenizer=None,\n",
    "    feature_extractor=None,\n",
    "    flatten=False,\n",
    "    concat_pool=True,\n",
    "    fc_dropout=0.1,\n",
    "    use_bn=False,\n",
    "    bias_init=None,\n",
    "    y_range=None,\n",
    "    custom_head=None,\n",
    ")\n",
    "_ = count_model_parameters(tsit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------+\n",
      "|                 Modules                  | Parameters |\n",
      "+------------------------------------------+------------+\n",
      "|                  W_pos                   |    160     |\n",
      "|                W_P.weight                |    480     |\n",
      "|                 W_P.bias                 |     32     |\n",
      "|  encoder.layers.0.self_attn.W_Q.weight   |    1024    |\n",
      "|  encoder.layers.0.self_attn.W_K.weight   |    1024    |\n",
      "|  encoder.layers.0.self_attn.W_V.weight   |    1024    |\n",
      "|  encoder.layers.0.self_attn.W_O.weight   |    1024    |\n",
      "| encoder.layers.0.batchnorm_attn.1.weight |     32     |\n",
      "|  encoder.layers.0.batchnorm_attn.1.bias  |     32     |\n",
      "|       encoder.layers.0.ff.0.weight       |    8192    |\n",
      "|        encoder.layers.0.ff.0.bias        |    256     |\n",
      "|       encoder.layers.0.ff.3.weight       |    8192    |\n",
      "|        encoder.layers.0.ff.3.bias        |     32     |\n",
      "| encoder.layers.0.batchnorm_ffn.1.weight  |     32     |\n",
      "|  encoder.layers.0.batchnorm_ffn.1.bias   |     32     |\n",
      "|              head.2.weight               |    160     |\n",
      "|               head.2.bias                |     1      |\n",
      "+------------------------------------------+------------+\n",
      "Total Trainable Params: 21729\n"
     ]
    }
   ],
   "source": [
    "tst_model = tsai.all.TST(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    n_layers=1,\n",
    "    d_model=32,\n",
    "    n_heads=16,\n",
    "    d_k=None,\n",
    "    d_v=None,\n",
    "    d_ff=256,\n",
    "    dropout=0.1,\n",
    "    act='gelu',\n",
    "    fc_dropout=0.\n",
    "    )\n",
    "_ = count_model_parameters(tst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------+\n",
      "|                 Modules                  | Parameters |\n",
      "+------------------------------------------+------------+\n",
      "|                  W_pos                   |    640     |\n",
      "|                W_P.weight                |    1920    |\n",
      "|                 W_P.bias                 |    128     |\n",
      "|  encoder.layers.0.self_attn.W_Q.weight   |   16384    |\n",
      "|  encoder.layers.0.self_attn.W_K.weight   |   16384    |\n",
      "|  encoder.layers.0.self_attn.W_V.weight   |   16384    |\n",
      "|  encoder.layers.0.self_attn.W_O.weight   |   16384    |\n",
      "| encoder.layers.0.batchnorm_attn.1.weight |    128     |\n",
      "|  encoder.layers.0.batchnorm_attn.1.bias  |    128     |\n",
      "|       encoder.layers.0.ff.0.weight       |   32768    |\n",
      "|        encoder.layers.0.ff.0.bias        |    256     |\n",
      "|       encoder.layers.0.ff.3.weight       |   32768    |\n",
      "|        encoder.layers.0.ff.3.bias        |    128     |\n",
      "| encoder.layers.0.batchnorm_ffn.1.weight  |    128     |\n",
      "|  encoder.layers.0.batchnorm_ffn.1.bias   |    128     |\n",
      "|  encoder.layers.1.self_attn.W_Q.weight   |   16384    |\n",
      "|  encoder.layers.1.self_attn.W_K.weight   |   16384    |\n",
      "|  encoder.layers.1.self_attn.W_V.weight   |   16384    |\n",
      "|  encoder.layers.1.self_attn.W_O.weight   |   16384    |\n",
      "| encoder.layers.1.batchnorm_attn.1.weight |    128     |\n",
      "|  encoder.layers.1.batchnorm_attn.1.bias  |    128     |\n",
      "|       encoder.layers.1.ff.0.weight       |   32768    |\n",
      "|        encoder.layers.1.ff.0.bias        |    256     |\n",
      "|       encoder.layers.1.ff.3.weight       |   32768    |\n",
      "|        encoder.layers.1.ff.3.bias        |    128     |\n",
      "| encoder.layers.1.batchnorm_ffn.1.weight  |    128     |\n",
      "|  encoder.layers.1.batchnorm_ffn.1.bias   |    128     |\n",
      "|  encoder.layers.2.self_attn.W_Q.weight   |   16384    |\n",
      "|  encoder.layers.2.self_attn.W_K.weight   |   16384    |\n",
      "|  encoder.layers.2.self_attn.W_V.weight   |   16384    |\n",
      "|  encoder.layers.2.self_attn.W_O.weight   |   16384    |\n",
      "| encoder.layers.2.batchnorm_attn.1.weight |    128     |\n",
      "|  encoder.layers.2.batchnorm_attn.1.bias  |    128     |\n",
      "|       encoder.layers.2.ff.0.weight       |   32768    |\n",
      "|        encoder.layers.2.ff.0.bias        |    256     |\n",
      "|       encoder.layers.2.ff.3.weight       |   32768    |\n",
      "|        encoder.layers.2.ff.3.bias        |    128     |\n",
      "| encoder.layers.2.batchnorm_ffn.1.weight  |    128     |\n",
      "|  encoder.layers.2.batchnorm_ffn.1.bias   |    128     |\n",
      "|              head.2.weight               |    640     |\n",
      "|               head.2.bias                |     1      |\n",
      "+------------------------------------------+------------+\n",
      "Total Trainable Params: 399233\n"
     ]
    }
   ],
   "source": [
    "# number of parameters for default HPs\n",
    "tst_model = tsai.all.TST(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    n_layers=3,\n",
    "    d_model=128,\n",
    "    n_heads=16,\n",
    "    d_k=None,\n",
    "    d_v=None,\n",
    "    d_ff=256,\n",
    "    dropout=0.1,\n",
    "    act='gelu',\n",
    "    fc_dropout=0.\n",
    "    )\n",
    "_ = count_model_parameters(tst_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "|         Modules         | Parameters |\n",
      "+-------------------------+------------+\n",
      "|   conv2dblock.1.weight  |    640     |\n",
      "|    conv2dblock.1.bias   |    128     |\n",
      "|   conv2dblock.2.weight  |    128     |\n",
      "|    conv2dblock.2.bias   |    128     |\n",
      "| conv2d1x1block.0.weight |    128     |\n",
      "|  conv2d1x1block.0.bias  |     1      |\n",
      "|   conv1dblock.0.weight  |    9600    |\n",
      "|    conv1dblock.0.bias   |    128     |\n",
      "|   conv1dblock.1.weight  |    128     |\n",
      "|    conv1dblock.1.bias   |    128     |\n",
      "| conv1d1x1block.0.weight |    128     |\n",
      "|  conv1d1x1block.0.bias  |     1      |\n",
      "|     conv1d.0.weight     |   10240    |\n",
      "|      conv1d.0.bias      |    128     |\n",
      "|     conv1d.1.weight     |    128     |\n",
      "|      conv1d.1.bias      |    128     |\n",
      "|     head.1.0.weight     |    128     |\n",
      "|      head.1.0.bias      |     1      |\n",
      "+-------------------------+------------+\n",
      "Total Trainable Params: 22019\n"
     ]
    }
   ],
   "source": [
    "xcm_model = tsai.all.XCM(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    window_perc=1,\n",
    "    flatten=False,\n",
    "    concat_pool=False,\n",
    "    fc_dropout=0,\n",
    "    bn=False,\n",
    "    y_range=None,\n",
    "    )\n",
    "_ = count_model_parameters(xcm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OmniScaleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------+\n",
      "|             Modules             | Parameters |\n",
      "+---------------------------------+------------+\n",
      "| net.0.conv_list.0.conv1d.weight |    1020    |\n",
      "|  net.0.conv_list.0.conv1d.bias  |     68     |\n",
      "|   net.0.conv_list.0.bn.weight   |     68     |\n",
      "|    net.0.conv_list.0.bn.bias    |     68     |\n",
      "| net.1.conv_list.0.conv1d.weight |   229364   |\n",
      "|  net.1.conv_list.0.conv1d.bias  |    3373    |\n",
      "|   net.1.conv_list.0.bn.weight   |    3373    |\n",
      "|    net.1.conv_list.0.bn.bias    |    3373    |\n",
      "| net.2.conv_list.0.conv1d.weight |  3453952   |\n",
      "|  net.2.conv_list.0.conv1d.bias  |    1024    |\n",
      "|   net.2.conv_list.0.bn.weight   |    1024    |\n",
      "|    net.2.conv_list.0.bn.bias    |    1024    |\n",
      "| net.2.conv_list.1.conv1d.weight |  6907904   |\n",
      "|  net.2.conv_list.1.conv1d.bias  |    1024    |\n",
      "|   net.2.conv_list.1.bn.weight   |    1024    |\n",
      "|    net.2.conv_list.1.bn.bias    |    1024    |\n",
      "|          hidden.weight          |    2048    |\n",
      "|           hidden.bias           |     1      |\n",
      "+---------------------------------+------------+\n",
      "Total Trainable Params: 10610756\n"
     ]
    }
   ],
   "source": [
    "omniscalecnn_model = tsai.all.OmniScaleCNN(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1,\n",
    "    seq_len=seq_len,\n",
    "    few_shot=False,\n",
    "    layers=[8*128, 5 * 128 * 256 + 2 * 256  *128]\n",
    "    )\n",
    "_ = count_model_parameters(omniscalecnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------------+\n",
      "|            Modules            | Parameters |\n",
      "+-------------------------------+------------+\n",
      "| resblock1.convblock1.0.weight |    6720    |\n",
      "| resblock1.convblock1.1.weight |     64     |\n",
      "|  resblock1.convblock1.1.bias  |     64     |\n",
      "| resblock1.convblock2.0.weight |   20480    |\n",
      "| resblock1.convblock2.1.weight |     64     |\n",
      "|  resblock1.convblock2.1.bias  |     64     |\n",
      "| resblock1.convblock3.0.weight |   12288    |\n",
      "| resblock1.convblock3.1.weight |     64     |\n",
      "|  resblock1.convblock3.1.bias  |     64     |\n",
      "|  resblock1.shortcut.0.weight  |    960     |\n",
      "|  resblock1.shortcut.1.weight  |     64     |\n",
      "|   resblock1.shortcut.1.bias   |     64     |\n",
      "| resblock2.convblock1.0.weight |   57344    |\n",
      "| resblock2.convblock1.1.weight |    128     |\n",
      "|  resblock2.convblock1.1.bias  |    128     |\n",
      "| resblock2.convblock2.0.weight |   81920    |\n",
      "| resblock2.convblock2.1.weight |    128     |\n",
      "|  resblock2.convblock2.1.bias  |    128     |\n",
      "| resblock2.convblock3.0.weight |   49152    |\n",
      "| resblock2.convblock3.1.weight |    128     |\n",
      "|  resblock2.convblock3.1.bias  |    128     |\n",
      "|  resblock2.shortcut.0.weight  |    8192    |\n",
      "|  resblock2.shortcut.1.weight  |    128     |\n",
      "|   resblock2.shortcut.1.bias   |    128     |\n",
      "| resblock3.convblock1.0.weight |   114688   |\n",
      "| resblock3.convblock1.1.weight |    128     |\n",
      "|  resblock3.convblock1.1.bias  |    128     |\n",
      "| resblock3.convblock2.0.weight |   81920    |\n",
      "| resblock3.convblock2.1.weight |    128     |\n",
      "|  resblock3.convblock2.1.bias  |    128     |\n",
      "| resblock3.convblock3.0.weight |   49152    |\n",
      "| resblock3.convblock3.1.weight |    128     |\n",
      "|  resblock3.convblock3.1.bias  |    128     |\n",
      "|   resblock3.shortcut.weight   |    128     |\n",
      "|    resblock3.shortcut.bias    |    128     |\n",
      "|           fc.weight           |    128     |\n",
      "|            fc.bias            |     1      |\n",
      "+-------------------------------+------------+\n",
      "Total Trainable Params: 485505\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tsai.all.ResNet(\n",
    "    c_in=input_features_length, \n",
    "    c_out=1)\n",
    "_ = count_model_parameters(resnet_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
