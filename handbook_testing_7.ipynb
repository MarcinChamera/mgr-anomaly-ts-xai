{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "\n",
    "@book{leborgne2022fraud,\n",
    "\n",
    "title={Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook},\n",
    "\n",
    "author={Le Borgne, Yann-A{\\\"e}l and Siblini, Wissam and Lebichot, Bertrand and Bontempi, Gianluca},\n",
    "\n",
    "url={https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook},\n",
    "\n",
    "year={2022},\n",
    "\n",
    "publisher={Universit{\\'e} Libre de Bruxelles}\n",
    "\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covered subchapters:\n",
    "* 7.3 Autoencoders and anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run shared_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run my_shared_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 414 ms\n",
      "919767 transactions loaded, containing 8195 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT = '../fraud-detection-handbook/simulated-data-transformed/data/'\n",
    "\n",
    "BEGIN_DATE = \"2018-06-11\"\n",
    "END_DATE = \"2018-09-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
    "\n",
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the starting day for the training period, and the deltas\n",
    "start_date_training = datetime.datetime.strptime(\"2018-07-25\", \"%Y-%m-%d\")\n",
    "delta_train=7\n",
    "delta_delay=7\n",
    "delta_test=7\n",
    "\n",
    "\n",
    "delta_valid = delta_test\n",
    "\n",
    "start_date_training_with_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "\n",
    "(train_df, valid_df)=get_train_test_set(transactions_df,start_date_training_with_valid,\n",
    "                                       delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_test)\n",
    "\n",
    "# By default, scales input data\n",
    "(train_df, valid_df)=scaleData(train_df, valid_df,input_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "x_valid = torch.FloatTensor(valid_df[input_features].values)\n",
    "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "y_valid = torch.FloatTensor(valid_df[output_feature].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = FraudDatasetUnsupervised(x_train.to(DEVICE))\n",
    "valid_set = FraudDatasetUnsupervised(x_valid.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator,valid_generator = prepare_generators(training_set, valid_set, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleAutoencoder(len(input_features), 100,20).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2b953ac70e4553bd65938026f5cf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221221_172517-2auayc6t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/2auayc6t\" target=\"_blank\">daily-night-8</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_autoencoder = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    intermediate_size = 100,\n",
    "    code_size = 20,\n",
    "    optimizer='adam',\n",
    "    lr=0.0001,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=2,\n",
    "    max_epochs=500,\n",
    "    scale=True,\n",
    "    criterion='mse'\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config_autoencoder, tags=['autoencoder', 'imbalance-not-considered'])\n",
    "config_autoencoder = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.4457242426962857\n",
      "valid loss: 0.11789110761766877\n",
      "New best score: 0.11789110761766877\n",
      "\n",
      "Epoch 1: train loss: 0.08445227285758031\n",
      "valid loss: 0.044737996382872916\n",
      "New best score: 0.044737996382872916\n",
      "\n",
      "Epoch 2: train loss: 0.038134472722447625\n",
      "valid loss: 0.028129172819803972\n",
      "New best score: 0.028129172819803972\n",
      "\n",
      "Epoch 3: train loss: 0.02394542537440847\n",
      "valid loss: 0.016839713429207686\n",
      "New best score: 0.016839713429207686\n",
      "\n",
      "Epoch 4: train loss: 0.013856798302681394\n",
      "valid loss: 0.009604576979687468\n",
      "New best score: 0.009604576979687468\n",
      "\n",
      "Epoch 5: train loss: 0.007683096453992661\n",
      "valid loss: 0.005340768664037107\n",
      "New best score: 0.005340768664037107\n",
      "\n",
      "Epoch 6: train loss: 0.005278768580599223\n",
      "valid loss: 0.004115462709533794\n",
      "New best score: 0.004115462709533794\n",
      "\n",
      "Epoch 7: train loss: 0.004053215772700612\n",
      "valid loss: 0.003135705668265458\n",
      "New best score: 0.003135705668265458\n",
      "\n",
      "Epoch 8: train loss: 0.0030779137747339105\n",
      "valid loss: 0.002502949561674372\n",
      "New best score: 0.002502949561674372\n",
      "\n",
      "Epoch 9: train loss: 0.0024888100696640377\n",
      "valid loss: 0.002192010166367791\n",
      "New best score: 0.002192010166367791\n",
      "\n",
      "Epoch 10: train loss: 0.0021338777523799432\n",
      "valid loss: 0.0018397382588400582\n",
      "New best score: 0.0018397382588400582\n",
      "\n",
      "Epoch 11: train loss: 0.001856876660185558\n",
      "valid loss: 0.0016029476445763692\n",
      "New best score: 0.0016029476445763692\n",
      "\n",
      "Epoch 12: train loss: 0.0016323591180254365\n",
      "valid loss: 0.0014201604700749078\n",
      "New best score: 0.0014201604700749078\n",
      "\n",
      "Epoch 13: train loss: 0.0014395096146632485\n",
      "valid loss: 0.0012285073982460089\n",
      "New best score: 0.0012285073982460089\n",
      "\n",
      "Epoch 14: train loss: 0.0012724622143062995\n",
      "valid loss: 0.0010776552875192908\n",
      "New best score: 0.0010776552875192908\n",
      "\n",
      "Epoch 15: train loss: 0.001127805371401942\n",
      "valid loss: 0.0009668350371130096\n",
      "New best score: 0.0009668350371130096\n",
      "\n",
      "Epoch 16: train loss: 0.0009997081281759742\n",
      "valid loss: 0.000836825860973417\n",
      "New best score: 0.000836825860973417\n",
      "\n",
      "Epoch 17: train loss: 0.000880098745596807\n",
      "valid loss: 0.0007501458344584117\n",
      "New best score: 0.0007501458344584117\n",
      "\n",
      "Epoch 18: train loss: 0.0007860685528294285\n",
      "valid loss: 0.0006711421276778594\n",
      "New best score: 0.0006711421276778594\n",
      "\n",
      "Epoch 19: train loss: 0.000695656446567968\n",
      "valid loss: 0.0006044107785733427\n",
      "New best score: 0.0006044107785733427\n",
      "\n",
      "Epoch 20: train loss: 0.0006245430018579192\n",
      "valid loss: 0.0005757165843076353\n",
      "New best score: 0.0005757165843076353\n",
      "\n",
      "Epoch 21: train loss: 0.0005636120727129929\n",
      "valid loss: 0.00045544422997220274\n",
      "New best score: 0.00045544422997220274\n",
      "\n",
      "Epoch 22: train loss: 0.0005043041292883155\n",
      "valid loss: 0.0004284143736369684\n",
      "New best score: 0.0004284143736369684\n",
      "\n",
      "Epoch 23: train loss: 0.0004545702795231186\n",
      "valid loss: 0.0004355047466526001\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 24: train loss: 0.00041356756289618224\n",
      "valid loss: 0.0004384790375113711\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 25: train loss: 0.0003753297742550577\n",
      "valid loss: 0.0003432235950406875\n",
      "New best score: 0.0003432235950406875\n",
      "\n",
      "Epoch 26: train loss: 0.00034048777124066535\n",
      "valid loss: 0.0002818920442282955\n",
      "New best score: 0.0002818920442282955\n",
      "\n",
      "Epoch 27: train loss: 0.0003102164250298472\n",
      "valid loss: 0.0003018340724393155\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 28: train loss: 0.00028284459131969945\n",
      "valid loss: 0.00022187937495010508\n",
      "New best score: 0.00022187937495010508\n",
      "\n",
      "Epoch 29: train loss: 0.0002634899137496243\n",
      "valid loss: 0.00019738005846834237\n",
      "New best score: 0.00019738005846834237\n",
      "\n",
      "Epoch 30: train loss: 0.00023631249352606582\n",
      "valid loss: 0.00019916365451282502\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 31: train loss: 0.00022112570572980586\n",
      "valid loss: 0.0001945047284736644\n",
      "New best score: 0.0001945047284736644\n",
      "\n",
      "Epoch 32: train loss: 0.0002088578451654607\n",
      "valid loss: 0.00015512093453705591\n",
      "New best score: 0.00015512093453705591\n",
      "\n",
      "Epoch 33: train loss: 0.0001928125529018412\n",
      "valid loss: 0.00015401486271599186\n",
      "New best score: 0.00015401486271599186\n",
      "\n",
      "Epoch 34: train loss: 0.00018271827830037215\n",
      "valid loss: 0.00014810691831510672\n",
      "New best score: 0.00014810691831510672\n",
      "\n",
      "Epoch 35: train loss: 0.00017240822395933286\n",
      "valid loss: 0.00015260653251901655\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 36: train loss: 0.00016020971615353033\n",
      "valid loss: 0.00011780743550873727\n",
      "New best score: 0.00011780743550873727\n",
      "\n",
      "Epoch 37: train loss: 0.00014543509366531156\n",
      "valid loss: 0.0001151307768567244\n",
      "New best score: 0.0001151307768567244\n",
      "\n",
      "Epoch 38: train loss: 0.00014119981018801935\n",
      "valid loss: 0.0001708969060898392\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 39: train loss: 0.00013542973382221136\n",
      "valid loss: 0.00011758325632856879\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 40: train loss: 0.0001263651879117487\n",
      "valid loss: 9.595048929734189e-05\n",
      "New best score: 9.595048929734189e-05\n",
      "\n",
      "Epoch 41: train loss: 0.00012185814163192838\n",
      "valid loss: 9.394778501159063e-05\n",
      "New best score: 9.394778501159063e-05\n",
      "\n",
      "Epoch 42: train loss: 0.00011642446037926735\n",
      "valid loss: 0.00010734898410912456\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 43: train loss: 0.00010992666505637532\n",
      "valid loss: 8.62396804729885e-05\n",
      "New best score: 8.62396804729885e-05\n",
      "\n",
      "Epoch 44: train loss: 0.00010587167951139435\n",
      "valid loss: 9.441669341564799e-05\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 45: train loss: 9.920142742737404e-05\n",
      "valid loss: 8.044177231140615e-05\n",
      "New best score: 8.044177231140615e-05\n",
      "\n",
      "Epoch 46: train loss: 9.528680670908835e-05\n",
      "valid loss: 8.012708636332186e-05\n",
      "New best score: 8.012708636332186e-05\n",
      "\n",
      "Epoch 47: train loss: 8.939813683729054e-05\n",
      "valid loss: 7.294435460006569e-05\n",
      "New best score: 7.294435460006569e-05\n",
      "\n",
      "Epoch 48: train loss: 8.822322454624508e-05\n",
      "valid loss: 6.524856979837845e-05\n",
      "New best score: 6.524856979837845e-05\n",
      "\n",
      "Epoch 49: train loss: 8.43317038508643e-05\n",
      "valid loss: 8.852920780684213e-05\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 50: train loss: 7.922769837405804e-05\n",
      "valid loss: 7.012833800908595e-05\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 51: train loss: 7.581647901351067e-05\n",
      "valid loss: 7.023764267470624e-05\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model,training_execution_time_autoencoder,train_losses,valid_losses = training_loop_and_saving_best_wandb(model,training_generator,valid_generator,optimizer,criterion,\n",
    "                                                            max_epochs=500,verbose=True, save_path='models/DL/autoencoder/simple_autoencoder_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.35099e-05, 2.8576625e-05, 3.6815803e-05, 4.5891364e-05, 3.6327274e-05]\n",
      "7.027291e-05\n"
     ]
    }
   ],
   "source": [
    "train_reconstruction = per_sample_mse_no_grad(model, training_generator)\n",
    "start_time=time.time()\n",
    "valid_reconstruction = per_sample_mse_no_grad(model, valid_generator)\n",
    "prediction_execution_time=time.time()-start_time\n",
    "print(valid_reconstruction[0:5])\n",
    "print(np.mean(valid_reconstruction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1323, -0.6306,  2.1808, -0.3003,  0.1241, -1.6917,  0.5035, -1.6630,\n",
      "        -0.0482, -0.9810, -0.0816, -1.9895, -0.1231, -0.9719, -0.1436])\n",
      "tensor([-0.1360, -0.6272,  2.1803, -0.2967,  0.1200, -1.6987,  0.5019, -1.6772,\n",
      "        -0.0493, -0.9762, -0.0749, -1.9800, -0.1180, -0.9697, -0.1373],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(model(x_train[0].to(DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fraud reconstruction error: 0.0013619309\n",
      "Average genuine reconstruction error: 6.196271e-05\n"
     ]
    }
   ],
   "source": [
    "genuine_losses = np.array(valid_reconstruction)[y_valid.cpu().numpy() == 0]\n",
    "fraud_losses = np.array(valid_reconstruction)[y_valid.cpu().numpy() == 1]\n",
    "print(\"Average fraud reconstruction error:\", np.mean(fraud_losses))\n",
    "print(\"Average genuine reconstruction error:\", np.mean(genuine_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282.9442689418793\n",
      "1.1509997844696045\n"
     ]
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time_autoencoder})\n",
    "print(training_execution_time_autoencoder)\n",
    "print(prediction_execution_time)\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0     0.84              0.163       0.0                 0.2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df=valid_df\n",
    "predictions_df['predictions']=valid_reconstruction\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\autoencoder)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3851ba4265694f7bb59125a2a6572d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.84</td></tr><tr><td>Average precision</td><td>0.163</td></tr><tr><td>Card Precision@100</td><td>0.2</td></tr><tr><td>F1 score</td><td>0.0</td></tr><tr><td>Prediction execution time</td><td>1.151</td></tr><tr><td>Training execution time</td><td>282.94427</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>val loss</td><td>7e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">daily-night-8</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/2auayc6t\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/2auayc6t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221221_172517-2auayc6t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "autoenc_artifact = wandb.Artifact('autoencoder', type='autoencoder', description='trained simple autoencoder')\n",
    "autoenc_artifact.add_dir('models/DL/autoencoder')\n",
    "wandb.log_artifact(autoenc_artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67c6e2d8adc4a60890fea427ae68c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221221_135539-37rryvn2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chamera/mgr-anomaly-ts-xai/runs/37rryvn2\" target=\"_blank\">fragrant-wind-78</a></strong> to <a href=\"https://wandb.ai/chamera/mgr-anomaly-ts-xai\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_if = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    n_estimators = 10,\n",
    "    scale=True,\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config_if, tags=['isolation-forest', 'imbalance-not-considered', 'baseline'])\n",
    "config_if = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.808              0.164     0.046                0.19"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalyclassifier = IsolationForest(random_state=config_if.seed, n_estimators=config_if.n_estimators)\n",
    "start_time=time.time()\n",
    "anomalyclassifier.fit(train_df[input_features])\n",
    "training_execution_time=time.time()-start_time\n",
    "wandb.log({'Training execution time': training_execution_time})\n",
    "predictions_df = valid_df\n",
    "start_time=time.time()\n",
    "predictions_df['predictions'] = -anomalyclassifier.score_samples(valid_df[input_features])\n",
    "prediction_execution_time=time.time()-start_time\n",
    "wandb.log({'Prediction execution time':  prediction_execution_time})\n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "pickle.dump(anomalyclassifier, open('models/baseline/if/isolation_forest_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\baseline\\if)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.808</td></tr><tr><td>Average precision</td><td>0.164</td></tr><tr><td>Card Precision@100</td><td>0.19</td></tr><tr><td>F1 score</td><td>0.046</td></tr><tr><td>Prediction execution time</td><td>0.13</td></tr><tr><td>Training execution time</td><td>0.05999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fragrant-wind-78</strong>: <a href=\"https://wandb.ai/chamera/mgr-anomaly-ts-xai/runs/37rryvn2\" target=\"_blank\">https://wandb.ai/chamera/mgr-anomaly-ts-xai/runs/37rryvn2</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221221_135539-37rryvn2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_artifact = wandb.Artifact('if', type='isolation_forest', description='trained baseline isolation forest')\n",
    "classifier_artifact.add_dir('models/baseline/if')\n",
    "wandb.log_artifact(classifier_artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchamera\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104143e4cf96480b9da67bd0922cbc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221221_151157-3d8imi3e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chamera/mgr-anomaly-ts-xai/runs/3d8imi3e\" target=\"_blank\">earthy-leaf-56</a></strong> to <a href=\"https://wandb.ai/chamera/mgr-anomaly-ts-xai\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('chamera/mgr-anomaly-tsxai-project/autoencoder:v0', type='autoencoder')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semi-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.10162743877167199\n",
      "valid loss: 0.035735654941877054\n",
      "New best score: 0.035735654941877054\n",
      "\n",
      "Epoch 1: train loss: 0.038805231760945136\n",
      "valid loss: 0.026402934476265003\n",
      "New best score: 0.026402934476265003\n",
      "\n",
      "Epoch 2: train loss: 0.03107889258012489\n",
      "valid loss: 0.023788556019404057\n",
      "New best score: 0.023788556019404057\n",
      "\n",
      "Epoch 3: train loss: 0.028793505515616536\n",
      "valid loss: 0.0226955978942862\n",
      "New best score: 0.0226955978942862\n",
      "\n",
      "Epoch 4: train loss: 0.02777124687149608\n",
      "valid loss: 0.022126405810570862\n",
      "New best score: 0.022126405810570862\n",
      "\n",
      "Epoch 5: train loss: 0.026878768456191623\n",
      "valid loss: 0.02189638417524596\n",
      "New best score: 0.02189638417524596\n",
      "\n",
      "Epoch 6: train loss: 0.02616935516404875\n",
      "valid loss: 0.021739530122375797\n",
      "New best score: 0.021739530122375797\n",
      "\n",
      "Epoch 7: train loss: 0.025671390378064197\n",
      "valid loss: 0.020999993936698172\n",
      "New best score: 0.020999993936698172\n",
      "\n",
      "Epoch 8: train loss: 0.02493373950921982\n",
      "valid loss: 0.02112951638670689\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 9: train loss: 0.02499750268157664\n",
      "valid loss: 0.020964671838316108\n",
      "New best score: 0.020964671838316108\n",
      "\n",
      "Epoch 10: train loss: 0.024326281892278197\n",
      "valid loss: 0.02061812084275069\n",
      "New best score: 0.02061812084275069\n",
      "\n",
      "Epoch 11: train loss: 0.024067515392038066\n",
      "valid loss: 0.020553967655417536\n",
      "New best score: 0.020553967655417536\n",
      "\n",
      "Epoch 12: train loss: 0.023930586477827073\n",
      "valid loss: 0.0200293792948595\n",
      "New best score: 0.0200293792948595\n",
      "\n",
      "Epoch 13: train loss: 0.02331075052221895\n",
      "valid loss: 0.02000886902691481\n",
      "New best score: 0.02000886902691481\n",
      "\n",
      "Epoch 14: train loss: 0.023393382868341334\n",
      "valid loss: 0.019777991362246863\n",
      "New best score: 0.019777991362246863\n",
      "\n",
      "Epoch 15: train loss: 0.02325185948856403\n",
      "valid loss: 0.01961279805925232\n",
      "New best score: 0.01961279805925232\n",
      "\n",
      "Epoch 16: train loss: 0.022855810540368563\n",
      "valid loss: 0.01949756133644918\n",
      "New best score: 0.01949756133644918\n",
      "\n",
      "Epoch 17: train loss: 0.022736510263674004\n",
      "valid loss: 0.019463186019960322\n",
      "New best score: 0.019463186019960322\n",
      "\n",
      "Epoch 18: train loss: 0.022446381913904943\n",
      "valid loss: 0.0192712763870196\n",
      "New best score: 0.0192712763870196\n",
      "\n",
      "Epoch 19: train loss: 0.02243082622158738\n",
      "valid loss: 0.019239676777588945\n",
      "New best score: 0.019239676777588945\n",
      "\n",
      "Epoch 20: train loss: 0.02222858941555112\n",
      "valid loss: 0.019080563899908275\n",
      "New best score: 0.019080563899908275\n",
      "\n",
      "Epoch 21: train loss: 0.022107634727885843\n",
      "valid loss: 0.01909825654020991\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 22: train loss: 0.02205043479149812\n",
      "valid loss: 0.019364968685260237\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 23: train loss: 0.021905907053575206\n",
      "valid loss: 0.01888030474850287\n",
      "New best score: 0.01888030474850287\n",
      "\n",
      "Epoch 24: train loss: 0.022007638937237194\n",
      "valid loss: 0.01910090185892692\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 25: train loss: 0.02185481802364954\n",
      "valid loss: 0.018792914988630824\n",
      "New best score: 0.018792914988630824\n",
      "\n",
      "Epoch 26: train loss: 0.02174852257211609\n",
      "valid loss: 0.01964396344805696\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 27: train loss: 0.021581984657182557\n",
      "valid loss: 0.018688938875499442\n",
      "New best score: 0.018688938875499442\n",
      "\n",
      "Epoch 28: train loss: 0.021206104933719612\n",
      "valid loss: 0.018619778697618126\n",
      "New best score: 0.018619778697618126\n",
      "\n",
      "Epoch 29: train loss: 0.021195673777091445\n",
      "valid loss: 0.019023725479495168\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 30: train loss: 0.021145555381614174\n",
      "valid loss: 0.018786671596625056\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 31: train loss: 0.021042767533076212\n",
      "valid loss: 0.018507354738587726\n",
      "New best score: 0.018507354738587726\n",
      "\n",
      "Epoch 32: train loss: 0.02102874953679947\n",
      "valid loss: 0.01848135543236499\n",
      "New best score: 0.01848135543236499\n",
      "\n",
      "Epoch 33: train loss: 0.020856819578124134\n",
      "valid loss: 0.018344052036959536\n",
      "New best score: 0.018344052036959536\n",
      "\n",
      "Epoch 34: train loss: 0.020829317952598844\n",
      "valid loss: 0.01853550426315903\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 35: train loss: 0.020760846491653766\n",
      "valid loss: 0.01835548081842399\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 36: train loss: 0.02084522888883076\n",
      "valid loss: 0.018243833575295947\n",
      "New best score: 0.018243833575295947\n",
      "\n",
      "Epoch 37: train loss: 0.020445502875996023\n",
      "valid loss: 0.018933898863850843\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 38: train loss: 0.020623713465101206\n",
      "valid loss: 0.018348710404714072\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 39: train loss: 0.02058446327585862\n",
      "valid loss: 0.018844509600849994\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "training_set_supervised = FraudDataset(x_train.to(DEVICE), y_train.to(DEVICE))\n",
    "valid_set_supervised = FraudDataset(x_valid.to(DEVICE), y_valid.to(DEVICE))\n",
    "\n",
    "training_generator_supervised,valid_generator_supervised = prepare_generators(training_set_supervised,\n",
    "                                                                              valid_set_supervised,\n",
    "                                                                              batch_size=64)\n",
    "\n",
    "model_supervised = SimpleFraudMLPWithDropout(len(input_features), 1000, 0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model_supervised.parameters(), lr = 0.0001)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "\n",
    "model_supervised,training_execution_time,train_losses_dropout,valid_losses_dropout =\\\n",
    "    training_loop_eval_with_no_grad(model_supervised,\n",
    "                  training_generator_supervised,\n",
    "                  valid_generator_supervised,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0    0.861              0.647     0.671               0.277"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for x_batch, y_batch in valid_generator_supervised: \n",
    "    predictions.append(model_supervised(x_batch.to(DEVICE)).detach().cpu().numpy())\n",
    "\n",
    "predictions_df=valid_df\n",
    "predictions_df['predictions']=np.vstack(predictions)\n",
    "    \n",
    "performance_assessment_f1_included(predictions_df, top_k_list=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = FraudDatasetUnsupervised(x_train.to(DEVICE))\n",
    "valid_set = FraudDatasetUnsupervised(x_valid.to(DEVICE))\n",
    "\n",
    "loader_params = {'batch_size': 64,\n",
    "                 'num_workers': 0}\n",
    "    \n",
    "training_generator = torch.utils.data.DataLoader(training_set, **loader_params)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, **loader_params)\n",
    "\n",
    "train_df[\"reconstruction_error\"] = train_reconstruction\n",
    "valid_df[\"reconstruction_error\"] = valid_reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670269d246a241e09b39b22aa84e3dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\repos\\mgr-anomaly-ts-xai\\wandb\\run-20221221_173237-plmyeu1f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/plmyeu1f\" target=\"_blank\">dark-disco-9</a></strong> to <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_autoencoder = dict(\n",
    "    dataset_id = 'fraud-detection-handbook-transformed-semisupervised',\n",
    "    validation = 'train test split',\n",
    "    seed = 42,\n",
    "    begin_date = '2018-07-25',\n",
    "    delta_train = 7,\n",
    "    delta_delay = 7,\n",
    "    delta_test = 7,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    unsupervised_intermediate_size = 100,\n",
    "    unsupervised_code_size = 20,\n",
    "    unsupervised_optimizer='adam',\n",
    "    unsupervised_lr=0.0001,\n",
    "    unsupervised_early_stopping=True,\n",
    "    unsupervised_early_stopping_patience=2,\n",
    "    unsupervised_max_epochs=500,\n",
    "    unsupervised_scale=True,\n",
    "    unsupervised_criterion='mse',\n",
    "    supervised_hidden_size = 100,\n",
    "    supervised_dropout=0.2,\n",
    "    supervised_optimizer='adam',\n",
    "    supervised_lr=0.0001,\n",
    "    supervised_early_stopping=True,\n",
    "    supervised_early_stopping_patience=2,\n",
    "    supervised_max_epochs=500,\n",
    "    supervised_scale=True,\n",
    "    supervised_criterion='bce',\n",
    ")\n",
    "wandb.init(project=\"mgr-anomaly-tsxai-project\", config=config_autoencoder, tags=['autoencoder', 'mlp', 'semi-supervised', 'imbalance-not-considered'])\n",
    "config_autoencoder = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.3238065295690674\n",
      "valid loss: 0.11897474443489085\n",
      "New best score: 0.11897474443489085\n",
      "\n",
      "Epoch 1: train loss: 0.08699691516790632\n",
      "valid loss: 0.05253201153923254\n",
      "New best score: 0.05253201153923254\n",
      "\n",
      "Epoch 2: train loss: 0.055241820214576236\n",
      "valid loss: 0.039304085049391445\n",
      "New best score: 0.039304085049391445\n",
      "\n",
      "Epoch 3: train loss: 0.04594115533306838\n",
      "valid loss: 0.0347509316652199\n",
      "New best score: 0.0347509316652199\n",
      "\n",
      "Epoch 4: train loss: 0.04037084207419541\n",
      "valid loss: 0.03193916861639648\n",
      "New best score: 0.03193916861639648\n",
      "\n",
      "Epoch 5: train loss: 0.036431323328228175\n",
      "valid loss: 0.030058473223677832\n",
      "New best score: 0.030058473223677832\n",
      "\n",
      "Epoch 6: train loss: 0.03379461977494628\n",
      "valid loss: 0.028923461568170314\n",
      "New best score: 0.028923461568170314\n",
      "\n",
      "Epoch 7: train loss: 0.03203564086514053\n",
      "valid loss: 0.02820663683375985\n",
      "New best score: 0.02820663683375985\n",
      "\n",
      "Epoch 8: train loss: 0.030814288029123105\n",
      "valid loss: 0.027781046959291636\n",
      "New best score: 0.027781046959291636\n",
      "\n",
      "Epoch 9: train loss: 0.02981960157869138\n",
      "valid loss: 0.027364441690345607\n",
      "New best score: 0.027364441690345607\n",
      "\n",
      "Epoch 10: train loss: 0.029556177704538045\n",
      "valid loss: 0.027248307754911605\n",
      "New best score: 0.027248307754911605\n",
      "\n",
      "Epoch 11: train loss: 0.028807074802502077\n",
      "valid loss: 0.027078346521568184\n",
      "New best score: 0.027078346521568184\n",
      "\n",
      "Epoch 12: train loss: 0.02843340825940345\n",
      "valid loss: 0.026872103086474246\n",
      "New best score: 0.026872103086474246\n",
      "\n",
      "Epoch 13: train loss: 0.02835337795877213\n",
      "valid loss: 0.026983617097800953\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 14: train loss: 0.02782686617818392\n",
      "valid loss: 0.026686494638176402\n",
      "New best score: 0.026686494638176402\n",
      "\n",
      "Epoch 15: train loss: 0.02762612111062474\n",
      "valid loss: 0.02671355667213599\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 16: train loss: 0.027630785535789498\n",
      "valid loss: 0.02680514597173658\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 17: train loss: 0.027082302831745498\n",
      "valid loss: 0.026621475614240914\n",
      "New best score: 0.026621475614240914\n",
      "\n",
      "Epoch 18: train loss: 0.026866118534268672\n",
      "valid loss: 0.026606559804309912\n",
      "New best score: 0.026606559804309912\n",
      "\n",
      "Epoch 19: train loss: 0.026894295736159025\n",
      "valid loss: 0.026601657185886727\n",
      "New best score: 0.026601657185886727\n",
      "\n",
      "Epoch 20: train loss: 0.02704654915065079\n",
      "valid loss: 0.026584211500397185\n",
      "New best score: 0.026584211500397185\n",
      "\n",
      "Epoch 21: train loss: 0.0266332208647715\n",
      "valid loss: 0.026554365910951026\n",
      "New best score: 0.026554365910951026\n",
      "\n",
      "Epoch 22: train loss: 0.02638820812117707\n",
      "valid loss: 0.02667300968425847\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 23: train loss: 0.026258999823475074\n",
      "valid loss: 0.026484966239143835\n",
      "New best score: 0.026484966239143835\n",
      "\n",
      "Epoch 24: train loss: 0.02581373815728355\n",
      "valid loss: 0.026667906049781483\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 25: train loss: 0.026275291881322802\n",
      "valid loss: 0.026635698921713837\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 26: train loss: 0.026099710382679636\n",
      "valid loss: 0.026547237446460405\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "input_features_new = input_features + [\"reconstruction_error\"]\n",
    "\n",
    "# Rescale the reconstruction error\n",
    "(train_df, valid_df)=scaleData(train_df, valid_df, [\"reconstruction_error\"])\n",
    "\n",
    "x_train_new = torch.FloatTensor(train_df[input_features_new].values)\n",
    "x_valid_new = torch.FloatTensor(valid_df[input_features_new].values)\n",
    "\n",
    "training_set_supervised_new = FraudDataset(x_train_new.to(DEVICE), y_train.to(DEVICE))\n",
    "valid_set_supervised_new = FraudDataset(x_valid_new.to(DEVICE), y_valid.to(DEVICE))\n",
    "\n",
    "training_generator_supervised,valid_generator_supervised = prepare_generators(training_set_supervised_new,\n",
    "                                                                              valid_set_supervised_new,\n",
    "                                                                              batch_size=64)\n",
    "\n",
    "model_supervised = SimpleFraudMLPWithDropout(len(input_features_new), 100, 0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model_supervised.parameters(), lr = 0.0001)\n",
    "criterion = torch.nn.BCELoss().to(DEVICE)\n",
    "\n",
    "model_supervised,new_training_execution_time_autoencoder,train_losses_dropout,valid_losses_dropout = \\\n",
    "    training_loop_and_saving_best_wandb(model_supervised,\n",
    "                  training_generator_supervised,\n",
    "                  valid_generator_supervised,\n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  verbose=True,\n",
    "                  save_path='models/DL/semi_sup_autoenc/semi_supervised_autoencoder_model.pt')\n",
    "\n",
    "predictions = []\n",
    "start_time=time.time()\n",
    "for x_batch, y_batch in valid_generator_supervised: \n",
    "    predictions.append(model_supervised(x_batch).detach().cpu().numpy())\n",
    "prediction_execution_time=time.time()-start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390.7052712440491\n",
      "0.9259974956512451\n"
     ]
    }
   ],
   "source": [
    "wandb.log({'Training execution time': training_execution_time_autoencoder + new_training_execution_time_autoencoder})\n",
    "print(training_execution_time_autoencoder + new_training_execution_time_autoencoder)\n",
    "print(prediction_execution_time)\n",
    "wandb.log({'Prediction execution time': prediction_execution_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  F1 score  Card Precision@100\n",
       "0     0.81              0.509     0.499               0.236"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df=valid_df\n",
    "predictions_df['predictions']=np.vstack(predictions)\n",
    "    \n",
    "performance_df = performance_assessment_f1_included(predictions_df, top_k_list=[100])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (.\\models\\DL\\semi_sup_autoenc)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>▁</td></tr><tr><td>Average precision</td><td>▁</td></tr><tr><td>Card Precision@100</td><td>▁</td></tr><tr><td>F1 score</td><td>▁</td></tr><tr><td>Prediction execution time</td><td>▁</td></tr><tr><td>Training execution time</td><td>▁</td></tr><tr><td>train loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC ROC</td><td>0.81</td></tr><tr><td>Average precision</td><td>0.509</td></tr><tr><td>Card Precision@100</td><td>0.236</td></tr><tr><td>F1 score</td><td>0.499</td></tr><tr><td>Prediction execution time</td><td>0.926</td></tr><tr><td>Training execution time</td><td>390.70527</td></tr><tr><td>train loss</td><td>0.0261</td></tr><tr><td>val loss</td><td>0.02655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dark-disco-9</strong>: <a href=\"https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/plmyeu1f\" target=\"_blank\">https://wandb.ai/mgr-anomaly-tsxai/mgr-anomaly-tsxai-project/runs/plmyeu1f</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221221_173237-plmyeu1f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'AUC ROC': performance_df.loc[0,'AUC ROC']})\n",
    "wandb.log({'Average precision': performance_df.loc[0,'Average precision']})\n",
    "wandb.log({'F1 score': performance_df.loc[0,'F1 score']})\n",
    "wandb.log({'Card Precision@100': performance_df.loc[0,'Card Precision@100']})\n",
    "\n",
    "mlp_artifact = wandb.Artifact('semi_sup_autoenc', type='semisupervised', description='trained semisupervised fraud detection where autoencoder generates new input feature and mlp predicts the final score')\n",
    "mlp_artifact.add_dir('models/DL/semi_sup_autoenc')\n",
    "wandb.log_artifact(mlp_artifact)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a11e3a7eb51e2483c16a5d7cdfda12389edc17230fd81a6fc823433cff3faa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
